CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal/05_ConvLocal_ndl_deprecated.cntk currentDirectory=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/TestData RunDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu DataDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/TestData ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal OutputDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu DeviceId=0 timestamping=true Train=[SGD=[maxEpochs=5]] Train=[SGD=[epochSize=100]] stderr=-
CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 10:57:44

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal/05_ConvLocal_ndl_deprecated.cntk  currentDirectory=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/TestData  RunDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu  DataDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/TestData  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal  OutputDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu  DeviceId=0  timestamping=true  Train=[SGD=[maxEpochs=5]]  Train=[SGD=[epochSize=100]]  stderr=-
Changed current directory to /tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/TestData
12/09/2017 10:57:44: Redirecting stderr to file -_Train_Test.log
12/09/2017 10:57:44: -------------------------------------------------------------------
12/09/2017 10:57:44: Build info: 

12/09/2017 10:57:44: 		Built time: Dec  8 2017 01:46:20
12/09/2017 10:57:44: 		Last modified date: Wed Nov 15 09:27:10 2017
12/09/2017 10:57:44: 		Build type: release
12/09/2017 10:57:44: 		Build target: GPU
12/09/2017 10:57:44: 		With 1bit-SGD: yes
12/09/2017 10:57:44: 		With ASGD: yes
12/09/2017 10:57:44: 		Math lib: mkl
12/09/2017 10:57:44: 		CUDA version: 9.0.0
12/09/2017 10:57:44: 		CUDNN version: 7.0.4
12/09/2017 10:57:44: 		Build Branch: HEAD
12/09/2017 10:57:44: 		Build SHA1: b130d7735044ce6697bfb963af91445bee740c73
12/09/2017 10:57:44: 		MPI distribution: Open MPI
12/09/2017 10:57:44: 		MPI version: 1.10.7
12/09/2017 10:57:44: -------------------------------------------------------------------
12/09/2017 10:57:44: -------------------------------------------------------------------
12/09/2017 10:57:44: GPU info:

12/09/2017 10:57:44: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/09/2017 10:57:44: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: 05_ConvLocal_ndl_deprecated.cntk:command=Train:Test
configparameters: 05_ConvLocal_ndl_deprecated.cntk:ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal
configparameters: 05_ConvLocal_ndl_deprecated.cntk:currentDirectory=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/TestData
configparameters: 05_ConvLocal_ndl_deprecated.cntk:DataDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/TestData
configparameters: 05_ConvLocal_ndl_deprecated.cntk:deviceId=0
configparameters: 05_ConvLocal_ndl_deprecated.cntk:imageLayout=cudnn
configparameters: 05_ConvLocal_ndl_deprecated.cntk:ModelDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/Models
configparameters: 05_ConvLocal_ndl_deprecated.cntk:modelPath=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/Models/05_ConvLocal
configparameters: 05_ConvLocal_ndl_deprecated.cntk:ndlMacros=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal/../Macros.ndl
configparameters: 05_ConvLocal_ndl_deprecated.cntk:numMBsToShowResult=50
configparameters: 05_ConvLocal_ndl_deprecated.cntk:OutputDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu
configparameters: 05_ConvLocal_ndl_deprecated.cntk:precision=float
configparameters: 05_ConvLocal_ndl_deprecated.cntk:RootDir=.
configparameters: 05_ConvLocal_ndl_deprecated.cntk:RunDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu
configparameters: 05_ConvLocal_ndl_deprecated.cntk:stderr=-
configparameters: 05_ConvLocal_ndl_deprecated.cntk:Test=[
    action = "test"
    minibatchSize = 16
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/TestData/Test_cntk_text.txt"
        input = [
            features = [
                dim = 3072
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]    
]

configparameters: 05_ConvLocal_ndl_deprecated.cntk:timestamping=true
configparameters: 05_ConvLocal_ndl_deprecated.cntk:traceLevel=1
configparameters: 05_ConvLocal_ndl_deprecated.cntk:Train=[
    action = "train"
     NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/05_ConvLocal/05_ConvLocal.ndl"
    ]
    SGD = [
        epochSize = 49984
        minibatchSize = 64
        learningRatesPerMB = 0.01*10:0.003*10:0.001
        momentumPerMB = 0.9*20:0.99
        maxEpochs = 30
        L2RegWeight = 0.03
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/TestData/Train_cntk_text.txt"
        input = [
            features = [
                dim = 3072
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]    
] [SGD=[maxEpochs=5]] [SGD=[epochSize=100]]

12/09/2017 10:57:44: Commands: Train Test
12/09/2017 10:57:44: precision = "float"

12/09/2017 10:57:44: ##############################################################################
12/09/2017 10:57:44: #                                                                            #
12/09/2017 10:57:44: # Train command (train action)                                               #
12/09/2017 10:57:44: #                                                                            #
12/09/2017 10:57:44: ##############################################################################

12/09/2017 10:57:44: 
Creating virgin network.
NDLBuilder Using GPU 0
SetGaussianRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
conv1.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 3, Output: 32 x 32 x 64, Kernel: 5 x 5 x 3, Map: 1 x 1 x 64, Stride: 1 x 1 x 3, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
pool1: using cuDNN convolution engine for geometry: Input: 32 x 32 x 64, Output: 15 x 15 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv2.c: using cuDNN convolution engine for geometry: Input: 15 x 15 x 64, Output: 15 x 15 x 64, Kernel: 5 x 5 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
pool2: using cuDNN convolution engine for geometry: Input: 15 x 15 x 64, Output: 7 x 7 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv3.c: using reference convolution engine for geometry, could be VERY SLOW: Input: 7 x 7 x 64, Output: 7 x 7 x 64, Kernel: 3 x 3 x 64, Map: 64, Stride: 1 x 1 x 64, Sharing: (0, 0, 0), AutoPad: (1, 1, 1), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
conv4.c: using reference convolution engine for geometry, could be VERY SLOW: Input: 7 x 7 x 64, Output: 7 x 7 x 32, Kernel: 3 x 3 x 64, Map: 32, Stride: 1 x 1 x 64, Sharing: (0, 0, 0), AutoPad: (1, 1, 1), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
12/09/2017 10:57:45: 
Model has 32 nodes. Using GPU 0.

12/09/2017 10:57:45: Training criterion:   CE = CrossEntropyWithSoftmax
12/09/2017 10:57:45: Evaluation criterion: Err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 12 are aliased.
	features (gradient) reuses featScaled (gradient)
	conv2.c (gradient) reuses conv2.p (gradient)
	conv3.c (gradient) reuses conv3.p (gradient)
	conv4.c (gradient) reuses conv4.p (gradient)
	conv1.c (gradient) reuses conv1.p (gradient)
	OutputNodes.t (gradient) reuses OutputNodes.z (gradient)

Memory Sharing: Out of 59 matrices, 36 are shared as 7, and 23 are not shared.

Here are the ones that share memory:
	{ conv1.W : [64 x 75] (gradient)
	  conv1.p : [32 x 32 x 64 x *]
	  conv1.y : [32 x 32 x 64 x *] (gradient)
	  conv2.y : [15 x 15 x 64 x *] }
	{ conv2.c : [15 x 15 x 64 x *]
	  conv2.c : [15 x 15 x 64 x *] (gradient)
	  conv2.p : [15 x 15 x 64 x *] (gradient)
	  pool2 : [7 x 7 x 64 x *] }
	{ conv3.W : [3136 x 576] (gradient)
	  conv4.y : [7 x 7 x 32 x *] }
	{ conv1.c : [32 x 32 x 64 x *]
	  conv1.c : [32 x 32 x 64 x *] (gradient)
	  conv1.p : [32 x 32 x 64 x *] (gradient)
	  conv2.p : [15 x 15 x 64 x *]
	  conv2.y : [15 x 15 x 64 x *] (gradient)
	  conv3.c : [7 x 7 x 64 x *]
	  conv3.y : [7 x 7 x 64 x *]
	  pool1 : [15 x 15 x 64 x *] (gradient) }
	{ OutputNodes.z : [10 x *]
	  conv2.W : [64 x 1600] (gradient)
	  conv3.p : [7 x 7 x 64 x *]
	  conv3.y : [7 x 7 x 64 x *] (gradient)
	  conv4.p : [7 x 7 x 32 x *]
	  conv4.y : [7 x 7 x 32 x *] (gradient)
	  pool2 : [7 x 7 x 64 x *] (gradient) }
	{ OutputNodes.t : [10 x *]
	  OutputNodes.t : [10 x *] (gradient)
	  OutputNodes.z : [10 x *] (gradient)
	  conv2.b : [1 x 1 x 64] (gradient)
	  conv3.c : [7 x 7 x 64 x *] (gradient)
	  conv3.p : [7 x 7 x 64 x *] (gradient)
	  conv4.c : [7 x 7 x 32 x *]
	  conv4.c : [7 x 7 x 32 x *] (gradient)
	  conv4.p : [7 x 7 x 32 x *] (gradient) }
	{ conv1.b : [1 x 1 x 64] (gradient)
	  conv1.y : [32 x 32 x 64 x *] }

Here are the ones that don't share memory:
	{Err : [1]}
	{featScaled : [32 x 32 x 3 x *]}
	{OutputNodes.W : [10 x 7 x 7 x 32] (gradient)}
	{OutputNodes.b : [10] (gradient)}
	{pool1 : [15 x 15 x 64 x *]}
	{conv4.b : [1 x 1 x 32] (gradient)}
	{CE : [1] (gradient)}
	{conv3.b : [1 x 1 x 64] (gradient)}
	{conv4.W : [1568 x 576] (gradient)}
	{labels : [10 x *]}
	{conv1.W : [64 x 75]}
	{conv1.b : [1 x 1 x 64]}
	{conv2.W : [64 x 1600]}
	{conv2.b : [1 x 1 x 64]}
	{conv3.W : [3136 x 576]}
	{conv3.b : [1 x 1 x 64]}
	{conv4.W : [1568 x 576]}
	{conv4.b : [1 x 1 x 32]}
	{OutputNodes.W : [10 x 7 x 7 x 32]}
	{OutputNodes.b : [10]}
	{featOffs : [1 x 1]}
	{CE : [1]}
	{features : [32 x 32 x 3 x *]}


12/09/2017 10:57:45: Training 2832618 parameters in 10 out of 10 parameter tensors and 27 nodes with gradient:

12/09/2017 10:57:45: 	Node 'OutputNodes.W' (LearnableParameter operation) : [10 x 7 x 7 x 32]
12/09/2017 10:57:45: 	Node 'OutputNodes.b' (LearnableParameter operation) : [10]
12/09/2017 10:57:45: 	Node 'conv1.W' (LearnableParameter operation) : [64 x 75]
12/09/2017 10:57:45: 	Node 'conv1.b' (LearnableParameter operation) : [1 x 1 x 64]
12/09/2017 10:57:45: 	Node 'conv2.W' (LearnableParameter operation) : [64 x 1600]
12/09/2017 10:57:45: 	Node 'conv2.b' (LearnableParameter operation) : [1 x 1 x 64]
12/09/2017 10:57:45: 	Node 'conv3.W' (LearnableParameter operation) : [3136 x 576]
12/09/2017 10:57:45: 	Node 'conv3.b' (LearnableParameter operation) : [1 x 1 x 64]
12/09/2017 10:57:45: 	Node 'conv4.W' (LearnableParameter operation) : [1568 x 576]
12/09/2017 10:57:45: 	Node 'conv4.b' (LearnableParameter operation) : [1 x 1 x 32]

12/09/2017 10:57:45: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/09/2017 10:57:45: Starting Epoch 1: learning rate per sample = 0.000156  effective momentum = 0.900000  momentum as time constant = 607.4 samples

12/09/2017 10:57:45: Starting minibatch loop.
12/09/2017 10:57:49: Finished Epoch[ 1 of 5]: [Training] CE = 2.30258331 * 100; Err = 0.90000000 * 100; totalSamplesSeen = 100; learningRatePerSample = 0.00015625; epochTime=4.49761s
12/09/2017 10:57:49: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/Models/05_ConvLocal.1'

12/09/2017 10:57:50: Starting Epoch 2: learning rate per sample = 0.000156  effective momentum = 0.900000  momentum as time constant = 607.4 samples

12/09/2017 10:57:50: Starting minibatch loop.
12/09/2017 10:57:50: Finished Epoch[ 2 of 5]: [Training] CE = 2.30260956 * 100; Err = 0.91000000 * 100; totalSamplesSeen = 200; learningRatePerSample = 0.00015625; epochTime=0.140209s
12/09/2017 10:57:50: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/Models/05_ConvLocal.2'

12/09/2017 10:57:50: Starting Epoch 3: learning rate per sample = 0.000156  effective momentum = 0.900000  momentum as time constant = 607.4 samples

12/09/2017 10:57:50: Starting minibatch loop.
12/09/2017 10:57:50: Finished Epoch[ 3 of 5]: [Training] CE = 2.30259995 * 100; Err = 0.90000000 * 100; totalSamplesSeen = 300; learningRatePerSample = 0.00015625; epochTime=0.141072s
12/09/2017 10:57:50: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/Models/05_ConvLocal.3'

12/09/2017 10:57:50: Starting Epoch 4: learning rate per sample = 0.000156  effective momentum = 0.900000  momentum as time constant = 607.4 samples

12/09/2017 10:57:50: Starting minibatch loop.
12/09/2017 10:57:50: Finished Epoch[ 4 of 5]: [Training] CE = 2.30261444 * 100; Err = 0.92000000 * 100; totalSamplesSeen = 400; learningRatePerSample = 0.00015625; epochTime=0.13592s
12/09/2017 10:57:50: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/Models/05_ConvLocal.4'

12/09/2017 10:57:51: Starting Epoch 5: learning rate per sample = 0.000156  effective momentum = 0.900000  momentum as time constant = 607.4 samples

12/09/2017 10:57:51: Starting minibatch loop.
12/09/2017 10:57:51: Finished Epoch[ 5 of 5]: [Training] CE = 2.30254822 * 100; Err = 0.92000000 * 100; totalSamplesSeen = 500; learningRatePerSample = 0.00015625; epochTime=0.141022s
12/09/2017 10:57:51: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_05_ConvLocal@release_gpu/Models/05_ConvLocal'

12/09/2017 10:57:51: Action "train" complete.


12/09/2017 10:57:51: ##############################################################################
12/09/2017 10:57:51: #                                                                            #
12/09/2017 10:57:51: # Test command (test action)                                                 #
12/09/2017 10:57:51: #                                                                            #
12/09/2017 10:57:51: ##############################################################################


Post-processing network...

3 roots:
	CE = CrossEntropyWithSoftmax()
	Err = ClassificationError()
	OutputNodes.z = Plus()

Validating network. 32 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [10 x *1]
Validating --> OutputNodes.W = LearnableParameter() :  -> [10 x 7 x 7 x 32]
Validating --> conv4.W = LearnableParameter() :  -> [1568 x 576]
Validating --> conv3.W = LearnableParameter() :  -> [3136 x 576]
Validating --> conv2.W = LearnableParameter() :  -> [64 x 1600]
Validating --> conv1.W = LearnableParameter() :  -> [64 x 75]
Validating --> features = InputValue() :  -> [32 x 32 x 3 x *1]
Validating --> featOffs = LearnableParameter() :  -> [1 x 1]
Validating --> featScaled = Minus (features, featOffs) : [32 x 32 x 3 x *1], [1 x 1] -> [32 x 32 x 3 x *1]
Validating --> conv1.c = Convolution (conv1.W, featScaled) : [64 x 75], [32 x 32 x 3 x *1] -> [32 x 32 x 64 x *1]
Validating --> conv1.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv1.p = Plus (conv1.c, conv1.b) : [32 x 32 x 64 x *1], [1 x 1 x 64] -> [32 x 32 x 64 x *1]
Validating --> conv1.y = RectifiedLinear (conv1.p) : [32 x 32 x 64 x *1] -> [32 x 32 x 64 x *1]
Validating --> pool1 = MaxPooling (conv1.y) : [32 x 32 x 64 x *1] -> [15 x 15 x 64 x *1]
Validating --> conv2.c = Convolution (conv2.W, pool1) : [64 x 1600], [15 x 15 x 64 x *1] -> [15 x 15 x 64 x *1]
Validating --> conv2.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv2.p = Plus (conv2.c, conv2.b) : [15 x 15 x 64 x *1], [1 x 1 x 64] -> [15 x 15 x 64 x *1]
Validating --> conv2.y = RectifiedLinear (conv2.p) : [15 x 15 x 64 x *1] -> [15 x 15 x 64 x *1]
Validating --> pool2 = MaxPooling (conv2.y) : [15 x 15 x 64 x *1] -> [7 x 7 x 64 x *1]
Validating --> conv3.c = Convolution (conv3.W, pool2) : [3136 x 576], [7 x 7 x 64 x *1] -> [7 x 7 x 64 x *1]
Validating --> conv3.b = LearnableParameter() :  -> [1 x 1 x 64]
Validating --> conv3.p = Plus (conv3.c, conv3.b) : [7 x 7 x 64 x *1], [1 x 1 x 64] -> [7 x 7 x 64 x *1]
Validating --> conv3.y = RectifiedLinear (conv3.p) : [7 x 7 x 64 x *1] -> [7 x 7 x 64 x *1]
Validating --> conv4.c = Convolution (conv4.W, conv3.y) : [1568 x 576], [7 x 7 x 64 x *1] -> [7 x 7 x 32 x *1]
Validating --> conv4.b = LearnableParameter() :  -> [1 x 1 x 32]
Validating --> conv4.p = Plus (conv4.c, conv4.b) : [7 x 7 x 32 x *1], [1 x 1 x 32] -> [7 x 7 x 32 x *1]
Validating --> conv4.y = RectifiedLinear (conv4.p) : [7 x 7 x 32 x *1] -> [7 x 7 x 32 x *1]
Validating --> OutputNodes.t = Times (OutputNodes.W, conv4.y) : [10 x 7 x 7 x 32], [7 x 7 x 32 x *1] -> [10 x *1]
Validating --> OutputNodes.b = LearnableParameter() :  -> [10]
Validating --> OutputNodes.z = Plus (OutputNodes.t, OutputNodes.b) : [10 x *1], [10] -> [10 x *1]
Validating --> CE = CrossEntropyWithSoftmax (labels, OutputNodes.z) : [10 x *1], [10 x *1] -> [1]
Validating --> Err = ClassificationError (labels, OutputNodes.z) : [10 x *1], [10 x *1] -> [1]

Validating network. 19 nodes to process in pass 2.


Validating network, final pass.

conv1.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 3, Output: 32 x 32 x 64, Kernel: 5 x 5 x 3, Map: 1 x 1 x 64, Stride: 1 x 1 x 3, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
pool1: using cuDNN convolution engine for geometry: Input: 32 x 32 x 64, Output: 15 x 15 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv2.c: using cuDNN convolution engine for geometry: Input: 15 x 15 x 64, Output: 15 x 15 x 64, Kernel: 5 x 5 x 64, Map: 1 x 1 x 64, Stride: 1 x 1 x 64, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
pool2: using cuDNN convolution engine for geometry: Input: 15 x 15 x 64, Output: 7 x 7 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv3.c: using reference convolution engine for geometry, could be VERY SLOW: Input: 7 x 7 x 64, Output: 7 x 7 x 64, Kernel: 3 x 3 x 64, Map: 64, Stride: 1 x 1 x 64, Sharing: (0, 0, 0), AutoPad: (1, 1, 1), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
conv4.c: using reference convolution engine for geometry, could be VERY SLOW: Input: 7 x 7 x 64, Output: 7 x 7 x 32, Kernel: 3 x 3 x 64, Map: 32, Stride: 1 x 1 x 64, Sharing: (0, 0, 0), AutoPad: (1, 1, 1), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 32 matrices, 17 are shared as 2, and 15 are not shared.

Here are the ones that share memory:
	{ OutputNodes.z : [10 x *1]
	  conv1.p : [32 x 32 x 64 x *1]
	  conv2.p : [15 x 15 x 64 x *1]
	  conv3.p : [7 x 7 x 64 x *1]
	  conv4.c : [7 x 7 x 32 x *1]
	  conv4.y : [7 x 7 x 32 x *1]
	  featScaled : [32 x 32 x 3 x *1]
	  pool1 : [15 x 15 x 64 x *1]
	  pool2 : [7 x 7 x 64 x *1] }
	{ OutputNodes.t : [10 x *1]
	  conv1.c : [32 x 32 x 64 x *1]
	  conv1.y : [32 x 32 x 64 x *1]
	  conv2.c : [15 x 15 x 64 x *1]
	  conv2.y : [15 x 15 x 64 x *1]
	  conv3.c : [7 x 7 x 64 x *1]
	  conv3.y : [7 x 7 x 64 x *1]
	  conv4.p : [7 x 7 x 32 x *1] }

Here are the ones that don't share memory:
	{conv1.W : [64 x 75]}
	{conv2.b : [1 x 1 x 64]}
	{conv2.W : [64 x 1600]}
	{conv3.b : [1 x 1 x 64]}
	{conv3.W : [3136 x 576]}
	{conv4.b : [1 x 1 x 32]}
	{conv4.W : [1568 x 576]}
	{featOffs : [1 x 1]}
	{features : [32 x 32 x 3 x *1]}
	{labels : [10 x *1]}
	{OutputNodes.b : [10]}
	{OutputNodes.W : [10 x 7 x 7 x 32]}
	{Err : [1]}
	{CE : [1]}
	{conv1.b : [1 x 1 x 64]}

12/09/2017 10:57:52: Minibatch[1-50]: Err = 0.88625000 * 800; CE = 2.30255409 * 800
12/09/2017 10:57:52: Minibatch[51-100]: Err = 0.88125000 * 800; CE = 2.30251834 * 800
12/09/2017 10:57:52: Minibatch[101-150]: Err = 0.88875000 * 800; CE = 2.30254840 * 800
12/09/2017 10:57:53: Minibatch[151-200]: Err = 0.88375000 * 800; CE = 2.30252307 * 800
12/09/2017 10:57:53: Minibatch[201-250]: Err = 0.88125000 * 800; CE = 2.30251458 * 800
12/09/2017 10:57:53: Minibatch[251-300]: Err = 0.89125000 * 800; CE = 2.30253713 * 800
12/09/2017 10:57:53: Minibatch[301-350]: Err = 0.86750000 * 800; CE = 2.30251247 * 800
12/09/2017 10:57:54: Minibatch[351-400]: Err = 0.87250000 * 800; CE = 2.30253078 * 800
12/09/2017 10:57:54: Minibatch[401-450]: Err = 0.89750000 * 800; CE = 2.30254354 * 800
12/09/2017 10:57:54: Minibatch[451-500]: Err = 0.88500000 * 800; CE = 2.30252729 * 800
12/09/2017 10:57:54: Minibatch[501-550]: Err = 0.89500000 * 800; CE = 2.30254131 * 800
12/09/2017 10:57:55: Minibatch[551-600]: Err = 0.87875000 * 800; CE = 2.30255236 * 800
12/09/2017 10:57:55: Minibatch[601-625]: Err = 0.88750000 * 400; CE = 2.30254293 * 400
12/09/2017 10:57:55: Final Results: Minibatch[1-625]: Err = 0.88420000 * 10000; CE = 2.30253399 * 10000; perplexity = 9.99948896

12/09/2017 10:57:55: Action "test" complete.

12/09/2017 10:57:55: __COMPLETED__