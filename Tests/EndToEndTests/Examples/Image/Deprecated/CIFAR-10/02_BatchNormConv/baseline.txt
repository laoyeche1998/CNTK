CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/02_BatchNormConv/02_BatchNormConv_ndl_deprecated.cntk currentDirectory=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/TestData RunDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu DataDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/TestData ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/02_BatchNormConv OutputDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu DeviceId=0 timestamping=true Train=[SGD=[maxEpochs=5]] Train=[SGD=[epochSize=100]] stderr=-
CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 10:56:52

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/02_BatchNormConv/02_BatchNormConv_ndl_deprecated.cntk  currentDirectory=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/TestData  RunDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu  DataDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/TestData  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/02_BatchNormConv  OutputDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu  DeviceId=0  timestamping=true  Train=[SGD=[maxEpochs=5]]  Train=[SGD=[epochSize=100]]  stderr=-
Changed current directory to /tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/TestData
12/09/2017 10:56:52: Redirecting stderr to file -_Train_Test.log
12/09/2017 10:56:52: -------------------------------------------------------------------
12/09/2017 10:56:52: Build info: 

12/09/2017 10:56:52: 		Built time: Dec  8 2017 01:46:20
12/09/2017 10:56:52: 		Last modified date: Wed Nov 15 09:27:10 2017
12/09/2017 10:56:52: 		Build type: release
12/09/2017 10:56:52: 		Build target: GPU
12/09/2017 10:56:52: 		With 1bit-SGD: yes
12/09/2017 10:56:52: 		With ASGD: yes
12/09/2017 10:56:52: 		Math lib: mkl
12/09/2017 10:56:52: 		CUDA version: 9.0.0
12/09/2017 10:56:52: 		CUDNN version: 7.0.4
12/09/2017 10:56:52: 		Build Branch: HEAD
12/09/2017 10:56:52: 		Build SHA1: b130d7735044ce6697bfb963af91445bee740c73
12/09/2017 10:56:52: 		MPI distribution: Open MPI
12/09/2017 10:56:52: 		MPI version: 1.10.7
12/09/2017 10:56:52: -------------------------------------------------------------------
12/09/2017 10:56:52: -------------------------------------------------------------------
12/09/2017 10:56:52: GPU info:

12/09/2017 10:56:52: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/09/2017 10:56:52: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: 02_BatchNormConv_ndl_deprecated.cntk:command=Train:Test
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/02_BatchNormConv
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:currentDirectory=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/TestData
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:DataDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/TestData
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:deviceId=0
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:imageLayout=cudnn
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:initOnCPUOnly=true
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:ModelDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/Models
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:ndlMacros=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/02_BatchNormConv/../Macros.ndl
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:numMBsToShowResult=500
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:OutputDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:precision=float
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:RootDir=.
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:RunDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:stderr=-
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:Test=[
    action = "test"
    modelPath = "/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/Models/02_BatchNormConv"
    minibatchSize = 16
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/TestData/Test_cntk_text.txt"
        input = [
            features = [
                dim = 3072
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]    
]

configparameters: 02_BatchNormConv_ndl_deprecated.cntk:timestamping=true
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:traceLevel=1
configparameters: 02_BatchNormConv_ndl_deprecated.cntk:Train=[
    action = "train"
    modelPath = "/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/Models/02_BatchNormConv"
     NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/Deprecated/CIFAR-10/02_BatchNormConv/02_BatchNormConv.ndl"
    ]
    SGD = [
        epochSize = 49984
        minibatchSize = 64
        learningRatesPerMB = 0.03*7:0.01
        momentumPerMB = 0
        maxEpochs = 10
        L2RegWeight = 0
        dropoutRate = 0
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/TestData/Train_cntk_text.txt"
        input = [
            features = [
                dim = 3072
                format = "dense"
            ]
            labels = [
                dim = 10
                format = "dense"
            ]
        ]
    ]    
] [SGD=[maxEpochs=5]] [SGD=[epochSize=100]]

12/09/2017 10:56:52: Commands: Train Test
12/09/2017 10:56:52: precision = "float"

12/09/2017 10:56:52: ##############################################################################
12/09/2017 10:56:52: #                                                                            #
12/09/2017 10:56:52: # Train command (train action)                                               #
12/09/2017 10:56:52: #                                                                            #
12/09/2017 10:56:52: ##############################################################################

12/09/2017 10:56:52: 
Creating virgin network.
NDLBuilder Using GPU 0
SetGaussianRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
conv1.c.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 3, Output: 32 x 32 x 32, Kernel: 5 x 5 x 3, Map: 1 x 1 x 32, Stride: 1 x 1 x 3, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
pool1: using cuDNN convolution engine for geometry: Input: 32 x 32 x 32, Output: 15 x 15 x 32, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv2.c.c.c: using cuDNN convolution engine for geometry: Input: 15 x 15 x 32, Output: 15 x 15 x 32, Kernel: 5 x 5 x 32, Map: 1 x 1 x 32, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
pool2: using cuDNN convolution engine for geometry: Input: 15 x 15 x 32, Output: 7 x 7 x 32, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv3.c.c.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 32, Output: 7 x 7 x 64, Kernel: 5 x 5 x 32, Map: 1 x 1 x 64, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
pool3: using cuDNN convolution engine for geometry: Input: 7 x 7 x 64, Output: 3 x 3 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
Using CNTK batch normalization engine.
12/09/2017 10:56:53: 
Model has 49 nodes. Using GPU 0.

12/09/2017 10:56:53: Training criterion:   CE = CrossEntropyWithSoftmax
12/09/2017 10:56:53: Evaluation criterion: Err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 4 are aliased.
	OutputNodes.t (gradient) reuses OutputNodes.z (gradient)
	features (gradient) reuses featScaled (gradient)

Memory Sharing: Out of 81 matrices, 43 are shared as 12, and 38 are not shared.

Here are the ones that share memory:
	{ conv2.c.c.sc : [32 x 1] (gradient)
	  conv3.y : [7 x 7 x 64 x *]
	  pool2 : [7 x 7 x 32 x *] (gradient) }
	{ conv1.c.c.b : [32 x 1] (gradient)
	  conv2.c.c.c : [15 x 15 x 32 x *] (gradient)
	  conv2.y : [15 x 15 x 32 x *] }
	{ conv3.c.W : [64 x 800] (gradient)
	  conv3.c.c.y : [7 x 7 x 64 x *]
	  conv3.c.c.y : [7 x 7 x 64 x *] (gradient)
	  pool3 : [3 x 3 x 64 x *] }
	{ conv2.c.c.b : [32 x 1] (gradient)
	  pool2 : [7 x 7 x 32 x *] }
	{ conv1.c.c.c : [32 x 32 x 32 x *] (gradient)
	  conv1.y : [32 x 32 x 32 x *] }
	{ conv1.c.W : [32 x 75] (gradient)
	  conv1.c.c.y : [32 x 32 x 32 x *]
	  conv1.y : [32 x 32 x 32 x *] (gradient)
	  conv2.c.c.c : [15 x 15 x 32 x *] }
	{ conv1.c.c.y : [32 x 32 x 32 x *] (gradient)
	  pool1 : [15 x 15 x 32 x *] }
	{ conv2.c.W : [32 x 800] (gradient)
	  conv2.y : [15 x 15 x 32 x *] (gradient)
	  conv3.c.c.c : [7 x 7 x 64 x *] }
	{ conv1.c.c.sc : [32 x 1] (gradient)
	  conv2.c.c.y : [15 x 15 x 32 x *]
	  conv2.c.c.y : [15 x 15 x 32 x *] (gradient)
	  conv3.c.c.c : [7 x 7 x 64 x *] (gradient)
	  conv3.y : [7 x 7 x 64 x *] (gradient)
	  h1.t : [64 x *]
	  pool1 : [15 x 15 x 32 x *] (gradient) }
	{ OutputNodes.t : [10 x *]
	  OutputNodes.t : [10 x *] (gradient)
	  OutputNodes.z : [10 x *] (gradient)
	  h1.W : [64 x 3 x 3 x 64] (gradient)
	  h1.bn : [64 x *] (gradient) }
	{ OutputNodes.z : [10 x *]
	  conv3.c.c.sc : [64 x 1] (gradient)
	  h1.bn : [64 x *]
	  h1.t : [64 x *] (gradient)
	  h1.y : [64 x *] (gradient) }
	{ conv3.c.c.b : [64 x 1] (gradient)
	  h1.y : [64 x *]
	  pool3 : [3 x 3 x 64 x *] (gradient) }

Here are the ones that don't share memory:
	{features : [32 x 32 x 3 x *]}
	{featOffs : [1 x 1]}
	{labels : [10 x *]}
	{conv1.c.W : [32 x 75]}
	{conv1.c.c.b : [32 x 1]}
	{conv1.c.c.sc : [32 x 1]}
	{conv1.c.c.m : [32 x 1]}
	{conv1.c.c.v : [32 x 1]}
	{conv1.c.c.y.run_sample_count : [1]}
	{conv2.c.W : [32 x 800]}
	{conv2.c.c.b : [32 x 1]}
	{conv2.c.c.sc : [32 x 1]}
	{conv2.c.c.m : [32 x 1]}
	{conv2.c.c.v : [32 x 1]}
	{conv2.c.c.y.run_sample_count : [1]}
	{conv3.c.W : [64 x 800]}
	{conv3.c.c.sc : [64 x 1]}
	{conv3.c.c.b : [64 x 1]}
	{conv3.c.c.m : [64 x 1]}
	{conv3.c.c.v : [64 x 1]}
	{conv3.c.c.y.run_sample_count : [1]}
	{h1.W : [64 x 3 x 3 x 64]}
	{h1.b : [64 x 1]}
	{h1.sc : [64 x 1]}
	{h1.m : [64 x 1]}
	{h1.v : [64 x 1]}
	{h1.bn.run_sample_count : [1]}
	{OutputNodes.W : [10 x 64]}
	{OutputNodes.b : [10]}
	{Err : [1]}
	{h1.b : [64 x 1] (gradient)}
	{h1.sc : [64 x 1] (gradient)}
	{CE : [1]}
	{OutputNodes.W : [10 x 64] (gradient)}
	{conv1.c.c.c : [32 x 32 x 32 x *]}
	{featScaled : [32 x 32 x 3 x *]}
	{CE : [1] (gradient)}
	{OutputNodes.b : [10] (gradient)}


12/09/2017 10:56:53: Training 117098 parameters in 14 out of 14 parameter tensors and 32 nodes with gradient:

12/09/2017 10:56:53: 	Node 'OutputNodes.W' (LearnableParameter operation) : [10 x 64]
12/09/2017 10:56:53: 	Node 'OutputNodes.b' (LearnableParameter operation) : [10]
12/09/2017 10:56:53: 	Node 'conv1.c.W' (LearnableParameter operation) : [32 x 75]
12/09/2017 10:56:53: 	Node 'conv1.c.c.b' (LearnableParameter operation) : [32 x 1]
12/09/2017 10:56:53: 	Node 'conv1.c.c.sc' (LearnableParameter operation) : [32 x 1]
12/09/2017 10:56:53: 	Node 'conv2.c.W' (LearnableParameter operation) : [32 x 800]
12/09/2017 10:56:53: 	Node 'conv2.c.c.b' (LearnableParameter operation) : [32 x 1]
12/09/2017 10:56:53: 	Node 'conv2.c.c.sc' (LearnableParameter operation) : [32 x 1]
12/09/2017 10:56:53: 	Node 'conv3.c.W' (LearnableParameter operation) : [64 x 800]
12/09/2017 10:56:53: 	Node 'conv3.c.c.b' (LearnableParameter operation) : [64 x 1]
12/09/2017 10:56:53: 	Node 'conv3.c.c.sc' (LearnableParameter operation) : [64 x 1]
12/09/2017 10:56:53: 	Node 'h1.W' (LearnableParameter operation) : [64 x 3 x 3 x 64]
12/09/2017 10:56:53: 	Node 'h1.b' (LearnableParameter operation) : [64 x 1]
12/09/2017 10:56:53: 	Node 'h1.sc' (LearnableParameter operation) : [64 x 1]

12/09/2017 10:56:53: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/09/2017 10:56:53: Starting Epoch 1: learning rate per sample = 0.000469  effective momentum = 0.000000  momentum as time constant = 0.0 samples

12/09/2017 10:56:53: Starting minibatch loop.
12/09/2017 10:56:58: Finished Epoch[ 1 of 5]: [Training] CE = 2.26618500 * 100; Err = 0.87000000 * 100; totalSamplesSeen = 100; learningRatePerSample = 0.00046874999; epochTime=4.3912s
12/09/2017 10:56:58: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/Models/02_BatchNormConv.1'

12/09/2017 10:56:58: Starting Epoch 2: learning rate per sample = 0.000469  effective momentum = 0.000000  momentum as time constant = 0.0 samples

12/09/2017 10:56:58: Starting minibatch loop.
12/09/2017 10:56:58: Finished Epoch[ 2 of 5]: [Training] CE = 2.24375671 * 100; Err = 0.82000000 * 100; totalSamplesSeen = 200; learningRatePerSample = 0.00046874999; epochTime=0.0096075s
12/09/2017 10:56:58: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/Models/02_BatchNormConv.2'

12/09/2017 10:56:58: Starting Epoch 3: learning rate per sample = 0.000469  effective momentum = 0.000000  momentum as time constant = 0.0 samples

12/09/2017 10:56:58: Starting minibatch loop.
12/09/2017 10:56:58: Finished Epoch[ 3 of 5]: [Training] CE = 2.21250885 * 100; Err = 0.84000000 * 100; totalSamplesSeen = 300; learningRatePerSample = 0.00046874999; epochTime=0.0090614s
12/09/2017 10:56:58: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/Models/02_BatchNormConv.3'

12/09/2017 10:56:58: Starting Epoch 4: learning rate per sample = 0.000469  effective momentum = 0.000000  momentum as time constant = 0.0 samples

12/09/2017 10:56:58: Starting minibatch loop.
12/09/2017 10:56:58: Finished Epoch[ 4 of 5]: [Training] CE = 2.20484741 * 100; Err = 0.82000000 * 100; totalSamplesSeen = 400; learningRatePerSample = 0.00046874999; epochTime=0.0093667s
12/09/2017 10:56:58: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/Models/02_BatchNormConv.4'

12/09/2017 10:56:58: Starting Epoch 5: learning rate per sample = 0.000469  effective momentum = 0.000000  momentum as time constant = 0.0 samples

12/09/2017 10:56:58: Starting minibatch loop.
12/09/2017 10:56:58: Finished Epoch[ 5 of 5]: [Training] CE = 2.17222458 * 100; Err = 0.77000000 * 100; totalSamplesSeen = 500; learningRatePerSample = 0.00046874999; epochTime=0.0094398s
12/09/2017 10:56:58: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Examples/Image/Deprecated/CIFAR-10_02_BatchNormConv@release_gpu/Models/02_BatchNormConv'

12/09/2017 10:56:58: Action "train" complete.


12/09/2017 10:56:58: ##############################################################################
12/09/2017 10:56:58: #                                                                            #
12/09/2017 10:56:58: # Test command (test action)                                                 #
12/09/2017 10:56:58: #                                                                            #
12/09/2017 10:56:58: ##############################################################################


Post-processing network...

3 roots:
	CE = CrossEntropyWithSoftmax()
	Err = ClassificationError()
	OutputNodes.z = Plus()

Validating network. 49 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [10 x *1]
Validating --> OutputNodes.W = LearnableParameter() :  -> [10 x 64]
Validating --> h1.W = LearnableParameter() :  -> [64 x 3 x 3 x 64]
Validating --> conv3.c.W = LearnableParameter() :  -> [64 x 800]
Validating --> conv2.c.W = LearnableParameter() :  -> [32 x 800]
Validating --> conv1.c.W = LearnableParameter() :  -> [32 x 75]
Validating --> features = InputValue() :  -> [32 x 32 x 3 x *1]
Validating --> featOffs = LearnableParameter() :  -> [1 x 1]
Validating --> featScaled = Minus (features, featOffs) : [32 x 32 x 3 x *1], [1 x 1] -> [32 x 32 x 3 x *1]
Validating --> conv1.c.c.c = Convolution (conv1.c.W, featScaled) : [32 x 75], [32 x 32 x 3 x *1] -> [32 x 32 x 32 x *1]
Validating --> conv1.c.c.sc = LearnableParameter() :  -> [32 x 1]
Validating --> conv1.c.c.b = LearnableParameter() :  -> [32 x 1]
Validating --> conv1.c.c.m = LearnableParameter() :  -> [32 x 1]
Validating --> conv1.c.c.v = LearnableParameter() :  -> [32 x 1]
Validating --> conv1.c.c.y.run_sample_count = LearnableParameter() :  -> [1]
Validating --> conv1.c.c.y = BatchNormalization (conv1.c.c.c, conv1.c.c.sc, conv1.c.c.b, conv1.c.c.m, conv1.c.c.v, conv1.c.c.y.run_sample_count) : [32 x 32 x 32 x *1], [32 x 1], [32 x 1], [32 x 1], [32 x 1], [1] -> [32 x 32 x 32 x *1]
Validating --> conv1.y = RectifiedLinear (conv1.c.c.y) : [32 x 32 x 32 x *1] -> [32 x 32 x 32 x *1]
Validating --> pool1 = MaxPooling (conv1.y) : [32 x 32 x 32 x *1] -> [15 x 15 x 32 x *1]
Validating --> conv2.c.c.c = Convolution (conv2.c.W, pool1) : [32 x 800], [15 x 15 x 32 x *1] -> [15 x 15 x 32 x *1]
Validating --> conv2.c.c.sc = LearnableParameter() :  -> [32 x 1]
Validating --> conv2.c.c.b = LearnableParameter() :  -> [32 x 1]
Validating --> conv2.c.c.m = LearnableParameter() :  -> [32 x 1]
Validating --> conv2.c.c.v = LearnableParameter() :  -> [32 x 1]
Validating --> conv2.c.c.y.run_sample_count = LearnableParameter() :  -> [1]
Validating --> conv2.c.c.y = BatchNormalization (conv2.c.c.c, conv2.c.c.sc, conv2.c.c.b, conv2.c.c.m, conv2.c.c.v, conv2.c.c.y.run_sample_count) : [15 x 15 x 32 x *1], [32 x 1], [32 x 1], [32 x 1], [32 x 1], [1] -> [15 x 15 x 32 x *1]
Validating --> conv2.y = RectifiedLinear (conv2.c.c.y) : [15 x 15 x 32 x *1] -> [15 x 15 x 32 x *1]
Validating --> pool2 = MaxPooling (conv2.y) : [15 x 15 x 32 x *1] -> [7 x 7 x 32 x *1]
Validating --> conv3.c.c.c = Convolution (conv3.c.W, pool2) : [64 x 800], [7 x 7 x 32 x *1] -> [7 x 7 x 64 x *1]
Validating --> conv3.c.c.sc = LearnableParameter() :  -> [64 x 1]
Validating --> conv3.c.c.b = LearnableParameter() :  -> [64 x 1]
Validating --> conv3.c.c.m = LearnableParameter() :  -> [64 x 1]
Validating --> conv3.c.c.v = LearnableParameter() :  -> [64 x 1]
Validating --> conv3.c.c.y.run_sample_count = LearnableParameter() :  -> [1]
Validating --> conv3.c.c.y = BatchNormalization (conv3.c.c.c, conv3.c.c.sc, conv3.c.c.b, conv3.c.c.m, conv3.c.c.v, conv3.c.c.y.run_sample_count) : [7 x 7 x 64 x *1], [64 x 1], [64 x 1], [64 x 1], [64 x 1], [1] -> [7 x 7 x 64 x *1]
Validating --> conv3.y = RectifiedLinear (conv3.c.c.y) : [7 x 7 x 64 x *1] -> [7 x 7 x 64 x *1]
Validating --> pool3 = MaxPooling (conv3.y) : [7 x 7 x 64 x *1] -> [3 x 3 x 64 x *1]
Validating --> h1.t = Times (h1.W, pool3) : [64 x 3 x 3 x 64], [3 x 3 x 64 x *1] -> [64 x *1]
Validating --> h1.sc = LearnableParameter() :  -> [64 x 1]
Validating --> h1.b = LearnableParameter() :  -> [64 x 1]
Validating --> h1.m = LearnableParameter() :  -> [64 x 1]
Validating --> h1.v = LearnableParameter() :  -> [64 x 1]
Validating --> h1.bn.run_sample_count = LearnableParameter() :  -> [1]
Validating --> h1.bn = BatchNormalization (h1.t, h1.sc, h1.b, h1.m, h1.v, h1.bn.run_sample_count) : [64 x *1], [64 x 1], [64 x 1], [64 x 1], [64 x 1], [1] -> [64 x *1]
Validating --> h1.y = RectifiedLinear (h1.bn) : [64 x *1] -> [64 x *1]
Validating --> OutputNodes.t = Times (OutputNodes.W, h1.y) : [10 x 64], [64 x *1] -> [10 x *1]
Validating --> OutputNodes.b = LearnableParameter() :  -> [10]
Validating --> OutputNodes.z = Plus (OutputNodes.t, OutputNodes.b) : [10 x *1], [10] -> [10 x *1]
Validating --> CE = CrossEntropyWithSoftmax (labels, OutputNodes.z) : [10 x *1], [10 x *1] -> [1]
Validating --> Err = ClassificationError (labels, OutputNodes.z) : [10 x *1], [10 x *1] -> [1]

Validating network. 20 nodes to process in pass 2.


Validating network, final pass.

conv1.c.c.c: using cuDNN convolution engine for geometry: Input: 32 x 32 x 3, Output: 32 x 32 x 32, Kernel: 5 x 5 x 3, Map: 1 x 1 x 32, Stride: 1 x 1 x 3, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
pool1: using cuDNN convolution engine for geometry: Input: 32 x 32 x 32, Output: 15 x 15 x 32, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv2.c.c.c: using cuDNN convolution engine for geometry: Input: 15 x 15 x 32, Output: 15 x 15 x 32, Kernel: 5 x 5 x 32, Map: 1 x 1 x 32, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
pool2: using cuDNN convolution engine for geometry: Input: 15 x 15 x 32, Output: 7 x 7 x 32, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv3.c.c.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 32, Output: 7 x 7 x 64, Kernel: 5 x 5 x 32, Map: 1 x 1 x 64, Stride: 1 x 1 x 32, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
pool3: using cuDNN convolution engine for geometry: Input: 7 x 7 x 64, Output: 3 x 3 x 64, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
Using CNTK batch normalization engine.



Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 49 matrices, 18 are shared as 3, and 31 are not shared.

Here are the ones that share memory:
	{ OutputNodes.t : [10 x *1]
	  conv1.c.c.y : [32 x 32 x 32 x *1]
	  conv2.y : [15 x 15 x 32 x *1]
	  conv3.c.c.c : [7 x 7 x 64 x *1]
	  conv3.y : [7 x 7 x 64 x *1]
	  h1.t : [64 x *1]
	  pool1 : [15 x 15 x 32 x *1] }
	{ conv1.c.c.c : [32 x 32 x 32 x *1]
	  conv1.y : [32 x 32 x 32 x *1]
	  conv2.c.c.c : [15 x 15 x 32 x *1]
	  h1.bn : [64 x *1] }
	{ OutputNodes.z : [10 x *1]
	  conv2.c.c.y : [15 x 15 x 32 x *1]
	  conv3.c.c.y : [7 x 7 x 64 x *1]
	  featScaled : [32 x 32 x 3 x *1]
	  h1.y : [64 x *1]
	  pool2 : [7 x 7 x 32 x *1]
	  pool3 : [3 x 3 x 64 x *1] }

Here are the ones that don't share memory:
	{conv2.c.c.m : [32 x 1]}
	{conv2.c.c.sc : [32 x 1]}
	{conv2.c.c.v : [32 x 1]}
	{conv2.c.W : [32 x 800]}
	{conv2.c.c.y.run_sample_count : [1]}
	{conv3.c.c.b : [64 x 1]}
	{conv3.c.c.m : [64 x 1]}
	{conv1.c.c.m : [32 x 1]}
	{conv1.c.c.sc : [32 x 1]}
	{conv1.c.c.b : [32 x 1]}
	{conv1.c.c.v : [32 x 1]}
	{conv1.c.W : [32 x 75]}
	{Err : [1]}
	{CE : [1]}
	{conv1.c.c.y.run_sample_count : [1]}
	{conv2.c.c.b : [32 x 1]}
	{conv3.c.c.sc : [64 x 1]}
	{conv3.c.c.v : [64 x 1]}
	{conv3.c.W : [64 x 800]}
	{conv3.c.c.y.run_sample_count : [1]}
	{featOffs : [1 x 1]}
	{features : [32 x 32 x 3 x *1]}
	{h1.b : [64 x 1]}
	{h1.bn.run_sample_count : [1]}
	{h1.m : [64 x 1]}
	{h1.sc : [64 x 1]}
	{h1.v : [64 x 1]}
	{h1.W : [64 x 3 x 3 x 64]}
	{labels : [10 x *1]}
	{OutputNodes.b : [10]}
	{OutputNodes.W : [10 x 64]}

12/09/2017 10:56:59: Minibatch[1-500]: Err = 0.83775000 * 8000; CE = 3.11091136 * 8000
12/09/2017 10:56:59: Minibatch[501-625]: Err = 0.83450000 * 2000; CE = 3.07735031 * 2000
12/09/2017 10:56:59: Final Results: Minibatch[1-625]: Err = 0.83710000 * 10000; CE = 3.10419915 * 10000; perplexity = 22.29135977

12/09/2017 10:56:59: Action "test" complete.

12/09/2017 10:56:59: __COMPLETED__