CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/GettingStarted/01_OneHidden/../../../../../../Examples/Image/GettingStarted/01_OneHidden.cntk currentDirectory=/home/ubuntu/workspace/Examples/Image/DataSets/MNIST RunDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/GettingStarted_01_OneHidden@release_gpu DataDir=/home/ubuntu/workspace/Examples/Image/DataSets/MNIST ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/GettingStarted/01_OneHidden/../../../../../../Examples/Image/GettingStarted OutputDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/GettingStarted_01_OneHidden@release_gpu DeviceId=0 timestamping=true forceDeterministicAlgorithms=true stderr=- trainNetwork=[SGD=[maxEpochs=3]]
CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 10:58:23

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/GettingStarted/01_OneHidden/../../../../../../Examples/Image/GettingStarted/01_OneHidden.cntk  currentDirectory=/home/ubuntu/workspace/Examples/Image/DataSets/MNIST  RunDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/GettingStarted_01_OneHidden@release_gpu  DataDir=/home/ubuntu/workspace/Examples/Image/DataSets/MNIST  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/GettingStarted/01_OneHidden/../../../../../../Examples/Image/GettingStarted  OutputDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/GettingStarted_01_OneHidden@release_gpu  DeviceId=0  timestamping=true  forceDeterministicAlgorithms=true  stderr=-  trainNetwork=[SGD=[maxEpochs=3]]
Changed current directory to /home/ubuntu/workspace/Examples/Image/DataSets/MNIST
12/09/2017 10:58:23: Redirecting stderr to file -_trainNetwork_testNetwork.log
12/09/2017 10:58:23: -------------------------------------------------------------------
12/09/2017 10:58:23: Build info: 

12/09/2017 10:58:23: 		Built time: Dec  8 2017 01:46:20
12/09/2017 10:58:23: 		Last modified date: Wed Nov 15 09:27:10 2017
12/09/2017 10:58:23: 		Build type: release
12/09/2017 10:58:23: 		Build target: GPU
12/09/2017 10:58:23: 		With 1bit-SGD: yes
12/09/2017 10:58:23: 		With ASGD: yes
12/09/2017 10:58:23: 		Math lib: mkl
12/09/2017 10:58:23: 		CUDA version: 9.0.0
12/09/2017 10:58:23: 		CUDNN version: 7.0.4
12/09/2017 10:58:23: 		Build Branch: HEAD
12/09/2017 10:58:23: 		Build SHA1: b130d7735044ce6697bfb963af91445bee740c73
12/09/2017 10:58:23: 		MPI distribution: Open MPI
12/09/2017 10:58:23: 		MPI version: 1.10.7
12/09/2017 10:58:23: -------------------------------------------------------------------
12/09/2017 10:58:23: -------------------------------------------------------------------
12/09/2017 10:58:23: GPU info:

12/09/2017 10:58:23: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/09/2017 10:58:23: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: 01_OneHidden.cntk:command=trainNetwork:testNetwork
configparameters: 01_OneHidden.cntk:ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Examples/Image/GettingStarted/01_OneHidden/../../../../../../Examples/Image/GettingStarted
configparameters: 01_OneHidden.cntk:currentDirectory=/home/ubuntu/workspace/Examples/Image/DataSets/MNIST
configparameters: 01_OneHidden.cntk:dataDir=/home/ubuntu/workspace/Examples/Image/DataSets/MNIST
configparameters: 01_OneHidden.cntk:deviceId=0
configparameters: 01_OneHidden.cntk:forceDeterministicAlgorithms=true
configparameters: 01_OneHidden.cntk:modelPath=/tmp/cntk-test-20171209080859.615414/Examples/Image/GettingStarted_01_OneHidden@release_gpu/Models/01_OneHidden
configparameters: 01_OneHidden.cntk:outputDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/GettingStarted_01_OneHidden@release_gpu
configparameters: 01_OneHidden.cntk:precision=float
configparameters: 01_OneHidden.cntk:rootDir=..
configparameters: 01_OneHidden.cntk:RunDir=/tmp/cntk-test-20171209080859.615414/Examples/Image/GettingStarted_01_OneHidden@release_gpu
configparameters: 01_OneHidden.cntk:stderr=-
configparameters: 01_OneHidden.cntk:testNetwork={
    action = "test"
minibatchSize = 1024    
    reader = {
        readerType = "CNTKTextFormatReader"
        file = "/home/ubuntu/workspace/Examples/Image/DataSets/MNIST/Test-28x28_cntk_text.txt"
        input = {
            features = { dim = 784 ; format = "dense" }
            labels =   { dim = 10  ; format = "dense" }
        }
    }
}

configparameters: 01_OneHidden.cntk:timestamping=true
configparameters: 01_OneHidden.cntk:traceLevel=1
configparameters: 01_OneHidden.cntk:trainNetwork={
    action = "train"
    BrainScriptNetworkBuilder = {
imageShape = 28:28:1                        
labelDim = 10                               
        featScale = 1/256
        model(x) = {
            s1 = x * featScale
            h1 = DenseLayer {200, activation=ReLU} (s1) 
            z = LinearLayer {labelDim} (h1)
        }
        features = Input {imageShape}
        labels = Input {labelDim}
        out = model (features)
        ce   = CrossEntropyWithSoftmax (labels, out.z)
        errs = ClassificationError (labels, out.z)
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (errs)
        outputNodes     = (out.z)
    }
    SGD = {
        epochSize = 60000
        minibatchSize = 64
        maxEpochs = 10
        learningRatesPerSample = 0.01*5:0.005
        momentumAsTimeConstant = 0
        numMBsToShowResult = 500
    }
    reader = {
        readerType = "CNTKTextFormatReader"
        file = "/home/ubuntu/workspace/Examples/Image/DataSets/MNIST/Train-28x28_cntk_text.txt"
        input = {
            features = { dim = 784 ; format = "dense" }
            labels =   { dim = 10  ; format = "dense" }
        }
    }   
} [SGD=[maxEpochs=3]]

12/09/2017 10:58:23: Commands: trainNetwork testNetwork
12/09/2017 10:58:23: precision = "float"
12/09/2017 10:58:23: WARNING: forceDeterministicAlgorithms flag is specified. Using 1 CPU thread for processing.

12/09/2017 10:58:23: ##############################################################################
12/09/2017 10:58:23: #                                                                            #
12/09/2017 10:58:23: # trainNetwork command (train action)                                        #
12/09/2017 10:58:23: #                                                                            #
12/09/2017 10:58:23: ##############################################################################

12/09/2017 10:58:23: 
Creating virgin network.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[10 x 0] as glorotUniform later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[200 x 0] as glorotUniform later when dimensions are fully known.

Post-processing network...

3 roots:
	ce = CrossEntropyWithSoftmax()
	errs = ClassificationError()
	out.z = Plus()

Validating network. 15 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [10 x *]
Validating --> out.z.W = LearnableParameter() :  -> [10 x 0]
Validating --> out.h1.arrayOfFunctions[0].W = LearnableParameter() :  -> [200 x 0]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *]
Validating --> _out.s1 = LearnableParameter() :  -> [1]
Validating --> out.s1 = ElementTimes (features, _out.s1) : [28 x 28 x 1 x *], [1] -> [28 x 28 x 1 x *]
Node 'out.h1.arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [200 x 28 x 28 x 1].
Node 'out.h1.arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[200 x 28 x 28 x 1] <- glorotUniform(seed=2, init dims=[200 x 784], range=0.078087(0.078087*1.000000), onCPU=true.
)Validating --> out.h1._.PlusArgs[0] = Times (out.h1.arrayOfFunctions[0].W, out.s1) : [200 x 28 x 28 x 1], [28 x 28 x 1 x *] -> [200 x *]
Validating --> out.h1.arrayOfFunctions[0].b = LearnableParameter() :  -> [200]
Validating --> out.h1._ = Plus (out.h1._.PlusArgs[0], out.h1.arrayOfFunctions[0].b) : [200 x *], [200] -> [200 x *]
Validating --> out.h1 = RectifiedLinear (out.h1._) : [200 x *] -> [200 x *]
Node 'out.z.W' (LearnableParameter operation) operation: Tensor shape was inferred as [10 x 200].
Node 'out.z.W' (LearnableParameter operation): Initializing Parameter[10 x 200] <- glorotUniform(seed=1, init dims=[10 x 200], range=0.169031(0.169031*1.000000), onCPU=true.
)Validating --> out.z.PlusArgs[0] = Times (out.z.W, out.h1) : [10 x 200], [200 x *] -> [10 x *]
Validating --> out.z.b = LearnableParameter() :  -> [10]
Validating --> out.z = Plus (out.z.PlusArgs[0], out.z.b) : [10 x *], [10] -> [10 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, out.z) : [10 x *], [10 x *] -> [1]
Validating --> errs = ClassificationError (labels, out.z) : [10 x *], [10 x *] -> [1]

Validating network. 8 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.

12/09/2017 10:58:23: 
Model has 15 nodes. Using GPU 0.

12/09/2017 10:58:23: Training criterion:   ce = CrossEntropyWithSoftmax
12/09/2017 10:58:23: Evaluation criterion: errs = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 4 are aliased.
	out.h1._.PlusArgs[0] (gradient) reuses out.h1._ (gradient)
	out.z.PlusArgs[0] (gradient) reuses out.z (gradient)

Memory Sharing: Out of 25 matrices, 12 are shared as 3, and 13 are not shared.

Here are the ones that share memory:
	{ out.h1._ : [200 x *] (gradient)
	  out.h1._.PlusArgs[0] : [200 x *]
	  out.h1._.PlusArgs[0] : [200 x *] (gradient)
	  out.z : [10 x *] (gradient)
	  out.z.PlusArgs[0] : [10 x *]
	  out.z.PlusArgs[0] : [10 x *] (gradient) }
	{ out.h1 : [200 x *] (gradient)
	  out.h1._ : [200 x *]
	  out.h1.arrayOfFunctions[0].W : [200 x 28 x 28 x 1] (gradient)
	  out.z : [10 x *] }
	{ out.h1 : [200 x *]
	  out.h1.arrayOfFunctions[0].b : [200] (gradient) }

Here are the ones that don't share memory:
	{out.z.W : [10 x 200]}
	{out.h1.arrayOfFunctions[0].b : [200]}
	{_out.s1 : [1]}
	{features : [28 x 28 x 1 x *]}
	{out.h1.arrayOfFunctions[0].W : [200 x 28 x 28 x 1]}
	{out.z.b : [10]}
	{out.z.W : [10 x 200] (gradient)}
	{errs : [1]}
	{ce : [1] (gradient)}
	{out.s1 : [28 x 28 x 1 x *]}
	{out.z.b : [10] (gradient)}
	{labels : [10 x *]}
	{ce : [1]}


12/09/2017 10:58:23: Training 159010 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

12/09/2017 10:58:23: 	Node 'out.h1.arrayOfFunctions[0].W' (LearnableParameter operation) : [200 x 28 x 28 x 1]
12/09/2017 10:58:23: 	Node 'out.h1.arrayOfFunctions[0].b' (LearnableParameter operation) : [200]
12/09/2017 10:58:23: 	Node 'out.z.W' (LearnableParameter operation) : [10 x 200]
12/09/2017 10:58:23: 	Node 'out.z.b' (LearnableParameter operation) : [10]

12/09/2017 10:58:23: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/09/2017 10:58:23: Starting Epoch 1: learning rate per sample = 0.010000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

12/09/2017 10:58:23: Starting minibatch loop.
12/09/2017 10:58:25:  Epoch[ 1 of 3]-Minibatch[   1- 500, 53.33%]: ce = 0.30729382 * 32000; errs = 9.516% * 32000; time = 1.8748s; samplesPerSecond = 17068.2
12/09/2017 10:58:25: Finished Epoch[ 1 of 3]: [Training] ce = 0.22720059 * 60000; errs = 6.982% * 60000; totalSamplesSeen = 60000; learningRatePerSample = 0.0099999998; epochTime=2.11908s
12/09/2017 10:58:25: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Examples/Image/GettingStarted_01_OneHidden@release_gpu/Models/01_OneHidden.1'

12/09/2017 10:58:25: Starting Epoch 2: learning rate per sample = 0.010000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

12/09/2017 10:58:25: Starting minibatch loop.
12/09/2017 10:58:26:  Epoch[ 2 of 3]-Minibatch[   1- 500, 53.33%]: ce = 0.09341621 * 32000; errs = 2.859% * 32000; time = 0.2784s; samplesPerSecond = 114930.9
12/09/2017 10:58:26: Finished Epoch[ 2 of 3]: [Training] ce = 0.09241722 * 60000; errs = 2.838% * 60000; totalSamplesSeen = 120000; learningRatePerSample = 0.0099999998; epochTime=0.533725s
12/09/2017 10:58:26: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Examples/Image/GettingStarted_01_OneHidden@release_gpu/Models/01_OneHidden.2'

12/09/2017 10:58:26: Starting Epoch 3: learning rate per sample = 0.010000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

12/09/2017 10:58:26: Starting minibatch loop.
12/09/2017 10:58:26:  Epoch[ 3 of 3]-Minibatch[   1- 500, 53.33%]: ce = 0.06297770 * 32000; errs = 2.028% * 32000; time = 0.2750s; samplesPerSecond = 116365.5
12/09/2017 10:58:26: Finished Epoch[ 3 of 3]: [Training] ce = 0.06358307 * 60000; errs = 2.028% * 60000; totalSamplesSeen = 180000; learningRatePerSample = 0.0099999998; epochTime=0.525038s
12/09/2017 10:58:26: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Examples/Image/GettingStarted_01_OneHidden@release_gpu/Models/01_OneHidden'

12/09/2017 10:58:26: Action "train" complete.


12/09/2017 10:58:26: ##############################################################################
12/09/2017 10:58:26: #                                                                            #
12/09/2017 10:58:26: # testNetwork command (test action)                                          #
12/09/2017 10:58:26: #                                                                            #
12/09/2017 10:58:26: ##############################################################################


Post-processing network...

3 roots:
	ce = CrossEntropyWithSoftmax()
	errs = ClassificationError()
	out.z = Plus()

Validating network. 15 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [10 x *1]
Validating --> out.z.W = LearnableParameter() :  -> [10 x 200]
Validating --> out.h1.arrayOfFunctions[0].W = LearnableParameter() :  -> [200 x 28 x 28 x 1]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *1]
Validating --> _out.s1 = LearnableParameter() :  -> [1]
Validating --> out.s1 = ElementTimes (features, _out.s1) : [28 x 28 x 1 x *1], [1] -> [28 x 28 x 1 x *1]
Validating --> out.h1._.PlusArgs[0] = Times (out.h1.arrayOfFunctions[0].W, out.s1) : [200 x 28 x 28 x 1], [28 x 28 x 1 x *1] -> [200 x *1]
Validating --> out.h1.arrayOfFunctions[0].b = LearnableParameter() :  -> [200]
Validating --> out.h1._ = Plus (out.h1._.PlusArgs[0], out.h1.arrayOfFunctions[0].b) : [200 x *1], [200] -> [200 x *1]
Validating --> out.h1 = RectifiedLinear (out.h1._) : [200 x *1] -> [200 x *1]
Validating --> out.z.PlusArgs[0] = Times (out.z.W, out.h1) : [10 x 200], [200 x *1] -> [10 x *1]
Validating --> out.z.b = LearnableParameter() :  -> [10]
Validating --> out.z = Plus (out.z.PlusArgs[0], out.z.b) : [10 x *1], [10] -> [10 x *1]
Validating --> ce = CrossEntropyWithSoftmax (labels, out.z) : [10 x *1], [10 x *1] -> [1]
Validating --> errs = ClassificationError (labels, out.z) : [10 x *1], [10 x *1] -> [1]

Validating network. 8 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 15 matrices, 6 are shared as 2, and 9 are not shared.

Here are the ones that share memory:
	{ out.h1._ : [200 x *1]
	  out.s1 : [28 x 28 x 1 x *1]
	  out.z.PlusArgs[0] : [10 x *1] }
	{ out.h1 : [200 x *1]
	  out.h1._.PlusArgs[0] : [200 x *1]
	  out.z : [10 x *1] }

Here are the ones that don't share memory:
	{features : [28 x 28 x 1 x *1]}
	{labels : [10 x *1]}
	{out.h1.arrayOfFunctions[0].b : [200]}
	{_out.s1 : [1]}
	{errs : [1]}
	{out.z.b : [10]}
	{out.h1.arrayOfFunctions[0].W : [200 x 28 x 28 x 1]}
	{out.z.W : [10 x 200]}
	{ce : [1]}

12/09/2017 10:58:27: Minibatch[1-10]: errs = 2.660% * 10000; ce = 0.07977878 * 10000
12/09/2017 10:58:27: Final Results: Minibatch[1-10]: errs = 2.660% * 10000; ce = 0.07977878 * 10000; perplexity = 1.08304745

12/09/2017 10:58:27: Action "test" complete.

12/09/2017 10:58:27: __COMPLETED__