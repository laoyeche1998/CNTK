CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E/cntk.cntk currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data RunDir=/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E OutputDir=/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu DeviceId=0 timestamping=true
CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 11:38:21

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E/cntk.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data  RunDir=/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E  OutputDir=/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu  DeviceId=0  timestamping=true
Changed current directory to /home/ubuntu/workspace/Tests/EndToEndTests/Image/Data
12/09/2017 11:38:21: -------------------------------------------------------------------
12/09/2017 11:38:21: Build info: 

12/09/2017 11:38:21: 		Built time: Dec  8 2017 01:46:20
12/09/2017 11:38:21: 		Last modified date: Wed Nov 15 09:27:10 2017
12/09/2017 11:38:21: 		Build type: release
12/09/2017 11:38:21: 		Build target: GPU
12/09/2017 11:38:21: 		With 1bit-SGD: yes
12/09/2017 11:38:21: 		With ASGD: yes
12/09/2017 11:38:21: 		Math lib: mkl
12/09/2017 11:38:21: 		CUDA version: 9.0.0
12/09/2017 11:38:21: 		CUDNN version: 7.0.4
12/09/2017 11:38:21: 		Build Branch: HEAD
12/09/2017 11:38:21: 		Build SHA1: b130d7735044ce6697bfb963af91445bee740c73
12/09/2017 11:38:21: 		MPI distribution: Open MPI
12/09/2017 11:38:21: 		MPI version: 1.10.7
12/09/2017 11:38:21: -------------------------------------------------------------------
12/09/2017 11:38:21: -------------------------------------------------------------------
12/09/2017 11:38:21: GPU info:

12/09/2017 11:38:21: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/09/2017 11:38:21: -------------------------------------------------------------------
12/09/2017 11:38:21: Using 6 CPU threads.

12/09/2017 11:38:21: ##############################################################################
12/09/2017 11:38:21: #                                                                            #
12/09/2017 11:38:21: # train command (train action)                                               #
12/09/2017 11:38:21: #                                                                            #
12/09/2017 11:38:21: ##############################################################################

parallelTrain option is not enabled. ParallelTrain config will be ignored.
12/09/2017 11:38:21: 
Creating virgin network.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[128 x 0] as uniform later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[10 x 0] as uniform later when dimensions are fully known.

Post-processing network...

2 roots:
	ce = CrossEntropyWithSoftmax()
	err = ClassificationError()

Validating network. 28 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [10 x *]
Validating --> ol.W = LearnableParameter() :  -> [10 x 0]
Validating --> h1.W = LearnableParameter() :  -> [128 x 0]
Validating --> conv2_act.convW = LearnableParameter() :  -> [32 x 400]
Validating --> conv1_act.convW = LearnableParameter() :  -> [16 x 25]
Validating --> featScale = LearnableParameter() :  -> [1 x 1]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *]
Validating --> featScaled = ElementTimes (featScale, features) : [1 x 1], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> conv1_act.conv = Convolution (conv1_act.convW, featScaled) : [16 x 25], [28 x 28 x 1 x *] -> [24 x 24 x 16 x *]
Validating --> conv1_act.convB = LearnableParameter() :  -> [1 x 1 x 16]
Validating --> conv1_act.convPlusB = Plus (conv1_act.conv, conv1_act.convB) : [24 x 24 x 16 x *], [1 x 1 x 16] -> [24 x 24 x 16 x *]
Validating --> conv1_act = RectifiedLinear (conv1_act.convPlusB) : [24 x 24 x 16 x *] -> [24 x 24 x 16 x *]
Validating --> pool1 = MaxPooling (conv1_act) : [24 x 24 x 16 x *] -> [12 x 12 x 16 x *]
Validating --> conv2_act.conv = Convolution (conv2_act.convW, pool1) : [32 x 400], [12 x 12 x 16 x *] -> [8 x 8 x 32 x *]
Validating --> conv2_act.convB = LearnableParameter() :  -> [1 x 1 x 32]
Validating --> conv2_act.convPlusB = Plus (conv2_act.conv, conv2_act.convB) : [8 x 8 x 32 x *], [1 x 1 x 32] -> [8 x 8 x 32 x *]
Validating --> conv2_act = RectifiedLinear (conv2_act.convPlusB) : [8 x 8 x 32 x *] -> [8 x 8 x 32 x *]
Validating --> pool2 = AveragePooling (conv2_act) : [8 x 8 x 32 x *] -> [4 x 4 x 32 x *]
Validating --> h1.x = Reshape (pool2) : [4 x 4 x 32 x *] -> [512 x *]
Node 'h1.W' (LearnableParameter operation) operation: Tensor shape was inferred as [128 x 512].
Node 'h1.W' (LearnableParameter operation): Initializing Parameter[128 x 512] <- uniform(seed=3, init dims=[128 x 512], range=0.050000(0.050000*1.000000), onCPU=true.
)Validating --> h1.z.PlusArgs[0] = Times (h1.W, h1.x) : [128 x 512], [512 x *] -> [128 x *]
Validating --> h1.b = LearnableParameter() :  -> [128]
Validating --> h1.z = Plus (h1.z.PlusArgs[0], h1.b) : [128 x *], [128] -> [128 x *]
Validating --> h1 = Sigmoid (h1.z) : [128 x *] -> [128 x *]
Node 'ol.W' (LearnableParameter operation) operation: Tensor shape was inferred as [10 x 128].
Node 'ol.W' (LearnableParameter operation): Initializing Parameter[10 x 128] <- uniform(seed=5, init dims=[10 x 128], range=0.050000(0.050000*1.000000), onCPU=true.
)Validating --> ol.out.PlusArgs[0] = Times (ol.W, h1) : [10 x 128], [128 x *] -> [10 x *]
Validating --> ol.b = LearnableParameter() :  -> [10 x 1]
Validating --> ol = Plus (ol.out.PlusArgs[0], ol.b) : [10 x *], [10 x 1] -> [10 x 1 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, ol) : [10 x *], [10 x 1 x *] -> [1]
Validating --> err = ClassificationError (labels, ol) : [10 x *], [10 x 1 x *] -> [1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.

12/09/2017 11:38:22: 
Model has 28 nodes. Using GPU 0.

12/09/2017 11:38:22: Training criterion:   ce = CrossEntropyWithSoftmax
12/09/2017 11:38:22: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 8 are aliased.
	conv1_act.conv (gradient) reuses conv1_act.convPlusB (gradient)
	h1.z.PlusArgs[0] (gradient) reuses h1.z (gradient)
	conv2_act.conv (gradient) reuses conv2_act.convPlusB (gradient)
	pool2 (gradient) reuses h1.x (gradient)

Memory Sharing: Out of 51 matrices, 33 are shared as 9, and 18 are not shared.

Here are the ones that share memory:
	{ conv2_act.convB : [1 x 1 x 32] (gradient)
	  h1 : [128 x *] (gradient)
	  h1.x : [512 x *] (gradient)
	  h1.z : [128 x *]
	  ol : [10 x 1 x *]
	  pool2 : [4 x 4 x 32 x *] (gradient) }
	{ conv1_act : [24 x 24 x 16 x *]
	  conv1_act.conv : [24 x 24 x 16 x *]
	  conv1_act.convW : [16 x 25] (gradient) }
	{ conv1_act.conv : [24 x 24 x 16 x *] (gradient)
	  conv1_act.convPlusB : [24 x 24 x 16 x *]
	  conv1_act.convPlusB : [24 x 24 x 16 x *] (gradient)
	  pool1 : [12 x 12 x 16 x *] }
	{ conv2_act.conv : [8 x 8 x 32 x *] (gradient)
	  conv2_act.convPlusB : [8 x 8 x 32 x *] (gradient)
	  h1.x : [512 x *] }
	{ conv1_act : [24 x 24 x 16 x *] (gradient)
	  conv1_act.convB : [1 x 1 x 16] (gradient)
	  conv2_act : [8 x 8 x 32 x *] (gradient)
	  conv2_act.convPlusB : [8 x 8 x 32 x *]
	  h1 : [128 x *]
	  h1.z.PlusArgs[0] : [128 x *] }
	{ h1.W : [128 x 512] (gradient)
	  ol : [10 x 1 x *] (gradient) }
	{ h1.z : [128 x *] (gradient)
	  h1.z.PlusArgs[0] : [128 x *] (gradient)
	  ol.out.PlusArgs[0] : [10 x *]
	  ol.out.PlusArgs[0] : [10 x *] (gradient) }
	{ conv2_act : [8 x 8 x 32 x *]
	  conv2_act.conv : [8 x 8 x 32 x *]
	  pool1 : [12 x 12 x 16 x *] (gradient) }
	{ conv2_act.convW : [32 x 400] (gradient)
	  pool2 : [4 x 4 x 32 x *] }

Here are the ones that don't share memory:
	{featScaled : [28 x 28 x 1 x *]}
	{ol.W : [10 x 128] (gradient)}
	{ce : [1] (gradient)}
	{ol.b : [10 x 1] (gradient)}
	{h1.b : [128] (gradient)}
	{featScale : [1 x 1]}
	{features : [28 x 28 x 1 x *]}
	{labels : [10 x *]}
	{conv2_act.convW : [32 x 400]}
	{h1.W : [128 x 512]}
	{h1.b : [128]}
	{err : [1]}
	{ce : [1]}
	{conv1_act.convB : [1 x 1 x 16]}
	{ol.W : [10 x 128]}
	{ol.b : [10 x 1]}
	{conv2_act.convB : [1 x 1 x 32]}
	{conv1_act.convW : [16 x 25]}


12/09/2017 11:38:22: Training 80202 parameters in 8 out of 8 parameter tensors and 23 nodes with gradient:

12/09/2017 11:38:22: 	Node 'conv1_act.convB' (LearnableParameter operation) : [1 x 1 x 16]
12/09/2017 11:38:22: 	Node 'conv1_act.convW' (LearnableParameter operation) : [16 x 25]
12/09/2017 11:38:22: 	Node 'conv2_act.convB' (LearnableParameter operation) : [1 x 1 x 32]
12/09/2017 11:38:22: 	Node 'conv2_act.convW' (LearnableParameter operation) : [32 x 400]
12/09/2017 11:38:22: 	Node 'h1.W' (LearnableParameter operation) : [128 x 512]
12/09/2017 11:38:22: 	Node 'h1.b' (LearnableParameter operation) : [128]
12/09/2017 11:38:22: 	Node 'ol.W' (LearnableParameter operation) : [10 x 128]
12/09/2017 11:38:22: 	Node 'ol.b' (LearnableParameter operation) : [10 x 1]

12/09/2017 11:38:22: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/09/2017 11:38:22: Starting Epoch 1: learning rate per sample = 0.000002  effective momentum = 0.904837  momentum as time constant = 1000.0 samples

12/09/2017 11:38:22: Starting minibatch loop.
12/09/2017 11:38:23:  Epoch[ 1 of 5]-Minibatch[   1-  10, 100.00%]: ce = 2.33338428 * 1000; err = 0.90000000 * 1000; time = 0.9008s; samplesPerSecond = 1110.2
12/09/2017 11:38:23: Finished Epoch[ 1 of 5]: [Training] ce = 2.33338428 * 1000; err = 0.90000000 * 1000; totalSamplesSeen = 1000; learningRatePerSample = 2e-06; epochTime=0.90163s
12/09/2017 11:38:23: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu/models/cntk.dnn.1'

12/09/2017 11:38:23: Starting Epoch 2: learning rate per sample = 0.000002  effective momentum = 0.904837  momentum as time constant = 1000.0 samples

12/09/2017 11:38:23: Starting minibatch loop.
12/09/2017 11:38:23:  Epoch[ 2 of 5]-Minibatch[   1-  10, 100.00%]: ce = 2.33235547 * 1000; err = 0.90000000 * 1000; time = 0.1125s; samplesPerSecond = 8889.0
12/09/2017 11:38:23: Finished Epoch[ 2 of 5]: [Training] ce = 2.33235547 * 1000; err = 0.90000000 * 1000; totalSamplesSeen = 2000; learningRatePerSample = 2e-06; epochTime=0.113123s
12/09/2017 11:38:23: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu/models/cntk.dnn.2'

12/09/2017 11:38:23: Starting Epoch 3: learning rate per sample = 0.000002  effective momentum = 0.904837  momentum as time constant = 1000.0 samples

12/09/2017 11:38:23: Starting minibatch loop.
12/09/2017 11:38:23:  Epoch[ 3 of 5]-Minibatch[   1-  10, 100.00%]: ce = 2.33108008 * 1000; err = 0.90000000 * 1000; time = 0.0343s; samplesPerSecond = 29143.8
12/09/2017 11:38:23: Finished Epoch[ 3 of 5]: [Training] ce = 2.33108008 * 1000; err = 0.90000000 * 1000; totalSamplesSeen = 3000; learningRatePerSample = 2e-06; epochTime=0.0347934s
12/09/2017 11:38:23: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu/models/cntk.dnn.3'

12/09/2017 11:38:23: Starting Epoch 4: learning rate per sample = 0.000002  effective momentum = 0.904837  momentum as time constant = 1000.0 samples

12/09/2017 11:38:23: Starting minibatch loop.
12/09/2017 11:38:23:  Epoch[ 4 of 5]-Minibatch[   1-  10, 100.00%]: ce = 2.32960474 * 1000; err = 0.90000000 * 1000; time = 0.0197s; samplesPerSecond = 50660.1
12/09/2017 11:38:23: Finished Epoch[ 4 of 5]: [Training] ce = 2.32960474 * 1000; err = 0.90000000 * 1000; totalSamplesSeen = 4000; learningRatePerSample = 2e-06; epochTime=0.0206262s
12/09/2017 11:38:23: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu/models/cntk.dnn.4'

12/09/2017 11:38:23: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.904837  momentum as time constant = 1000.0 samples

12/09/2017 11:38:23: Starting minibatch loop.
12/09/2017 11:38:23:  Epoch[ 5 of 5]-Minibatch[   1-  10, 100.00%]: ce = 2.32814063 * 1000; err = 0.90000000 * 1000; time = 0.0200s; samplesPerSecond = 50001.0
12/09/2017 11:38:23: Finished Epoch[ 5 of 5]: [Training] ce = 2.32814063 * 1000; err = 0.90000000 * 1000; totalSamplesSeen = 5000; learningRatePerSample = 2e-06; epochTime=0.0208649s
12/09/2017 11:38:23: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu/models/cntk.dnn'

12/09/2017 11:38:23: Action "train" complete.


12/09/2017 11:38:23: ##############################################################################
12/09/2017 11:38:23: #                                                                            #
12/09/2017 11:38:23: # test command (test action)                                                 #
12/09/2017 11:38:23: #                                                                            #
12/09/2017 11:38:23: ##############################################################################

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.
12/09/2017 11:38:23: Final Results: Minibatch[1-1]: err = 0.90000000 * 100; ce = 2.32728546 * 100; perplexity = 10.25007950

12/09/2017 11:38:23: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E/cntk.cntk currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data RunDir=/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E OutputDir=/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu DeviceId=0 timestamping=true makeMode=true
CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 11:38:23

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E/cntk.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data  RunDir=/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/QuickE2E  OutputDir=/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu  DeviceId=0  timestamping=true  makeMode=true
Changed current directory to /home/ubuntu/workspace/Tests/EndToEndTests/Image/Data
12/09/2017 11:38:23: -------------------------------------------------------------------
12/09/2017 11:38:23: Build info: 

12/09/2017 11:38:23: 		Built time: Dec  8 2017 01:46:20
12/09/2017 11:38:23: 		Last modified date: Wed Nov 15 09:27:10 2017
12/09/2017 11:38:23: 		Build type: release
12/09/2017 11:38:23: 		Build target: GPU
12/09/2017 11:38:23: 		With 1bit-SGD: yes
12/09/2017 11:38:23: 		With ASGD: yes
12/09/2017 11:38:23: 		Math lib: mkl
12/09/2017 11:38:23: 		CUDA version: 9.0.0
12/09/2017 11:38:23: 		CUDNN version: 7.0.4
12/09/2017 11:38:23: 		Build Branch: HEAD
12/09/2017 11:38:23: 		Build SHA1: b130d7735044ce6697bfb963af91445bee740c73
12/09/2017 11:38:23: 		MPI distribution: Open MPI
12/09/2017 11:38:23: 		MPI version: 1.10.7
12/09/2017 11:38:23: -------------------------------------------------------------------
12/09/2017 11:38:23: -------------------------------------------------------------------
12/09/2017 11:38:23: GPU info:

12/09/2017 11:38:23: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/09/2017 11:38:23: -------------------------------------------------------------------
12/09/2017 11:38:23: Using 6 CPU threads.

12/09/2017 11:38:23: ##############################################################################
12/09/2017 11:38:23: #                                                                            #
12/09/2017 11:38:23: # train command (train action)                                               #
12/09/2017 11:38:23: #                                                                            #
12/09/2017 11:38:23: ##############################################################################

parallelTrain option is not enabled. ParallelTrain config will be ignored.
12/09/2017 11:38:23: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu/models/cntk.dnn.4'.
12/09/2017 11:38:24: 
Model has 28 nodes. Using GPU 0.

12/09/2017 11:38:24: Training criterion:   ce = CrossEntropyWithSoftmax
12/09/2017 11:38:24: Evaluation criterion: err = ClassificationError

12/09/2017 11:38:24: Training 80202 parameters in 8 out of 8 parameter tensors and 23 nodes with gradient:

12/09/2017 11:38:24: 	Node 'conv1_act.convB' (LearnableParameter operation) : [1 x 1 x 16]
12/09/2017 11:38:24: 	Node 'conv1_act.convW' (LearnableParameter operation) : [16 x 25]
12/09/2017 11:38:24: 	Node 'conv2_act.convB' (LearnableParameter operation) : [1 x 1 x 32]
12/09/2017 11:38:24: 	Node 'conv2_act.convW' (LearnableParameter operation) : [32 x 400]
12/09/2017 11:38:24: 	Node 'h1.W' (LearnableParameter operation) : [128 x 512]
12/09/2017 11:38:24: 	Node 'h1.b' (LearnableParameter operation) : [128]
12/09/2017 11:38:24: 	Node 'ol.W' (LearnableParameter operation) : [10 x 128]
12/09/2017 11:38:24: 	Node 'ol.b' (LearnableParameter operation) : [10 x 1]

12/09/2017 11:38:24: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/09/2017 11:38:24: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.904837  momentum as time constant = 1000.0 samples

12/09/2017 11:38:24: Starting minibatch loop.
12/09/2017 11:38:24:  Epoch[ 5 of 5]-Minibatch[   1-  10, 100.00%]: ce = 2.32814063 * 1000; err = 0.90000000 * 1000; time = 0.2313s; samplesPerSecond = 4323.5
12/09/2017 11:38:24: Finished Epoch[ 5 of 5]: [Training] ce = 2.32814063 * 1000; err = 0.90000000 * 1000; totalSamplesSeen = 5000; learningRatePerSample = 2e-06; epochTime=0.232085s
12/09/2017 11:38:24: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Image_QuickE2E@release_gpu/models/cntk.dnn'

12/09/2017 11:38:24: Action "train" complete.


12/09/2017 11:38:24: ##############################################################################
12/09/2017 11:38:24: #                                                                            #
12/09/2017 11:38:24: # test command (test action)                                                 #
12/09/2017 11:38:24: #                                                                            #
12/09/2017 11:38:24: ##############################################################################

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.
12/09/2017 11:38:24: Final Results: Minibatch[1-1]: err = 0.90000000 * 100; ce = 2.32728546 * 100; perplexity = 10.25007950

12/09/2017 11:38:24: __COMPLETED__