CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Preparing training and test data
=== Running training
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN/fcn.cntk currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data RunDir=/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN OutputDir=/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu DeviceId=0 timestamping=true
CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 11:38:18

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN/fcn.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data  RunDir=/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN  OutputDir=/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu  DeviceId=0  timestamping=true
Changed current directory to /home/ubuntu/workspace/Tests/EndToEndTests/Image/Data
--------------------------------------------------------------------------
[[23277,1],0]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: 4bb8be993ee1

Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
ping [requestnodes (before change)]: 1 nodes pinging each other
ping [requestnodes (after change)]: 1 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 1 out of 1 MPI nodes on a single host (1 requested); we (0) are in (participating)
ping [mpihelper]: 1 nodes pinging each other
12/09/2017 11:38:18: -------------------------------------------------------------------
12/09/2017 11:38:18: Build info: 

12/09/2017 11:38:18: 		Built time: Dec  8 2017 01:46:20
12/09/2017 11:38:18: 		Last modified date: Wed Nov 15 09:27:10 2017
12/09/2017 11:38:18: 		Build type: release
12/09/2017 11:38:18: 		Build target: GPU
12/09/2017 11:38:18: 		With 1bit-SGD: yes
12/09/2017 11:38:18: 		With ASGD: yes
12/09/2017 11:38:18: 		Math lib: mkl
12/09/2017 11:38:18: 		CUDA version: 9.0.0
12/09/2017 11:38:18: 		CUDNN version: 7.0.4
12/09/2017 11:38:18: 		Build Branch: HEAD
12/09/2017 11:38:18: 		Build SHA1: b130d7735044ce6697bfb963af91445bee740c73
12/09/2017 11:38:18: 		MPI distribution: Open MPI
12/09/2017 11:38:18: 		MPI version: 1.10.7
12/09/2017 11:38:18: -------------------------------------------------------------------
12/09/2017 11:38:18: -------------------------------------------------------------------
12/09/2017 11:38:18: GPU info:

12/09/2017 11:38:18: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/09/2017 11:38:18: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: fcn.cntk:ClassCount=2
configparameters: fcn.cntk:command=TrainFCN8:ConvertFCN8ToFCN4:TrainFCN4:PrepareFCN4ForTest:TestFCN4
configparameters: fcn.cntk:ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN
configparameters: fcn.cntk:ConvertFCN8ToFCN4=[
    action = "edit"
    CurModel = "/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN8_train"
    NewModel = "/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_initial"
    editPath = "/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN/fcn8_to_fcn4.mel"
]

configparameters: fcn.cntk:currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data
configparameters: fcn.cntk:DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Image/Data
configparameters: fcn.cntk:deviceId=0
configparameters: fcn.cntk:Epochs=2
configparameters: fcn.cntk:FcnDataDir=/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Data
configparameters: fcn.cntk:FeatureChannels=16
configparameters: fcn.cntk:ImageChannels=1
configparameters: fcn.cntk:LrPerSample=0.01
configparameters: fcn.cntk:MbSize=16
configparameters: fcn.cntk:ModelDir=/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models
configparameters: fcn.cntk:MomentumTimeConstant=1215
configparameters: fcn.cntk:numMBsToShowResult=1
configparameters: fcn.cntk:OutputDir=/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu
configparameters: fcn.cntk:parallelTrain=true
configparameters: fcn.cntk:precision=float
configparameters: fcn.cntk:PrepareFCN4ForTest=[
    action = "edit"
    CurModel = "/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_train"
    NewModel = "/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_test"
    editPath = "/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN/prepare_for_test.mel"
    TestImageHeight = 28
    TestImageWidth = 28
    ImageChannels = 1
    ClassCount = 2
]

configparameters: fcn.cntk:RunDir=/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu
configparameters: fcn.cntk:TestDataFile=Test_cntk_fcn_text.txt
configparameters: fcn.cntk:TestFCN4=[
    action = test
    numMBsToShowResult = 20
    modelPath = "/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_test"
    minibatchSize = 16
distributedMBReading = "true" 
    BrainScriptNetworkBuilder = [
        m = BS.Network.Load("/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_test")
        evaluationNodes = (m.pixelwiseError:m.miouError)
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Data/Test_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
]

configparameters: fcn.cntk:TestFeaturesDim=784
configparameters: fcn.cntk:TestIgnoreDim=784
configparameters: fcn.cntk:TestImageHeight=28
configparameters: fcn.cntk:TestImageWidth=28
configparameters: fcn.cntk:TestLabelsDim=1568
configparameters: fcn.cntk:timestamping=true
configparameters: fcn.cntk:traceLevel=1
configparameters: fcn.cntk:TrainDataFile=Train_cntk_fcn_text.txt
configparameters: fcn.cntk:TrainFCN4=[
    action = "train"
    modelPath = "/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_train"
    saveBestModelPerCriterion = "true"
    BrainScriptNetworkBuilder = [
        include "/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN/shared.bs"
        classCount = 2
        featureChannels = 16
        inModel = BS.Network.Load("/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_initial")
        predictionFCN4 = ConvLayer1x1MSRAInit(inModel.featuresFCN4, featureChannels, classCount, 1, 1)
        upsampledFCN8 = LearnableUpsamplingLayer{classCount, classCount, 4, 2}(inModel.predictionFCN8)
        cropFCN8 = CropAutomatic(upsampledFCN8, predictionFCN4)
        fusionFCN4 = Plus(cropFCN8, predictionFCN4)
        upsampledFCN4 = BilinearUpsamplingLayer{classCount, 8, 4}(fusionFCN4)
        out = CropAutomaticGivenAncestors(upsampledFCN4, inModel.labels, inModel.features, inModel.labels)
        CE = CrossEntropyWithSoftmaxNDNormalized(inModel.labels, out, inModel.ignoreMask, axis = 3, tag = 'criterion')
        pixelwiseError = PixelError(inModel.labels, out, inModel.ignoreMask)
        miouError = MeanIOUError(inModel.labels, out, inModel.ignoreMask, classCount = classCount)
        featureNodes    = (inModel.features)
        labelNodes      = (inModel.labels)
        criterionNodes  = (CE)
        evaluationNodes = (pixelwiseError:miouError)
        outputNodes     = (out)
    ]
    SGD = [
        minibatchSize = 16
        learningRatesPerSample = 0.01
        momentumAsTimeConstant= 1215
        maxEpochs = 2
        gradUpdateType = "None"
        L2RegWeight = 0.00000390625
        dropoutRate = 0
        minLearningRatePerSample = 1e-15
disableWkInBatchNormal = "true" 
        ParallelTrain = [
            parallelizationMethod = "DataParallelSGD"
            distributedMBReading = "true"
            parallelizationStartEpoch = 1
            DataParallelSGD = [
                gradientBits = 32
            ]
        ]
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Data/Train_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
    cvReader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Data/Test_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
]

configparameters: fcn.cntk:TrainFCN8=[
    action = "train"
    modelPath = "/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN8_train"
    saveBestModelPerCriterion = "true"
    BrainScriptNetworkBuilder = [
        include "/home/ubuntu/workspace/Tests/EndToEndTests/Image/FCN/shared.bs"
        classCount = 2
        imageWidth = 28
        imageHeight = 28
        imageChannels = 1
        featureChannels = 16
        bnTimeConst = 15992
        features = ImageInput(imageWidth, imageHeight, imageChannels, imageLayout = "cudnn", tag = 'feature')
        labels = ImageInput(imageWidth, imageHeight, classCount, imageLayout = "cudnn", tag = 'label')
        ignoreMask = ImageInput(imageWidth, imageHeight, 1, imageLayout = "cudnn", tag = 'feature')
        featuresFCN4 = Sequential(
            ConvBNReLULayer{featureChannels, /*kernel*/ (7:7), /*stride*/ (2:2), bnTimeConst} :
            MaxPoolingLayer{(3:3), stride = 2, pad = true})(features)
        featuresFCN8 = Sequential(
            ResNetBasicInc{featureChannels, /*stride*/ (2:2), bnTimeConst} :
            ResNetBasic{featureChannels, bnTimeConst})(featuresFCN4)
        predictionFCN8 = ConvLayer1x1MSRAInit(featuresFCN8, featureChannels, classCount, 1, 1)
        upsampledFCN8 = BilinearUpsamplingLayer{classCount, 16, 8}(predictionFCN8)
        out = CropAutomaticGivenAncestors(upsampledFCN8, labels, features, labels)
        CE = CrossEntropyWithSoftmaxNDNormalized(labels, out, ignoreMask, axis = 3, tag = 'criterion')
        pixelwiseError = PixelError(labels, out, ignoreMask)
        miouError = MeanIOUError(labels, out, ignoreMask, classCount = classCount)
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (CE)
        evaluationNodes = (pixelwiseError:miouError)
        outputNodes     = (out)
    ]
    SGD = [
        minibatchSize = 16
        learningRatesPerSample = 0.01
        momentumAsTimeConstant = 1215
        maxEpochs = 2
        gradUpdateType = "None"
        L2RegWeight = 0.00000390625
        dropoutRate = 0
        minLearningRatePerSample = 1e-15
disableWkInBatchNormal = "true" 
        ParallelTrain = [
            parallelizationMethod = "DataParallelSGD"
            distributedMBReading = "true"
            parallelizationStartEpoch = 1
            DataParallelSGD = [
                gradientBits = 32
            ]
        ]
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Data/Train_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
    cvReader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Data/Test_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
]

configparameters: fcn.cntk:TrainFeaturesDim=784
configparameters: fcn.cntk:TrainIgnoreDim=784
configparameters: fcn.cntk:TrainImageHeight=28
configparameters: fcn.cntk:TrainImageWidth=28
configparameters: fcn.cntk:TrainLabelsDim=1568
configparameters: fcn.cntk:ValDataFile=Test_cntk_fcn_text.txt
configparameters: fcn.cntk:WeightDecay=0.00000390625
12/09/2017 11:38:18: Commands: TrainFCN8 ConvertFCN8ToFCN4 TrainFCN4 PrepareFCN4ForTest TestFCN4
12/09/2017 11:38:18: precision = "float"

12/09/2017 11:38:18: ##############################################################################
12/09/2017 11:38:18: #                                                                            #
12/09/2017 11:38:18: # TrainFCN8 command (train action)                                           #
12/09/2017 11:38:18: #                                                                            #
12/09/2017 11:38:18: ##############################################################################

12/09/2017 11:38:18: 
Creating virgin network.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[7 x 7 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[1 x 1 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.

Post-processing network...

4 roots:
	CE = ElementTimes()
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 108 nodes to process in pass 1.

Validating --> upsampledFCN8.W = LearnableParameter() :  -> [16 x 16 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 0 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *]
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [7 x 7 x 1 x 16].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[7 x 7 x 1 x 16] <- heNormal(seed=6, init dims=[784 x 49], range=0.202031(0.202031*1.000000), onCPU=true.
)Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *] -> [14 x 14 x 16 x *]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *] -> [14 x 14 x 16 x *]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *] -> [7 x 7 x 16 x *]
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=5, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=4, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 0 x 16]
Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [1 x 1 x 16 x 16].
Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[1 x 1 x 16 x 16] <- heNormal(seed=7, init dims=[16 x 16], range=0.353553(0.353553*1.000000), onCPU=true.
)Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=3, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=2, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 2 x *]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [16 x 16 x 2 x 2], [4 x 4 x 2 x *] -> [40 x 40 x 2 x *]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *]
Validating --> out = Crop (upsampledFCN8, labels, features, labels) : [40 x 40 x 2 x *], [28 x 28 x 2 x *], [28 x 28 x 1 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> CE.out_max.r = ReduceElements (out) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> CE.out_shift = Minus (out, CE.out_max.r) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> CE.log_sum.r = ReduceElements (CE.out_shift) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> CE.logits_per_class = ElementTimes (labels, CE.out_shift) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> CE.logits.r = ReduceElements (CE.logits_per_class) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> CE.diff = Minus (CE.log_sum.r, CE.logits.r) : [28 x 28 x 1 x *], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *]
Validating --> CE.diff_valid = ElementTimes (CE.diff, ignoreMask) : [28 x 28 x 1 x *], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> CE.ce_unnorm = SumElements (CE.diff_valid) : [28 x 28 x 1 x *] -> [1]
Validating --> CE.norm_factor.z = SumElements (ignoreMask) : [28 x 28 x 1 x *] -> [1]
Validating --> CE.norm_factor = Reciprocal (CE.norm_factor.z) : [1] -> [1]
Validating --> CE = ElementTimes (CE.ce_unnorm, CE.norm_factor) : [1], [1] -> [1]
Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *] -> [784 x 2 x *]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *] -> [1 x 2 x *]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *] -> [784 x 2 x *]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *] -> [1 x 2 x *]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *] -> [1 x *]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *] -> [1 x *]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *] -> [1 x *]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *], [1 x *] -> [1 x *]

Validating network. 64 nodes to process in pass 2.


Validating network, final pass.

featuresFCN4.x._.x.c: using cuDNN convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using cuDNN convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using cuDNN convolution engine for geometry: Input: 40 x 40 x 2, Output: 4 x 4 x 2, Kernel: 16 x 16 x 2, Map: 2, Stride: 8 x 8 x 8, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.

12/09/2017 11:38:19: 
Model has 108 nodes. Using GPU 0.

12/09/2017 11:38:19: Training criterion:   CE = ElementTimes

12/09/2017 11:38:19: Evaluation criteria:
12/09/2017 11:38:19: 	pixelwiseError = ElementTimes
12/09/2017 11:38:19: 	miouError = Minus


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 12 are aliased.
	CE.log_sum.r (gradient) reuses CE.diff (gradient)
	miouError.union (gradient) reuses miouError.unionFlat (gradient)
	featuresFCN8.x.s (gradient) reuses featuresFCN8.x.p (gradient)
	miouError.union.MinusArgs[0] (gradient) reuses miouError.unionFlat (gradient)
	miouError.u (gradient) reuses miouError.reciprocalUnion.z (gradient)
	featuresFCN8.x.b (gradient) reuses featuresFCN8.x.p (gradient)
	featuresFCN8.b (gradient) reuses featuresFCN8.p (gradient)

Memory Sharing: Out of 159 matrices, 96 are shared as 27, and 63 are not shared.

Here are the ones that share memory:
	{ miouError.intersectionFlat : [784 x 2 x *]
	  miouError.union.MinusArgs[0] : [28 x 28 x 2 x *]
	  miouError.unionFlat : [784 x 2 x *]
	  pixelwiseError.outHardmax.isMax : [28 x 28 x 2 x *] }
	{ CE.logits_per_class : [28 x 28 x 2 x *] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  miouError.intersection : [28 x 28 x 2 x *]
	  out : [28 x 28 x 2 x *] (gradient)
	  pixelwiseError.acc._ : [28 x 28 x 2 x *] }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  predictionFCN8 : [4 x 4 x 2 x *] }
	{ CE.logits.r : [28 x 28 x 1 x *]
	  miouError.labelMasked : [28 x 28 x 2 x *] }
	{ CE.out_shift : [28 x 28 x 2 x *]
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient) }
	{ featuresFCN4 : [7 x 7 x 16 x *] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  out : [28 x 28 x 2 x *] }
	{ featuresFCN8.b.x : [4 x 4 x 16 x *]
	  featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *]
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *] (gradient) }
	{ featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *] }
	{ CE.out_max.r : [28 x 28 x 1 x *]
	  featuresFCN8 : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.p : [4 x 4 x 16 x *]
	  featuresFCN8.x.b : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN8.x.p : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.s : [4 x 4 x 16 x *] (gradient) }
	{ featuresFCN8 : [4 x 4 x 16 x *]
	  featuresFCN8.b : [4 x 4 x 16 x *]
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *] (gradient) }
	{ CE.diff : [28 x 28 x 1 x *] (gradient)
	  CE.log_sum.r : [28 x 28 x 1 x *] (gradient)
	  featuresFCN8.x.r : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16] (gradient)
	  pixelwiseError.diffs : [28 x 28 x 1 x *]
	  pixelwiseError.pixelNorm.z.r : [1 x *] }
	{ CE.out_shift : [28 x 28 x 2 x *] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN4.x : [14 x 14 x 16 x *] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *]
	  miouError.union : [28 x 28 x 2 x *]
	  upsampledFCN8 : [40 x 40 x 2 x *] (gradient) }
	{ CE.ce_unnorm : [1] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  miouError.iou : [1 x 2]
	  miouError.u : [1 x 2] }
	{ CE.logits_per_class : [28 x 28 x 2 x *]
	  miouError.outHardmax.isMax : [28 x 28 x 2 x *] }
	{ CE.ce_unnorm : [1]
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient) }
	{ CE.norm_factor.z : [1]
	  miouError.i : [1 x 2] }
	{ featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  miouError.reciprocalUnion.z : [1 x 2] }
	{ featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *]
	  featuresFCN8.x.b : [4 x 4 x 16 x *] }
	{ CE : [1] (gradient)
	  miouError.miou : [1] }
	{ featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *] (gradient)
	  upsampledFCN8 : [40 x 40 x 2 x *] }
	{ featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.r : [4 x 4 x 16 x *]
	  featuresFCN8.x.s : [4 x 4 x 16 x *] }
	{ miouError.intersectionByClass.r : [1 x 2 x *]
	  miouError.unionByClass.r : [1 x 2 x *]
	  pixelwiseError.diffs.ElementTimesArgs[0] : [28 x 28 x 1 x *] }
	{ CE.diff_valid : [28 x 28 x 1 x *]
	  CE.diff_valid : [28 x 28 x 1 x *] (gradient)
	  CE.logits.r : [28 x 28 x 1 x *] (gradient)
	  CE.out_max.r : [28 x 28 x 1 x *] (gradient)
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  pixelwiseError.acc.r : [28 x 28 x 1 x *] }
	{ featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *]
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.p : [4 x 4 x 16 x *] }
	{ featuresFCN4.x : [14 x 14 x 16 x *]
	  featuresFCN4.x._.x.c : [14 x 14 x 16 x *] (gradient) }
	{ CE.log_sum.r : [28 x 28 x 1 x *]
	  featuresFCN8.b : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b.x : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.p : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  predictionFCN8 : [4 x 4 x 2 x *] (gradient) }
	{ CE.diff : [28 x 28 x 1 x *]
	  featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient) }

Here are the ones that don't share memory:
	{miouError.reciprocalUnion.z.PlusArgs[1] : [1]}
	{upsampledFCN8.W : [16 x 16 x 2 x 2]}
	{predictionFCN8.W : [2 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{miouError.norm.z : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{BS.Constants.One : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runMean : [16 x 1]}
	{ignoreMask : [28 x 28 x 1 x *]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{labels : [28 x 28 x 2 x *]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{features : [28 x 28 x 1 x *]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16]}
	{miouError : [1]}
	{CE : [1]}
	{pixelwiseError : [1 x *]}
	{miouError.norm : [1]}
	{featuresFCN8.x.b.x : [4 x 4 x 16 x *]}
	{featuresFCN4.x._.x.c : [14 x 14 x 16 x *]}
	{featuresFCN4 : [7 x 7 x 16 x *]}
	{miouError.iouSum.r : [1]}
	{miouError.reciprocalUnion : [1 x 2]}
	{miouError.outHardmax.maxVals.r : [28 x 28 x 1 x *]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)}
	{pixelwiseError.outHardmax.maxVals.r : [28 x 28 x 1 x *]}
	{featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *]}
	{pixelwiseError.errSum.r : [1 x *]}
	{miouError.outMasked : [28 x 28 x 2 x *]}
	{pixelwiseError.pixelNorm : [1 x *]}
	{predictionFCN8.W : [2 x 16] (gradient)}
	{CE.norm_factor : [1]}
	{featuresFCN8.x.s.x.c : [4 x 4 x 16 x *]}


12/09/2017 11:38:19: Training 10480 parameters in 19 out of 19 parameter tensors and 51 nodes with gradient:

12/09/2017 11:38:19: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [7 x 7 x 1 x 16]
12/09/2017 11:38:19: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:19: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:19: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/09/2017 11:38:19: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:19: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:19: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/09/2017 11:38:19: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:19: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:19: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/09/2017 11:38:19: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:19: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:19: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/09/2017 11:38:19: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:19: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:19: 	Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation) : [1 x 1 x 16 x 16]
12/09/2017 11:38:19: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:19: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:19: 	Node 'predictionFCN8.W' (LearnableParameter operation) : [2 x 16]

Initializing dataParallelSGD with FP32 aggregation.
NcclComm: initialized
12/09/2017 11:38:19: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/09/2017 11:38:19: Starting Epoch 1: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

12/09/2017 11:38:19: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[   1-   1]: CE = 0.05358126 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.67398942 * 1; time = 0.2350s; samplesPerSecond = 68.1
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[   2-   2]: CE = 0.05348114 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67441511 * 1; time = 0.0480s; samplesPerSecond = 333.6
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[   3-   3]: CE = 0.05336734 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67430866 * 1; time = 0.0026s; samplesPerSecond = 6264.7
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[   4-   4]: CE = 0.05368700 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67455792 * 1; time = 0.0023s; samplesPerSecond = 6962.6
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[   5-   5]: CE = 0.05335811 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.67504084 * 1; time = 0.0023s; samplesPerSecond = 6977.1
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[   6-   6]: CE = 0.05369276 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67514026 * 1; time = 0.0023s; samplesPerSecond = 7065.3
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[   7-   7]: CE = 0.05265899 * 16; pixelwiseError = 0.50087690 * 16; miouError = 0.67507046 * 1; time = 0.0023s; samplesPerSecond = 6989.0
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[   8-   8]: CE = 0.05230937 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.67532295 * 1; time = 0.0025s; samplesPerSecond = 6404.6
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[   9-   9]: CE = 0.05198928 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67511535 * 1; time = 0.0023s; samplesPerSecond = 7040.4
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  10-  10]: CE = 0.05222526 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67508692 * 1; time = 0.0023s; samplesPerSecond = 7008.0
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  11-  11]: CE = 0.05389463 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67506301 * 1; time = 0.0023s; samplesPerSecond = 7027.4
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  12-  12]: CE = 0.05333263 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67526436 * 1; time = 0.0023s; samplesPerSecond = 6905.8
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  13-  13]: CE = 0.05272815 * 16; pixelwiseError = 0.49936223 * 16; miouError = 0.67540681 * 1; time = 0.0023s; samplesPerSecond = 7034.2
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  14-  14]: CE = 0.05209520 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67514801 * 1; time = 0.0025s; samplesPerSecond = 6319.6
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  15-  15]: CE = 0.05225396 * 16; pixelwiseError = 0.50127548 * 16; miouError = 0.67502201 * 1; time = 0.0023s; samplesPerSecond = 6908.8
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  16-  16]: CE = 0.05167080 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67490757 * 1; time = 0.0023s; samplesPerSecond = 7067.8
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  17-  17]: CE = 0.05176315 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.67495865 * 1; time = 0.0023s; samplesPerSecond = 7011.1
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  18-  18]: CE = 0.05266295 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67491806 * 1; time = 0.0022s; samplesPerSecond = 7243.4
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  19-  19]: CE = 0.05159565 * 16; pixelwiseError = 0.49848530 * 16; miouError = 0.67501092 * 1; time = 0.0023s; samplesPerSecond = 7013.2
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  20-  20]: CE = 0.05183941 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67500412 * 1; time = 0.0023s; samplesPerSecond = 6988.7
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  21-  21]: CE = 0.05289968 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67495602 * 1; time = 0.0025s; samplesPerSecond = 6340.4
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  22-  22]: CE = 0.05099520 * 16; pixelwiseError = 0.49840561 * 16; miouError = 0.67506933 * 1; time = 0.0023s; samplesPerSecond = 6913.8
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  23-  23]: CE = 0.05251543 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67518258 * 1; time = 0.0023s; samplesPerSecond = 7054.1
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  24-  24]: CE = 0.05193302 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67510223 * 1; time = 0.0023s; samplesPerSecond = 6908.2
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  25-  25]: CE = 0.05142954 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67501879 * 1; time = 0.0023s; samplesPerSecond = 7076.8
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  26-  26]: CE = 0.05142086 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67494613 * 1; time = 0.0023s; samplesPerSecond = 7055.6
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  27-  27]: CE = 0.05044030 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67490309 * 1; time = 0.0023s; samplesPerSecond = 6974.4
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  28-  28]: CE = 0.05047078 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67470402 * 1; time = 0.0027s; samplesPerSecond = 5932.5
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  29-  29]: CE = 0.05127440 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67464465 * 1; time = 0.0023s; samplesPerSecond = 6836.1
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  30-  30]: CE = 0.05085520 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67467308 * 1; time = 0.0023s; samplesPerSecond = 6832.1
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  31-  31]: CE = 0.05155106 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67465854 * 1; time = 0.0025s; samplesPerSecond = 6506.2
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  32-  32]: CE = 0.05023826 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.67464679 * 1; time = 0.0023s; samplesPerSecond = 6827.1
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  33-  33]: CE = 0.05065093 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67471081 * 1; time = 0.0023s; samplesPerSecond = 6970.5
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  34-  34]: CE = 0.05021257 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67462003 * 1; time = 0.0025s; samplesPerSecond = 6349.2
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  35-  35]: CE = 0.05021331 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67457271 * 1; time = 0.0023s; samplesPerSecond = 6984.8
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  36-  36]: CE = 0.04962941 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67442662 * 1; time = 0.0022s; samplesPerSecond = 7126.3
12/09/2017 11:38:19:  Epoch[ 1 of 2]-Minibatch[  37-  37]: CE = 0.04995882 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.67431754 * 1; time = 0.0023s; samplesPerSecond = 6932.4
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  38-  38]: CE = 0.04905782 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67424846 * 1; time = 0.0023s; samplesPerSecond = 6992.7
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  39-  39]: CE = 0.04903949 * 16; pixelwiseError = 0.49872449 * 16; miouError = 0.67405820 * 1; time = 0.0023s; samplesPerSecond = 7019.7
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  40-  40]: CE = 0.04942059 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67393029 * 1; time = 0.0025s; samplesPerSecond = 6436.8
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  41-  41]: CE = 0.04903770 * 16; pixelwiseError = 0.50039864 * 16; miouError = 0.67384571 * 1; time = 0.0023s; samplesPerSecond = 7047.5
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  42-  42]: CE = 0.04925745 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67371136 * 1; time = 0.0023s; samplesPerSecond = 6984.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  43-  43]: CE = 0.04858891 * 16; pixelwiseError = 0.49936223 * 16; miouError = 0.67352647 * 1; time = 0.0022s; samplesPerSecond = 7124.7
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  44-  44]: CE = 0.04879065 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67342925 * 1; time = 0.0023s; samplesPerSecond = 7006.5
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  45-  45]: CE = 0.04846421 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67336810 * 1; time = 0.0023s; samplesPerSecond = 7049.4
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  46-  46]: CE = 0.04976217 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67332262 * 1; time = 0.0023s; samplesPerSecond = 7013.5
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  47-  47]: CE = 0.04835905 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67324579 * 1; time = 0.0027s; samplesPerSecond = 5982.7
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  48-  48]: CE = 0.04839681 * 16; pixelwiseError = 0.49912307 * 16; miouError = 0.67312372 * 1; time = 0.0022s; samplesPerSecond = 7119.3
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  49-  49]: CE = 0.04807591 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67301512 * 1; time = 0.0023s; samplesPerSecond = 6969.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  50-  50]: CE = 0.04864993 * 16; pixelwiseError = 0.50023919 * 16; miouError = 0.67287576 * 1; time = 0.0023s; samplesPerSecond = 7050.6
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  51-  51]: CE = 0.04807357 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67276663 * 1; time = 0.0023s; samplesPerSecond = 7056.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  52-  52]: CE = 0.04832945 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67266524 * 1; time = 0.0023s; samplesPerSecond = 7039.8
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  53-  53]: CE = 0.04854266 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.67255133 * 1; time = 0.0023s; samplesPerSecond = 7031.7
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  54-  54]: CE = 0.04867917 * 16; pixelwiseError = 0.49856505 * 16; miouError = 0.67244208 * 1; time = 0.0024s; samplesPerSecond = 6693.4
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  55-  55]: CE = 0.04762788 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67233753 * 1; time = 0.0023s; samplesPerSecond = 7084.7
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  56-  56]: CE = 0.04807315 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67224896 * 1; time = 0.0023s; samplesPerSecond = 7095.7
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  57-  57]: CE = 0.04766793 * 16; pixelwiseError = 0.50071752 * 16; miouError = 0.67212522 * 1; time = 0.0045s; samplesPerSecond = 3542.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  58-  58]: CE = 0.04836554 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67193943 * 1; time = 0.0023s; samplesPerSecond = 6960.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  59-  59]: CE = 0.04791102 * 16; pixelwiseError = 0.49904338 * 16; miouError = 0.67184711 * 1; time = 0.0023s; samplesPerSecond = 7090.9
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  60-  60]: CE = 0.04734936 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67173970 * 1; time = 0.0023s; samplesPerSecond = 6988.7
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  61-  61]: CE = 0.04762773 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67164236 * 1; time = 0.0023s; samplesPerSecond = 6983.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  62-  62]: CE = 0.04713606 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67150962 * 1; time = 0.0023s; samplesPerSecond = 7046.6
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  63-  63]: CE = 0.09483323 * 8; pixelwiseError = 0.50000000 * 8; miouError = 0.67144477 * 1; time = 0.0022s; samplesPerSecond = 3588.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  64-  64]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.67144477 * 1; time = 0.0004s; samplesPerSecond = 0.0
NcclComm: initialized
12/09/2017 11:38:20: Finished Epoch[ 1 of 2]: [Training] CE = 0.05085723 * 1000; pixelwiseError = 0.49977423 * 1000; miouError = 0.67144483 * 1; totalSamplesSeen = 1000; learningRatePerSample = 0.0099999998; epochTime=0.441228s
NcclComm: initialized
NcclComm: initialized
12/09/2017 11:38:20: Final Results: Minibatch[1-8]: CE = 0.05367578 * 100; pixelwiseError = 0.50012756 * 100; miouError = 0.66783655 * 1
12/09/2017 11:38:20: Finished Epoch[ 1 of 2]: [Validate] CE = 0.05367578 * 100; pixelwiseError = 0.50012756 * 100; miouError = 0.66783655 * 1
12/09/2017 11:38:20: Best epoch per criterion so far: [Validate] CE = 0.053676 (Epoch 1); pixelwiseError = 0.500128 (Epoch 1); miouError = 0.667837 (Epoch 1)
12/09/2017 11:38:20: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN8_train.1'

12/09/2017 11:38:20: Starting Epoch 2: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

12/09/2017 11:38:20: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   1-   1, 0.00%]: CE = 0.04700518 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.66612023 * 1; time = 0.0029s; samplesPerSecond = 5593.0
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   2-   2, 0.00%]: CE = 0.04714876 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.66607058 * 1; time = 0.0023s; samplesPerSecond = 6869.3
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   3-   3, 0.00%]: CE = 0.04765576 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.66636401 * 1; time = 0.0023s; samplesPerSecond = 7010.5
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   4-   4, 0.00%]: CE = 0.04804923 * 16; pixelwiseError = 0.50079721 * 16; miouError = 0.66675544 * 1; time = 0.0027s; samplesPerSecond = 6000.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   5-   5, 0.00%]: CE = 0.04675569 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.66669500 * 1; time = 0.0023s; samplesPerSecond = 6904.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   6-   6, 0.00%]: CE = 0.04724479 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66669518 * 1; time = 0.0023s; samplesPerSecond = 6963.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   7-   7, 0.00%]: CE = 0.04702438 * 16; pixelwiseError = 0.49840561 * 16; miouError = 0.66650820 * 1; time = 0.0023s; samplesPerSecond = 7035.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   8-   8, 0.00%]: CE = 0.04676029 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66648334 * 1; time = 0.0023s; samplesPerSecond = 7110.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   9-   9, 0.00%]: CE = 0.04685746 * 16; pixelwiseError = 0.49944198 * 16; miouError = 0.66642678 * 1; time = 0.0023s; samplesPerSecond = 6972.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  10-  10, 0.00%]: CE = 0.04695185 * 16; pixelwiseError = 0.50103641 * 16; miouError = 0.66651678 * 1; time = 0.0023s; samplesPerSecond = 6933.0
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  11-  11, 0.00%]: CE = 0.04675236 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.66656190 * 1; time = 0.0025s; samplesPerSecond = 6441.0
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  12-  12, 0.00%]: CE = 0.04688483 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66650724 * 1; time = 0.0024s; samplesPerSecond = 6537.0
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  13-  13, 0.00%]: CE = 0.04710711 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.66653931 * 1; time = 0.0023s; samplesPerSecond = 7027.7
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  14-  14, 0.00%]: CE = 0.04658839 * 16; pixelwiseError = 0.50047827 * 16; miouError = 0.66656172 * 1; time = 0.0023s; samplesPerSecond = 6927.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  15-  15, 0.00%]: CE = 0.04683049 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.66656494 * 1; time = 0.0023s; samplesPerSecond = 7108.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  16-  16, 0.00%]: CE = 0.04657679 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66652799 * 1; time = 0.0023s; samplesPerSecond = 7083.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  17-  17, 0.00%]: CE = 0.04679915 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.66655302 * 1; time = 0.0023s; samplesPerSecond = 6897.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  18-  18, 0.00%]: CE = 0.04660954 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66652733 * 1; time = 0.0022s; samplesPerSecond = 7138.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  19-  19, 0.00%]: CE = 0.04645365 * 16; pixelwiseError = 0.49840561 * 16; miouError = 0.66646546 * 1; time = 0.0023s; samplesPerSecond = 7049.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  20-  20, 0.00%]: CE = 0.04691649 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.66647786 * 1; time = 0.0023s; samplesPerSecond = 6944.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  21-  21, 0.00%]: CE = 0.04672623 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66648334 * 1; time = 0.0022s; samplesPerSecond = 7113.3
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  22-  22, 0.00%]: CE = 0.04685799 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66649449 * 1; time = 0.0023s; samplesPerSecond = 6967.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  23-  23, 0.00%]: CE = 0.04632717 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.66652137 * 1; time = 0.0023s; samplesPerSecond = 7104.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  24-  24, 0.00%]: CE = 0.04620083 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66652417 * 1; time = 0.0027s; samplesPerSecond = 6013.0
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  25-  25, 0.00%]: CE = 0.04644240 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66655266 * 1; time = 0.0023s; samplesPerSecond = 6917.7
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  26-  26, 0.00%]: CE = 0.04647167 * 16; pixelwiseError = 0.50111610 * 16; miouError = 0.66662544 * 1; time = 0.0023s; samplesPerSecond = 7106.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  27-  27, 0.00%]: CE = 0.04656660 * 16; pixelwiseError = 0.49848530 * 16; miouError = 0.66658986 * 1; time = 0.0023s; samplesPerSecond = 6920.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  28-  28, 0.00%]: CE = 0.04652066 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66661507 * 1; time = 0.0023s; samplesPerSecond = 7082.5
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  29-  29, 0.00%]: CE = 0.04621993 * 16; pixelwiseError = 0.49808672 * 16; miouError = 0.66658843 * 1; time = 0.0022s; samplesPerSecond = 7136.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  30-  30, 0.00%]: CE = 0.04661595 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66662574 * 1; time = 0.0025s; samplesPerSecond = 6355.0
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  31-  31, 0.00%]: CE = 0.04641042 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.66667020 * 1; time = 0.0022s; samplesPerSecond = 7192.3
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  32-  32, 0.00%]: CE = 0.04644847 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66669607 * 1; time = 0.0023s; samplesPerSecond = 7083.7
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  33-  33, 0.00%]: CE = 0.04617931 * 16; pixelwiseError = 0.49832588 * 16; miouError = 0.66668630 * 1; time = 0.0022s; samplesPerSecond = 7145.7
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  34-  34, 0.00%]: CE = 0.04607056 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66672164 * 1; time = 0.0040s; samplesPerSecond = 3995.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  35-  35, 0.00%]: CE = 0.04620294 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.66673577 * 1; time = 0.0023s; samplesPerSecond = 6894.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  36-  36, 0.00%]: CE = 0.04600681 * 16; pixelwiseError = 0.49864474 * 16; miouError = 0.66672814 * 1; time = 0.0025s; samplesPerSecond = 6352.5
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  37-  37, 0.00%]: CE = 0.04620455 * 16; pixelwiseError = 0.49912307 * 16; miouError = 0.66676486 * 1; time = 0.0023s; samplesPerSecond = 7018.5
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  38-  38, 0.00%]: CE = 0.04619167 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.66678196 * 1; time = 0.0023s; samplesPerSecond = 6994.5
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  39-  39, 0.00%]: CE = 0.04603130 * 16; pixelwiseError = 0.49776784 * 16; miouError = 0.66675991 * 1; time = 0.0023s; samplesPerSecond = 7050.6
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  40-  40, 0.00%]: CE = 0.04587509 * 16; pixelwiseError = 0.49880418 * 16; miouError = 0.66677636 * 1; time = 0.0023s; samplesPerSecond = 7044.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  41-  41, 0.00%]: CE = 0.04610740 * 16; pixelwiseError = 0.49888393 * 16; miouError = 0.66679800 * 1; time = 0.0023s; samplesPerSecond = 7016.0
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  42-  42, 0.00%]: CE = 0.04596604 * 16; pixelwiseError = 0.49832585 * 16; miouError = 0.66679817 * 1; time = 0.0023s; samplesPerSecond = 6960.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  43-  43, 0.00%]: CE = 0.04600766 * 16; pixelwiseError = 0.49896365 * 16; miouError = 0.66681063 * 1; time = 0.0026s; samplesPerSecond = 6160.5
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  44-  44, 0.00%]: CE = 0.04608698 * 16; pixelwiseError = 0.49824616 * 16; miouError = 0.66680336 * 1; time = 0.0025s; samplesPerSecond = 6429.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  45-  45, 0.00%]: CE = 0.04595218 * 16; pixelwiseError = 0.49784753 * 16; miouError = 0.66678584 * 1; time = 0.0023s; samplesPerSecond = 7004.3
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  46-  46, 0.00%]: CE = 0.04611240 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66680765 * 1; time = 0.0023s; samplesPerSecond = 6940.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  47-  47, 0.00%]: CE = 0.04594595 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66686189 * 1; time = 0.0023s; samplesPerSecond = 7024.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  48-  48, 0.00%]: CE = 0.04565826 * 16; pixelwiseError = 0.49864474 * 16; miouError = 0.66688406 * 1; time = 0.0023s; samplesPerSecond = 6983.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  49-  49, 0.00%]: CE = 0.04572549 * 16; pixelwiseError = 0.49936226 * 16; miouError = 0.66691160 * 1; time = 0.0028s; samplesPerSecond = 5687.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  50-  50, 0.00%]: CE = 0.04577860 * 16; pixelwiseError = 0.49832588 * 16; miouError = 0.66692114 * 1; time = 0.0024s; samplesPerSecond = 6807.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  51-  51, 0.00%]: CE = 0.04588787 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66695815 * 1; time = 0.0023s; samplesPerSecond = 6928.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  52-  52, 0.00%]: CE = 0.04579680 * 16; pixelwiseError = 0.49912307 * 16; miouError = 0.66696715 * 1; time = 0.0024s; samplesPerSecond = 6611.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  53-  53, 0.00%]: CE = 0.04578758 * 16; pixelwiseError = 0.49968109 * 16; miouError = 0.66698885 * 1; time = 0.0024s; samplesPerSecond = 6723.3
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  54-  54, 0.00%]: CE = 0.04561337 * 16; pixelwiseError = 0.49936223 * 16; miouError = 0.66702253 * 1; time = 0.0023s; samplesPerSecond = 7065.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  55-  55, 0.00%]: CE = 0.04561181 * 16; pixelwiseError = 0.49768811 * 16; miouError = 0.66701943 * 1; time = 0.0023s; samplesPerSecond = 6970.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  56-  56, 0.00%]: CE = 0.04555615 * 16; pixelwiseError = 0.49824616 * 16; miouError = 0.66701114 * 1; time = 0.0024s; samplesPerSecond = 6763.3
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  57-  57, 0.00%]: CE = 0.04548024 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.66704595 * 1; time = 0.0023s; samplesPerSecond = 7033.6
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  58-  58, 0.00%]: CE = 0.04564868 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.66706735 * 1; time = 0.0023s; samplesPerSecond = 7020.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  59-  59, 0.00%]: CE = 0.04551122 * 16; pixelwiseError = 0.49713007 * 16; miouError = 0.66705430 * 1; time = 0.0024s; samplesPerSecond = 6803.3
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  60-  60, 0.00%]: CE = 0.04540705 * 16; pixelwiseError = 0.49736923 * 16; miouError = 0.66704893 * 1; time = 0.0023s; samplesPerSecond = 7044.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  61-  61, 0.00%]: CE = 0.04547740 * 16; pixelwiseError = 0.49808672 * 16; miouError = 0.66703582 * 1; time = 0.0035s; samplesPerSecond = 4565.0
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  62-  62, 0.00%]: CE = 0.04542790 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.66706908 * 1; time = 0.0025s; samplesPerSecond = 6324.6
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  63-  63, 0.00%]: CE = 0.09121688 * 8; pixelwiseError = 0.49936226 * 8; miouError = 0.66708285 * 1; time = 0.0021s; samplesPerSecond = 3776.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  64-  64, 0.00%]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.66708285 * 1; time = 0.0003s; samplesPerSecond = 0.0
NcclComm: initialized
12/09/2017 11:38:20: Finished Epoch[ 2 of 2]: [Training] CE = 0.04668317 * 1000; pixelwiseError = 0.49928443 * 1000; miouError = 0.66708291 * 1; totalSamplesSeen = 2000; learningRatePerSample = 0.0099999998; epochTime=0.164407s
NcclComm: initialized
NcclComm: initialized
12/09/2017 11:38:20: Final Results: Minibatch[1-8]: CE = 0.05160968 * 100; pixelwiseError = 0.49910715 * 100; miouError = 0.66589987 * 1
12/09/2017 11:38:20: Finished Epoch[ 2 of 2]: [Validate] CE = 0.05160968 * 100; pixelwiseError = 0.49910715 * 100; miouError = 0.66589987 * 1
12/09/2017 11:38:20: Best epoch per criterion so far: [Validate] CE = 0.051610 (Epoch 2); pixelwiseError = 0.499107 (Epoch 2); miouError = 0.665900 (Epoch 2)
12/09/2017 11:38:20: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN8_train'
12/09/2017 11:38:20: Best epoch for criterion 'CE' is 2 and model /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN8_train copied to /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN8_train_CE
12/09/2017 11:38:20: Best epoch for criterion 'miouError' is 2 and model /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN8_train copied to /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN8_train_miouError
12/09/2017 11:38:20: Best epoch for criterion 'pixelwiseError' is 2 and model /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN8_train copied to /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN8_train_pixelwiseError

12/09/2017 11:38:20: Action "train" complete.


12/09/2017 11:38:20: ##############################################################################
12/09/2017 11:38:20: #                                                                            #
12/09/2017 11:38:20: # ConvertFCN8ToFCN4 command (edit action)                                    #
12/09/2017 11:38:20: #                                                                            #
12/09/2017 11:38:20: ##############################################################################

featuresFCN4.x._.x.c: using GEMM convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using GEMM convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using GEMM convolution engine for geometry: Input: 40 x 40 x 2, Output: 4 x 4 x 2, Kernel: 16 x 16 x 2, Map: 2, Stride: 8 x 8 x 8, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.

12/09/2017 11:38:20: Action "edit" complete.


12/09/2017 11:38:20: ##############################################################################
12/09/2017 11:38:20: #                                                                            #
12/09/2017 11:38:20: # TrainFCN4 command (train action)                                           #
12/09/2017 11:38:20: #                                                                            #
12/09/2017 11:38:20: ##############################################################################

12/09/2017 11:38:20: 
Creating virgin network.
Load: Loading model file: /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_initial
Post-processing network...

4 roots:
	ignoreMask = InputValue()
	labels = InputValue()
	predictionFCN8 = Convolution()
	upsampledFCN8.W = LearnableParameter()

Validating network. 62 nodes to process in pass 1.

Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *3]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *3]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *3]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *3] -> [14 x 14 x 16 x *3]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *3]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *3] -> [14 x 14 x 16 x *3]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *3] -> [7 x 7 x 16 x *3]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *3], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *3], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 2 x *3]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [16 x 16 x 2 x 2]

Validating network. 21 nodes to process in pass 2.


Validating network, final pass.

featuresFCN4.x._.x.c: using cuDNN convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using cuDNN convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.


Post-processing network...

4 roots:
	CE = ElementTimes()
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 114 nodes to process in pass 1.

Validating --> upsampledFCN4.W = LearnableParameter() :  -> [8 x 8 x 2 x 2]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [4 x 4 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *2]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *2] -> [14 x 14 x 16 x *2]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *2]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *2] -> [14 x 14 x 16 x *2]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *2] -> [7 x 7 x 16 x *2]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *2], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *2], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 2 x *2]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [4 x 4 x 2 x 2], [4 x 4 x 2 x *2] -> [10 x 10 x 2 x *2]
Validating --> predictionFCN4.W = LearnableParameter() :  -> [2 x 16]
Validating --> predictionFCN4 = Convolution (predictionFCN4.W, featuresFCN4) : [2 x 16], [7 x 7 x 16 x *2] -> [7 x 7 x 2 x *2]
Validating --> cropFCN8 = Crop (upsampledFCN8, predictionFCN4) : [10 x 10 x 2 x *2], [7 x 7 x 2 x *2] -> [7 x 7 x 2 x *2]
Validating --> fusionFCN4 = Plus (cropFCN8, predictionFCN4) : [7 x 7 x 2 x *2], [7 x 7 x 2 x *2] -> [7 x 7 x 2 x *2]
Validating --> upsampledFCN4 = Convolution (upsampledFCN4.W, fusionFCN4) : [8 x 8 x 2 x 2], [7 x 7 x 2 x *2] -> [32 x 32 x 2 x *2]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *2]
Validating --> out = Crop (upsampledFCN4, labels, features, labels) : [32 x 32 x 2 x *2], [28 x 28 x 2 x *2], [28 x 28 x 1 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> CE.out_max.r = ReduceElements (out) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.out_shift = Minus (out, CE.out_max.r) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> CE.log_sum.r = ReduceElements (CE.out_shift) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.logits_per_class = ElementTimes (labels, CE.out_shift) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> CE.logits.r = ReduceElements (CE.logits_per_class) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.diff = Minus (CE.log_sum.r, CE.logits.r) : [28 x 28 x 1 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *2]
Validating --> CE.diff_valid = ElementTimes (CE.diff, ignoreMask) : [28 x 28 x 1 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.ce_unnorm = SumElements (CE.diff_valid) : [28 x 28 x 1 x *2] -> [1]
Validating --> CE.norm_factor.z = SumElements (ignoreMask) : [28 x 28 x 1 x *2] -> [1]
Validating --> CE.norm_factor = Reciprocal (CE.norm_factor.z) : [1] -> [1]
Validating --> CE = ElementTimes (CE.ce_unnorm, CE.norm_factor) : [1], [1] -> [1]
Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *2] -> [784 x 2 x *2]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *2] -> [1 x 2 x *2]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *2] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *2] -> [784 x 2 x *2]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *2] -> [1 x 2 x *2]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *2] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *2] -> [1 x *2]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *2] -> [1 x *2]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *2] -> [1 x *2]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *2], [1 x *2] -> [1 x *2]

Validating network. 68 nodes to process in pass 2.


Validating network, final pass.

upsampledFCN8: using cuDNN convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
predictionFCN4: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 7 x 7 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using cuDNN convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.

12/09/2017 11:38:20: 
Model has 114 nodes. Using GPU 0.

12/09/2017 11:38:20: Training criterion:   CE = ElementTimes

12/09/2017 11:38:20: Evaluation criteria:
12/09/2017 11:38:20: 	pixelwiseError = ElementTimes
12/09/2017 11:38:20: 	miouError = Minus


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 14 are aliased.
	miouError.union (gradient) reuses miouError.unionFlat (gradient)
	featuresFCN8.b (gradient) reuses featuresFCN8.p (gradient)
	featuresFCN8.x.b (gradient) reuses featuresFCN8.x.p (gradient)
	miouError.union.MinusArgs[0] (gradient) reuses miouError.unionFlat (gradient)
	miouError.u (gradient) reuses miouError.reciprocalUnion.z (gradient)
	cropFCN8 (gradient) reuses fusionFCN4 (gradient)
	CE.log_sum.r (gradient) reuses CE.diff (gradient)
	featuresFCN8.x.s (gradient) reuses featuresFCN8.x.p (gradient)

Memory Sharing: Out of 171 matrices, 106 are shared as 29, and 65 are not shared.

Here are the ones that share memory:
	{ CE.diff_valid : [28 x 28 x 1 x *2]
	  miouError.union : [28 x 28 x 2 x *2]
	  pixelwiseError.outHardmax.isMax : [28 x 28 x 2 x *2] }
	{ CE.logits.r : [28 x 28 x 1 x *2] (gradient)
	  CE.out_shift : [28 x 28 x 2 x *2] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  miouError.intersection : [28 x 28 x 2 x *2]
	  pixelwiseError.acc.r : [28 x 28 x 1 x *2] }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  upsampledFCN8 : [10 x 10 x 2 x *2] }
	{ CE.diff : [28 x 28 x 1 x *2] (gradient)
	  CE.log_sum.r : [28 x 28 x 1 x *2] (gradient)
	  cropFCN8 : [7 x 7 x 2 x *2] (gradient)
	  featuresFCN8 : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  fusionFCN4 : [7 x 7 x 2 x *2] (gradient)
	  pixelwiseError.diffs : [28 x 28 x 1 x *2]
	  pixelwiseError.pixelNorm.z.r : [1 x *2] }
	{ featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN4.x : [14 x 14 x 16 x *2] }
	{ miouError.unionByClass.r : [1 x 2 x *2]
	  pixelwiseError.diffs.ElementTimesArgs[0] : [28 x 28 x 1 x *2] }
	{ miouError.intersectionByClass.r : [1 x 2 x *2]
	  pixelwiseError.outHardmax.maxVals.r : [28 x 28 x 1 x *2] }
	{ featuresFCN4.x : [14 x 14 x 16 x *2] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *2]
	  featuresFCN4.x._.x.c : [14 x 14 x 16 x *2] (gradient)
	  upsampledFCN4 : [32 x 32 x 2 x *2] }
	{ featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  out : [28 x 28 x 2 x *2] }
	{ CE.log_sum.r : [28 x 28 x 1 x *2]
	  CE.out_max.r : [28 x 28 x 1 x *2] (gradient)
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient) }
	{ cropFCN8 : [7 x 7 x 2 x *2]
	  upsampledFCN8.W : [4 x 4 x 2 x 2] (gradient) }
	{ featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  predictionFCN4 : [7 x 7 x 2 x *2]
	  predictionFCN8 : [4 x 4 x 2 x *2] (gradient) }
	{ fusionFCN4 : [7 x 7 x 2 x *2]
	  predictionFCN8.W : [2 x 16] (gradient) }
	{ featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN8.x.p : [4 x 4 x 16 x *2] }
	{ CE.diff_valid : [28 x 28 x 1 x *2] (gradient)
	  CE.logits.r : [28 x 28 x 1 x *2]
	  CE.logits_per_class : [28 x 28 x 2 x *2] (gradient)
	  featuresFCN4 : [7 x 7 x 16 x *2] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  miouError.intersectionFlat : [784 x 2 x *2]
	  miouError.union.MinusArgs[0] : [28 x 28 x 2 x *2]
	  miouError.unionFlat : [784 x 2 x *2]
	  out : [28 x 28 x 2 x *2] (gradient)
	  pixelwiseError.acc._ : [28 x 28 x 2 x *2] }
	{ CE.diff : [28 x 28 x 1 x *2]
	  featuresFCN8.x.r : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16] (gradient)
	  predictionFCN4 : [7 x 7 x 2 x *2] (gradient) }
	{ CE.logits_per_class : [28 x 28 x 2 x *2]
	  miouError.outHardmax.isMax : [28 x 28 x 2 x *2] }
	{ CE.norm_factor.z : [1]
	  miouError.i : [1 x 2] }
	{ featuresFCN8.b.x._ : [4 x 4 x 16 x *2]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.p : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.s : [4 x 4 x 16 x *2] (gradient) }
	{ featuresFCN8.x.b.x.c : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *2] }
	{ miouError.reciprocalUnion : [1 x 2]
	  miouError.u : [1 x 2] }
	{ CE.ce_unnorm : [1] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  miouError.iou : [1 x 2]
	  miouError.miou : [1]
	  miouError.reciprocalUnion.z : [1 x 2] }
	{ featuresFCN8 : [4 x 4 x 16 x *2]
	  featuresFCN8.b : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *2] (gradient) }
	{ CE.out_shift : [28 x 28 x 2 x *2]
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *2] (gradient)
	  upsampledFCN4 : [32 x 32 x 2 x *2] (gradient) }
	{ featuresFCN8.x.b.x._ : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *2] }
	{ CE.out_max.r : [28 x 28 x 1 x *2]
	  featuresFCN8.b : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.b.x : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.p : [4 x 4 x 16 x *2]
	  featuresFCN8.p : [4 x 4 x 16 x *2] (gradient)
	  upsampledFCN8 : [10 x 10 x 2 x *2] (gradient) }
	{ featuresFCN8.b.x : [4 x 4 x 16 x *2]
	  featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *2]
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *2] (gradient) }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  predictionFCN8 : [4 x 4 x 2 x *2] }
	{ featuresFCN8.x.r : [4 x 4 x 16 x *2]
	  featuresFCN8.x.s : [4 x 4 x 16 x *2]
	  featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1] (gradient) }

Here are the ones that don't share memory:
	{upsampledFCN4.W : [8 x 8 x 2 x 2]}
	{BS.Constants.One : [1]}
	{features : [28 x 28 x 1 x *2]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{upsampledFCN8.W : [4 x 4 x 2 x 2]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16]}
	{featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1]}
	{ignoreMask : [28 x 28 x 1 x *2]}
	{labels : [28 x 28 x 2 x *2]}
	{predictionFCN8.W : [2 x 16]}
	{miouError.reciprocalUnion.z.PlusArgs[1] : [1]}
	{predictionFCN4.W : [2 x 16]}
	{featuresFCN4 : [7 x 7 x 16 x *2]}
	{miouError.outMasked : [28 x 28 x 2 x *2]}
	{pixelwiseError.pixelNorm : [1 x *2]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)}
	{CE.norm_factor : [1]}
	{miouError.outHardmax.maxVals.r : [28 x 28 x 1 x *2]}
	{featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *2]}
	{predictionFCN4.W : [2 x 16] (gradient)}
	{miouError.iouSum.r : [1]}
	{CE.ce_unnorm : [1]}
	{pixelwiseError.errSum.r : [1 x *2]}
	{featuresFCN4.x._.x.c : [14 x 14 x 16 x *2]}
	{CE : [1] (gradient)}
	{miouError.labelMasked : [28 x 28 x 2 x *2]}
	{featuresFCN8.x.b.x : [4 x 4 x 16 x *2]}
	{pixelwiseError : [1 x *2]}
	{miouError.norm : [1]}
	{miouError.norm.z : [1]}
	{miouError : [1]}
	{CE : [1]}


12/09/2017 11:38:20: Training 10576 parameters in 21 out of 21 parameter tensors and 57 nodes with gradient:

12/09/2017 11:38:20: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [7 x 7 x 1 x 16]
12/09/2017 11:38:20: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:20: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:20: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/09/2017 11:38:20: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:20: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:20: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/09/2017 11:38:20: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:20: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:20: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/09/2017 11:38:20: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:20: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:20: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
12/09/2017 11:38:20: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:20: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:20: 	Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation) : [1 x 1 x 16 x 16]
12/09/2017 11:38:20: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:20: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
12/09/2017 11:38:20: 	Node 'predictionFCN4.W' (LearnableParameter operation) : [2 x 16]
12/09/2017 11:38:20: 	Node 'predictionFCN8.W' (LearnableParameter operation) : [2 x 16]
12/09/2017 11:38:20: 	Node 'upsampledFCN8.W' (LearnableParameter operation) : [4 x 4 x 2 x 2]

Initializing dataParallelSGD with FP32 aggregation.
NcclComm: initialized
12/09/2017 11:38:20: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/09/2017 11:38:20: Starting Epoch 1: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

12/09/2017 11:38:20: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[   1-   1]: CE = 0.05408767 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.69101435 * 1; time = 0.0710s; samplesPerSecond = 225.3
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[   2-   2]: CE = 0.05385973 * 16; pixelwiseError = 0.50015950 * 16; miouError = 0.69340897 * 1; time = 0.0485s; samplesPerSecond = 330.0
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[   3-   3]: CE = 0.05385835 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.69396359 * 1; time = 0.0025s; samplesPerSecond = 6337.4
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[   4-   4]: CE = 0.05368459 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.69347245 * 1; time = 0.0025s; samplesPerSecond = 6288.8
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[   5-   5]: CE = 0.05405236 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.69376075 * 1; time = 0.0025s; samplesPerSecond = 6379.8
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[   6-   6]: CE = 0.05423238 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.69405150 * 1; time = 0.0027s; samplesPerSecond = 5845.8
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[   7-   7]: CE = 0.05287183 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.69366407 * 1; time = 0.0025s; samplesPerSecond = 6309.4
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[   8-   8]: CE = 0.05354694 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.69346058 * 1; time = 0.0025s; samplesPerSecond = 6321.9
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[   9-   9]: CE = 0.05235495 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.69276190 * 1; time = 0.0025s; samplesPerSecond = 6409.5
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  10-  10]: CE = 0.05295617 * 16; pixelwiseError = 0.49888393 * 16; miouError = 0.69204527 * 1; time = 0.0025s; samplesPerSecond = 6348.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  11-  11]: CE = 0.05347527 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.69193119 * 1; time = 0.0025s; samplesPerSecond = 6287.6
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  12-  12]: CE = 0.05425291 * 16; pixelwiseError = 0.50039864 * 16; miouError = 0.69223964 * 1; time = 0.0025s; samplesPerSecond = 6319.9
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  13-  13]: CE = 0.05330436 * 16; pixelwiseError = 0.50071746 * 16; miouError = 0.69225311 * 1; time = 0.0026s; samplesPerSecond = 6274.5
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  14-  14]: CE = 0.05264026 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.69169366 * 1; time = 0.0025s; samplesPerSecond = 6320.4
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  15-  15]: CE = 0.05210470 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.69131744 * 1; time = 0.0025s; samplesPerSecond = 6442.8
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  16-  16]: CE = 0.05206249 * 16; pixelwiseError = 0.50135523 * 16; miouError = 0.69083494 * 1; time = 0.0025s; samplesPerSecond = 6355.3
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  17-  17]: CE = 0.05233751 * 16; pixelwiseError = 0.50023919 * 16; miouError = 0.69061160 * 1; time = 0.0025s; samplesPerSecond = 6432.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  18-  18]: CE = 0.05247623 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.69038469 * 1; time = 0.0031s; samplesPerSecond = 5134.1
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  19-  19]: CE = 0.05215513 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.68994164 * 1; time = 0.0025s; samplesPerSecond = 6343.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  20-  20]: CE = 0.05162350 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.68971133 * 1; time = 0.0026s; samplesPerSecond = 6249.0
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  21-  21]: CE = 0.05161402 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.68927050 * 1; time = 0.0025s; samplesPerSecond = 6460.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  22-  22]: CE = 0.05166121 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.68870723 * 1; time = 0.0025s; samplesPerSecond = 6414.1
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  23-  23]: CE = 0.05194513 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.68856549 * 1; time = 0.0025s; samplesPerSecond = 6420.8
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  24-  24]: CE = 0.05064921 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.68823797 * 1; time = 0.0027s; samplesPerSecond = 5911.3
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  25-  25]: CE = 0.05066123 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.68765056 * 1; time = 0.0025s; samplesPerSecond = 6377.6
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  26-  26]: CE = 0.05086557 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.68713176 * 1; time = 0.0025s; samplesPerSecond = 6487.5
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  27-  27]: CE = 0.05032179 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.68656027 * 1; time = 0.0025s; samplesPerSecond = 6408.5
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  28-  28]: CE = 0.05003508 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.68584216 * 1; time = 0.0025s; samplesPerSecond = 6282.1
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  29-  29]: CE = 0.05032287 * 16; pixelwiseError = 0.49920282 * 16; miouError = 0.68524671 * 1; time = 0.0025s; samplesPerSecond = 6448.8
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  30-  30]: CE = 0.05034602 * 16; pixelwiseError = 0.50119579 * 16; miouError = 0.68489403 * 1; time = 0.0026s; samplesPerSecond = 6195.8
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  31-  31]: CE = 0.05042294 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.68453479 * 1; time = 0.0025s; samplesPerSecond = 6312.9
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  32-  32]: CE = 0.04997968 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.68395954 * 1; time = 0.0025s; samplesPerSecond = 6502.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  33-  33]: CE = 0.04988771 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.68333209 * 1; time = 0.0027s; samplesPerSecond = 6014.4
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  34-  34]: CE = 0.04989042 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.68268013 * 1; time = 0.0025s; samplesPerSecond = 6393.4
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  35-  35]: CE = 0.04950381 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.68214840 * 1; time = 0.0025s; samplesPerSecond = 6468.8
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  36-  36]: CE = 0.04935871 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.68155581 * 1; time = 0.0030s; samplesPerSecond = 5338.1
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  37-  37]: CE = 0.04955855 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.68087161 * 1; time = 0.0025s; samplesPerSecond = 6419.5
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  38-  38]: CE = 0.04900089 * 16; pixelwiseError = 0.50047827 * 16; miouError = 0.68023121 * 1; time = 0.0025s; samplesPerSecond = 6399.0
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  39-  39]: CE = 0.04891424 * 16; pixelwiseError = 0.50127548 * 16; miouError = 0.67955327 * 1; time = 0.0025s; samplesPerSecond = 6354.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  40-  40]: CE = 0.04941810 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67893493 * 1; time = 0.0025s; samplesPerSecond = 6381.4
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  41-  41]: CE = 0.04927996 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67836249 * 1; time = 0.0025s; samplesPerSecond = 6451.6
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  42-  42]: CE = 0.04905721 * 16; pixelwiseError = 0.49856505 * 16; miouError = 0.67784154 * 1; time = 0.0027s; samplesPerSecond = 5836.9
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  43-  43]: CE = 0.04904880 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67723340 * 1; time = 0.0025s; samplesPerSecond = 6381.6
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  44-  44]: CE = 0.04888834 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67673242 * 1; time = 0.0025s; samplesPerSecond = 6401.3
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  45-  45]: CE = 0.04921453 * 16; pixelwiseError = 0.50071746 * 16; miouError = 0.67626107 * 1; time = 0.0025s; samplesPerSecond = 6328.4
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  46-  46]: CE = 0.04886933 * 16; pixelwiseError = 0.49760839 * 16; miouError = 0.67585421 * 1; time = 0.0025s; samplesPerSecond = 6326.9
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  47-  47]: CE = 0.04896349 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.67539048 * 1; time = 0.0025s; samplesPerSecond = 6398.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  48-  48]: CE = 0.04925613 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67490333 * 1; time = 0.0026s; samplesPerSecond = 6207.8
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  49-  49]: CE = 0.04920729 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67444450 * 1; time = 0.0026s; samplesPerSecond = 6226.4
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  50-  50]: CE = 0.04889734 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67408210 * 1; time = 0.0026s; samplesPerSecond = 6235.9
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  51-  51]: CE = 0.04893097 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67369682 * 1; time = 0.0025s; samplesPerSecond = 6342.4
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  52-  52]: CE = 0.04907078 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67327964 * 1; time = 0.0025s; samplesPerSecond = 6371.2
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  53-  53]: CE = 0.04876319 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67292494 * 1; time = 0.0025s; samplesPerSecond = 6387.0
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  54-  54]: CE = 0.04880457 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67260265 * 1; time = 0.0031s; samplesPerSecond = 5213.4
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  55-  55]: CE = 0.04883927 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.67225629 * 1; time = 0.0025s; samplesPerSecond = 6279.9
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  56-  56]: CE = 0.04879939 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67195523 * 1; time = 0.0025s; samplesPerSecond = 6357.8
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  57-  57]: CE = 0.04886785 * 16; pixelwiseError = 0.50039864 * 16; miouError = 0.67162460 * 1; time = 0.0025s; samplesPerSecond = 6298.7
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  58-  58]: CE = 0.04896085 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.67133743 * 1; time = 0.0025s; samplesPerSecond = 6402.6
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  59-  59]: CE = 0.04855758 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67108321 * 1; time = 0.0025s; samplesPerSecond = 6414.6
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  60-  60]: CE = 0.04910423 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67081738 * 1; time = 0.0027s; samplesPerSecond = 5904.7
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  61-  61]: CE = 0.04917107 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67052484 * 1; time = 0.0025s; samplesPerSecond = 6413.1
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  62-  62]: CE = 0.04896258 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67026603 * 1; time = 0.0025s; samplesPerSecond = 6357.0
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  63-  63]: CE = 0.09795266 * 8; pixelwiseError = 0.50159436 * 8; miouError = 0.67015588 * 1; time = 0.0023s; samplesPerSecond = 3427.3
12/09/2017 11:38:20:  Epoch[ 1 of 2]-Minibatch[  64-  64]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.67015588 * 1; time = 0.0004s; samplesPerSecond = 0.0
NcclComm: initialized
12/09/2017 11:38:20: Finished Epoch[ 1 of 2]: [Training] CE = 0.05108457 * 1000; pixelwiseError = 0.49989540 * 1000; miouError = 0.67015588 * 1; totalSamplesSeen = 1000; learningRatePerSample = 0.0099999998; epochTime=0.28976s
NcclComm: initialized
NcclComm: initialized
12/09/2017 11:38:20: Final Results: Minibatch[1-8]: CE = 0.05615826 * 100; pixelwiseError = 0.50025512 * 100; miouError = 0.67410809 * 1
12/09/2017 11:38:20: Finished Epoch[ 1 of 2]: [Validate] CE = 0.05615826 * 100; pixelwiseError = 0.50025512 * 100; miouError = 0.67410809 * 1
12/09/2017 11:38:20: Best epoch per criterion so far: [Validate] CE = 0.056158 (Epoch 1); pixelwiseError = 0.500255 (Epoch 1); miouError = 0.674108 (Epoch 1)
12/09/2017 11:38:20: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_train.1'

12/09/2017 11:38:20: Starting Epoch 2: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

12/09/2017 11:38:20: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   1-   1, 0.00%]: CE = 0.04874115 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67050445 * 1; time = 0.0030s; samplesPerSecond = 5312.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   2-   2, 0.00%]: CE = 0.04858399 * 16; pixelwiseError = 0.50111610 * 16; miouError = 0.67125618 * 1; time = 0.0026s; samplesPerSecond = 6263.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   3-   3, 0.00%]: CE = 0.04862301 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67129827 * 1; time = 0.0026s; samplesPerSecond = 6258.3
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   4-   4, 0.00%]: CE = 0.04852179 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67108834 * 1; time = 0.0028s; samplesPerSecond = 5812.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   5-   5, 0.00%]: CE = 0.04924908 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67148232 * 1; time = 0.0025s; samplesPerSecond = 6397.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   6-   6, 0.00%]: CE = 0.04842582 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67124337 * 1; time = 0.0025s; samplesPerSecond = 6285.6
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   7-   7, 0.00%]: CE = 0.04871033 * 16; pixelwiseError = 0.50095665 * 16; miouError = 0.67147094 * 1; time = 0.0025s; samplesPerSecond = 6421.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   8-   8, 0.00%]: CE = 0.04856232 * 16; pixelwiseError = 0.50103635 * 16; miouError = 0.67166054 * 1; time = 0.0025s; samplesPerSecond = 6380.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[   9-   9, 0.00%]: CE = 0.04851813 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67176348 * 1; time = 0.0025s; samplesPerSecond = 6355.5
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  10-  10, 0.00%]: CE = 0.04858100 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67185932 * 1; time = 0.0026s; samplesPerSecond = 6198.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  11-  11, 0.00%]: CE = 0.04842703 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67188013 * 1; time = 0.0028s; samplesPerSecond = 5618.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  12-  12, 0.00%]: CE = 0.04870864 * 16; pixelwiseError = 0.50087690 * 16; miouError = 0.67207754 * 1; time = 0.0025s; samplesPerSecond = 6319.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  13-  13, 0.00%]: CE = 0.04835921 * 16; pixelwiseError = 0.50071746 * 16; miouError = 0.67225170 * 1; time = 0.0025s; samplesPerSecond = 6381.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  14-  14, 0.00%]: CE = 0.04857209 * 16; pixelwiseError = 0.50111604 * 16; miouError = 0.67254031 * 1; time = 0.0025s; samplesPerSecond = 6351.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  15-  15, 0.00%]: CE = 0.04875096 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67262268 * 1; time = 0.0025s; samplesPerSecond = 6373.0
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  16-  16, 0.00%]: CE = 0.04838093 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67275655 * 1; time = 0.0028s; samplesPerSecond = 5636.0
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  17-  17, 0.00%]: CE = 0.04791702 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67270094 * 1; time = 0.0029s; samplesPerSecond = 5505.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  18-  18, 0.00%]: CE = 0.04792605 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67268384 * 1; time = 0.0025s; samplesPerSecond = 6274.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  19-  19, 0.00%]: CE = 0.04791676 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67263293 * 1; time = 0.0025s; samplesPerSecond = 6459.7
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  20-  20, 0.00%]: CE = 0.04778210 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67264944 * 1; time = 0.0026s; samplesPerSecond = 6211.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  21-  21, 0.00%]: CE = 0.04807534 * 16; pixelwiseError = 0.50095665 * 16; miouError = 0.67282325 * 1; time = 0.0025s; samplesPerSecond = 6334.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  22-  22, 0.00%]: CE = 0.04771000 * 16; pixelwiseError = 0.50023919 * 16; miouError = 0.67289799 * 1; time = 0.0028s; samplesPerSecond = 5810.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  23-  23, 0.00%]: CE = 0.04764029 * 16; pixelwiseError = 0.50111610 * 16; miouError = 0.67300606 * 1; time = 0.0026s; samplesPerSecond = 6269.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  24-  24, 0.00%]: CE = 0.04776138 * 16; pixelwiseError = 0.50159442 * 16; miouError = 0.67308670 * 1; time = 0.0025s; samplesPerSecond = 6399.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  25-  25, 0.00%]: CE = 0.04778313 * 16; pixelwiseError = 0.50127554 * 16; miouError = 0.67318887 * 1; time = 0.0025s; samplesPerSecond = 6437.3
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  26-  26, 0.00%]: CE = 0.04750790 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67319697 * 1; time = 0.0026s; samplesPerSecond = 6245.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  27-  27, 0.00%]: CE = 0.04693056 * 16; pixelwiseError = 0.50087690 * 16; miouError = 0.67312074 * 1; time = 0.0025s; samplesPerSecond = 6328.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  28-  28, 0.00%]: CE = 0.04714459 * 16; pixelwiseError = 0.50095665 * 16; miouError = 0.67310667 * 1; time = 0.0025s; samplesPerSecond = 6381.6
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  29-  29, 0.00%]: CE = 0.04725987 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67307067 * 1; time = 0.0025s; samplesPerSecond = 6320.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  30-  30, 0.00%]: CE = 0.04727478 * 16; pixelwiseError = 0.49848530 * 16; miouError = 0.67294753 * 1; time = 0.0025s; samplesPerSecond = 6432.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  31-  31, 0.00%]: CE = 0.04711294 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67284286 * 1; time = 0.0025s; samplesPerSecond = 6526.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  32-  32, 0.00%]: CE = 0.04695427 * 16; pixelwiseError = 0.49944198 * 16; miouError = 0.67272568 * 1; time = 0.0025s; samplesPerSecond = 6372.5
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  33-  33, 0.00%]: CE = 0.04690144 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67260265 * 1; time = 0.0025s; samplesPerSecond = 6335.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  34-  34, 0.00%]: CE = 0.04688371 * 16; pixelwiseError = 0.50111604 * 16; miouError = 0.67255402 * 1; time = 0.0027s; samplesPerSecond = 5888.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  35-  35, 0.00%]: CE = 0.04653957 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.67240494 * 1; time = 0.0028s; samplesPerSecond = 5625.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  36-  36, 0.00%]: CE = 0.04644156 * 16; pixelwiseError = 0.49832588 * 16; miouError = 0.67218071 * 1; time = 0.0025s; samplesPerSecond = 6392.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  37-  37, 0.00%]: CE = 0.04687493 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67209351 * 1; time = 0.0025s; samplesPerSecond = 6397.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  38-  38, 0.00%]: CE = 0.04662436 * 16; pixelwiseError = 0.49920282 * 16; miouError = 0.67192173 * 1; time = 0.0025s; samplesPerSecond = 6379.6
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  39-  39, 0.00%]: CE = 0.04632360 * 16; pixelwiseError = 0.49848530 * 16; miouError = 0.67170632 * 1; time = 0.0025s; samplesPerSecond = 6371.7
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  40-  40, 0.00%]: CE = 0.04650132 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.67156243 * 1; time = 0.0028s; samplesPerSecond = 5753.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  41-  41, 0.00%]: CE = 0.04661683 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67143625 * 1; time = 0.0025s; samplesPerSecond = 6426.0
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  42-  42, 0.00%]: CE = 0.04636475 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.67123479 * 1; time = 0.0025s; samplesPerSecond = 6355.5
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  43-  43, 0.00%]: CE = 0.04632140 * 16; pixelwiseError = 0.49872446 * 16; miouError = 0.67102039 * 1; time = 0.0025s; samplesPerSecond = 6277.7
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  44-  44, 0.00%]: CE = 0.04622518 * 16; pixelwiseError = 0.49824616 * 16; miouError = 0.67080921 * 1; time = 0.0025s; samplesPerSecond = 6391.8
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  45-  45, 0.00%]: CE = 0.04666243 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67065656 * 1; time = 0.0025s; samplesPerSecond = 6526.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  46-  46, 0.00%]: CE = 0.04639143 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67052984 * 1; time = 0.0032s; samplesPerSecond = 5020.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  47-  47, 0.00%]: CE = 0.04653831 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67041266 * 1; time = 0.0026s; samplesPerSecond = 6146.3
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  48-  48, 0.00%]: CE = 0.04647608 * 16; pixelwiseError = 0.49816644 * 16; miouError = 0.67024434 * 1; time = 0.0027s; samplesPerSecond = 5941.6
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  49-  49, 0.00%]: CE = 0.04665370 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.67010534 * 1; time = 0.0025s; samplesPerSecond = 6292.3
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  50-  50, 0.00%]: CE = 0.04646923 * 16; pixelwiseError = 0.49912307 * 16; miouError = 0.66996825 * 1; time = 0.0026s; samplesPerSecond = 6040.5
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  51-  51, 0.00%]: CE = 0.04623271 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.66985643 * 1; time = 0.0029s; samplesPerSecond = 5605.6
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  52-  52, 0.00%]: CE = 0.04638717 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66969061 * 1; time = 0.0025s; samplesPerSecond = 6497.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  53-  53, 0.00%]: CE = 0.04618802 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66952890 * 1; time = 0.0025s; samplesPerSecond = 6370.7
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  54-  54, 0.00%]: CE = 0.04628267 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66939855 * 1; time = 0.0025s; samplesPerSecond = 6366.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  55-  55, 0.00%]: CE = 0.04640311 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.66924465 * 1; time = 0.0025s; samplesPerSecond = 6436.6
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  56-  56, 0.00%]: CE = 0.04634180 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.66905826 * 1; time = 0.0025s; samplesPerSecond = 6307.7
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  57-  57, 0.00%]: CE = 0.04644876 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66892511 * 1; time = 0.0025s; samplesPerSecond = 6331.9
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  58-  58, 0.00%]: CE = 0.04599565 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.66880918 * 1; time = 0.0025s; samplesPerSecond = 6300.2
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  59-  59, 0.00%]: CE = 0.04626718 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66868544 * 1; time = 0.0025s; samplesPerSecond = 6375.3
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  60-  60, 0.00%]: CE = 0.04629884 * 16; pixelwiseError = 0.49880418 * 16; miouError = 0.66854924 * 1; time = 0.0025s; samplesPerSecond = 6390.0
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  61-  61, 0.00%]: CE = 0.04630820 * 16; pixelwiseError = 0.49888390 * 16; miouError = 0.66839349 * 1; time = 0.0025s; samplesPerSecond = 6316.1
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  62-  62, 0.00%]: CE = 0.04616638 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66828036 * 1; time = 0.0025s; samplesPerSecond = 6301.4
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  63-  63, 0.00%]: CE = 0.09348039 * 8; pixelwiseError = 0.50015944 * 8; miouError = 0.66822493 * 1; time = 0.0025s; samplesPerSecond = 3145.3
12/09/2017 11:38:20:  Epoch[ 2 of 2]-Minibatch[  64-  64, 0.00%]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.66822493 * 1; time = 0.0004s; samplesPerSecond = 0.0
NcclComm: initialized
12/09/2017 11:38:20: Finished Epoch[ 2 of 2]: [Training] CE = 0.04765253 * 1000; pixelwiseError = 0.49990051 * 1000; miouError = 0.66822493 * 1; totalSamplesSeen = 2000; learningRatePerSample = 0.0099999998; epochTime=0.176704s
NcclComm: initialized
NcclComm: initialized
12/09/2017 11:38:20: Final Results: Minibatch[1-8]: CE = 0.05274026 * 100; pixelwiseError = 0.50051021 * 100; miouError = 0.66819537 * 1
12/09/2017 11:38:20: Finished Epoch[ 2 of 2]: [Validate] CE = 0.05274026 * 100; pixelwiseError = 0.50051021 * 100; miouError = 0.66819537 * 1
12/09/2017 11:38:20: Best epoch per criterion so far: [Validate] CE = 0.052740 (Epoch 2); pixelwiseError = 0.500255 (Epoch 1); miouError = 0.668195 (Epoch 2)
12/09/2017 11:38:20: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_train'
12/09/2017 11:38:20: Best epoch for criterion 'CE' is 2 and model /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_train copied to /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_train_CE
12/09/2017 11:38:20: Best epoch for criterion 'miouError' is 2 and model /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_train copied to /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_train_miouError
12/09/2017 11:38:20: Best epoch for criterion 'pixelwiseError' is 1 and model /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_train.1 copied to /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_train_pixelwiseError

12/09/2017 11:38:20: Action "train" complete.


12/09/2017 11:38:20: ##############################################################################
12/09/2017 11:38:20: #                                                                            #
12/09/2017 11:38:20: # PrepareFCN4ForTest command (edit action)                                   #
12/09/2017 11:38:20: #                                                                            #
12/09/2017 11:38:20: ##############################################################################

featuresFCN4.x._.x.c: using GEMM convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using GEMM convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using GEMM convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
predictionFCN4: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 7 x 7 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using GEMM convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using GEMM convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using GEMM convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.

12/09/2017 11:38:20: Action "edit" complete.


12/09/2017 11:38:20: ##############################################################################
12/09/2017 11:38:20: #                                                                            #
12/09/2017 11:38:20: # TestFCN4 command (test action)                                             #
12/09/2017 11:38:20: #                                                                            #
12/09/2017 11:38:20: ##############################################################################

Load: Loading model file: /tmp/cntk-test-20171209080859.615414/Image_FCN@release_gpu/Models/FCN4_test
Post-processing network...

4 roots:
	CE = ElementTimes()
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 114 nodes to process in pass 1.

Validating --> upsampledFCN4.W = LearnableParameter() :  -> [8 x 8 x 2 x 2]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [4 x 4 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *6]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *6] -> [14 x 14 x 16 x *6]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *6]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *6] -> [14 x 14 x 16 x *6]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *6] -> [7 x 7 x 16 x *6]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *6], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *6], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 2 x *6]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [4 x 4 x 2 x 2], [4 x 4 x 2 x *6] -> [10 x 10 x 2 x *6]
Validating --> predictionFCN4.W = LearnableParameter() :  -> [2 x 16]
Validating --> predictionFCN4 = Convolution (predictionFCN4.W, featuresFCN4) : [2 x 16], [7 x 7 x 16 x *6] -> [7 x 7 x 2 x *6]
Validating --> cropFCN8 = Crop (upsampledFCN8, predictionFCN4) : [10 x 10 x 2 x *6], [7 x 7 x 2 x *6] -> [7 x 7 x 2 x *6]
Validating --> fusionFCN4 = Plus (cropFCN8, predictionFCN4) : [7 x 7 x 2 x *6], [7 x 7 x 2 x *6] -> [7 x 7 x 2 x *6]
Validating --> upsampledFCN4 = Convolution (upsampledFCN4.W, fusionFCN4) : [8 x 8 x 2 x 2], [7 x 7 x 2 x *6] -> [32 x 32 x 2 x *6]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *6]
Validating --> out = Crop (upsampledFCN4, labels, features, labels) : [32 x 32 x 2 x *6], [28 x 28 x 2 x *6], [28 x 28 x 1 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> CE.out_max.r = ReduceElements (out) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.out_shift = Minus (out, CE.out_max.r) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> CE.log_sum.r = ReduceElements (CE.out_shift) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.logits_per_class = ElementTimes (labels, CE.out_shift) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> CE.logits.r = ReduceElements (CE.logits_per_class) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.diff = Minus (CE.log_sum.r, CE.logits.r) : [28 x 28 x 1 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *6]
Validating --> CE.diff_valid = ElementTimes (CE.diff, ignoreMask) : [28 x 28 x 1 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.ce_unnorm = SumElements (CE.diff_valid) : [28 x 28 x 1 x *6] -> [1]
Validating --> CE.norm_factor.z = SumElements (ignoreMask) : [28 x 28 x 1 x *6] -> [1]
Validating --> CE.norm_factor = Reciprocal (CE.norm_factor.z) : [1] -> [1]
Validating --> CE = ElementTimes (CE.ce_unnorm, CE.norm_factor) : [1], [1] -> [1]
Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *6] -> [784 x 2 x *6]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *6] -> [1 x 2 x *6]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *6] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *6] -> [784 x 2 x *6]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *6] -> [1 x 2 x *6]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *6] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *6] -> [1 x *6]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *6] -> [1 x *6]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *6] -> [1 x *6]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *6], [1 x *6] -> [1 x *6]

Validating network. 68 nodes to process in pass 2.


Validating network, final pass.

featuresFCN4.x._.x.c: using cuDNN convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using cuDNN convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using cuDNN convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
predictionFCN4: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 7 x 7 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using cuDNN convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.


Post-processing network...

3 roots:
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 103 nodes to process in pass 1.

Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> upsampledFCN4.W = LearnableParameter() :  -> [8 x 8 x 2 x 2]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [4 x 4 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *5]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *5] -> [14 x 14 x 16 x *5]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *5]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *5] -> [14 x 14 x 16 x *5]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *5] -> [7 x 7 x 16 x *5]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *5], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *5], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 2 x *5]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [4 x 4 x 2 x 2], [4 x 4 x 2 x *5] -> [10 x 10 x 2 x *5]
Validating --> predictionFCN4.W = LearnableParameter() :  -> [2 x 16]
Validating --> predictionFCN4 = Convolution (predictionFCN4.W, featuresFCN4) : [2 x 16], [7 x 7 x 16 x *5] -> [7 x 7 x 2 x *5]
Validating --> cropFCN8 = Crop (upsampledFCN8, predictionFCN4) : [10 x 10 x 2 x *5], [7 x 7 x 2 x *5] -> [7 x 7 x 2 x *5]
Validating --> fusionFCN4 = Plus (cropFCN8, predictionFCN4) : [7 x 7 x 2 x *5], [7 x 7 x 2 x *5] -> [7 x 7 x 2 x *5]
Validating --> upsampledFCN4 = Convolution (upsampledFCN4.W, fusionFCN4) : [8 x 8 x 2 x 2], [7 x 7 x 2 x *5] -> [32 x 32 x 2 x *5]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *5]
Validating --> out = Crop (upsampledFCN4, labels, features, labels) : [32 x 32 x 2 x *5], [28 x 28 x 2 x *5], [28 x 28 x 1 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *5] -> [28 x 28 x 1 x *5]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *5]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *5] -> [784 x 2 x *5]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *5] -> [1 x 2 x *5]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *5] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *5] -> [784 x 2 x *5]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *5] -> [1 x 2 x *5]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *5] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *5] -> [1 x *5]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *5] -> [1 x *5]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *5] -> [1 x *5]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *5], [1 x *5] -> [1 x *5]

Validating network. 56 nodes to process in pass 2.


Validating network, final pass.

upsampledFCN8: using cuDNN convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using cuDNN convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 103 matrices, 53 are shared as 6, and 50 are not shared.

Here are the ones that share memory:
	{ miouError.i : [1 x 2]
	  miouError.miou : [1] }
	{ cropFCN8 : [7 x 7 x 2 x *5]
	  featuresFCN4 : [7 x 7 x 16 x *5]
	  miouError.intersection : [28 x 28 x 2 x *5]
	  miouError.outHardmax.maxVals.r : [28 x 28 x 1 x *5]
	  pixelwiseError.diffs : [28 x 28 x 1 x *5]
	  pixelwiseError.pixelNorm : [1 x *5] }
	{ featuresFCN8.b.x : [4 x 4 x 16 x *5]
	  featuresFCN8.p : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *5]
	  featuresFCN8.x.p : [4 x 4 x 16 x *5]
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *5]
	  miouError.iou : [1 x 2]
	  miouError.outMasked : [28 x 28 x 2 x *5]
	  miouError.reciprocalUnion.z : [1 x 2]
	  miouError.union : [28 x 28 x 2 x *5]
	  miouError.unionByClass.r : [1 x 2 x *5]
	  pixelwiseError.diffs.ElementTimesArgs[0] : [28 x 28 x 1 x *5]
	  pixelwiseError.errSum.r : [1 x *5]
	  predictionFCN4 : [7 x 7 x 2 x *5]
	  predictionFCN8 : [4 x 4 x 2 x *5] }
	{ featuresFCN4.x : [14 x 14 x 16 x *5]
	  featuresFCN4.x._.x.c : [14 x 14 x 16 x *5]
	  featuresFCN8.x.r : [4 x 4 x 16 x *5]
	  out : [28 x 28 x 2 x *5]
	  pixelwiseError.acc._ : [28 x 28 x 2 x *5] }
	{ featuresFCN4.x._ : [14 x 14 x 16 x *5]
	  featuresFCN8.b : [4 x 4 x 16 x *5]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *5]
	  featuresFCN8.x.s : [4 x 4 x 16 x *5]
	  miouError.iouSum.r : [1]
	  miouError.labelMasked : [28 x 28 x 2 x *5]
	  miouError.outHardmax.isMax : [28 x 28 x 2 x *5]
	  miouError.reciprocalUnion : [1 x 2]
	  miouError.u : [1 x 2]
	  pixelwiseError.outHardmax.isMax : [28 x 28 x 2 x *5]
	  upsampledFCN4 : [32 x 32 x 2 x *5] }
	{ featuresFCN8 : [4 x 4 x 16 x *5]
	  featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *5]
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *5]
	  fusionFCN4 : [7 x 7 x 2 x *5]
	  miouError.intersectionFlat : [784 x 2 x *5]
	  miouError.union.MinusArgs[0] : [28 x 28 x 2 x *5]
	  miouError.unionFlat : [784 x 2 x *5]
	  pixelwiseError.acc.r : [28 x 28 x 1 x *5]
	  pixelwiseError.outHardmax.maxVals.r : [28 x 28 x 1 x *5]
	  pixelwiseError.pixelNorm.z.r : [1 x *5]
	  upsampledFCN8 : [10 x 10 x 2 x *5] }

Here are the ones that don't share memory:
	{predictionFCN8.W : [2 x 16]}
	{upsampledFCN4.W : [8 x 8 x 2 x 2]}
	{upsampledFCN8.W : [4 x 4 x 2 x 2]}
	{miouError : [1]}
	{pixelwiseError : [1 x *5]}
	{features : [28 x 28 x 1 x *5]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16]}
	{miouError.norm : [1]}
	{BS.Constants.One : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{miouError.intersectionByClass.r : [1 x 2 x *5]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16]}
	{featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runVariance : [16 x 1]}
	{ignoreMask : [28 x 28 x 1 x *5]}
	{labels : [28 x 28 x 2 x *5]}
	{miouError.norm.z : [1]}
	{miouError.reciprocalUnion.z.PlusArgs[1] : [1]}
	{predictionFCN4.W : [2 x 16]}

NcclComm: initialized
12/09/2017 11:38:21: Minibatch[1-8]: pixelwiseError = 0.50051021 * 100; miouError = 0.66819543 * 1
NcclComm: initialized
12/09/2017 11:38:21: Final Results: Minibatch[1-8]: pixelwiseError = 0.50051021 * 100; miouError = 0.66819543 * 1

12/09/2017 11:38:21: Action "test" complete.

12/09/2017 11:38:21: __COMPLETED__
~MPIWrapperMpi
=== Deleting training and test data