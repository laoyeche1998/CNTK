CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Running /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/cntk_dpt.cntk currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining OutputDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu DeviceId=0 timestamping=true
CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 11:42:11

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/cntk_dpt.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining  OutputDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data
12/09/2017 11:42:11: -------------------------------------------------------------------
12/09/2017 11:42:11: Build info: 

12/09/2017 11:42:11: 		Built time: Dec  8 2017 01:46:20
12/09/2017 11:42:11: 		Last modified date: Wed Nov 15 09:27:10 2017
12/09/2017 11:42:11: 		Build type: release
12/09/2017 11:42:11: 		Build target: GPU
12/09/2017 11:42:11: 		With 1bit-SGD: yes
12/09/2017 11:42:11: 		With ASGD: yes
12/09/2017 11:42:11: 		Math lib: mkl
12/09/2017 11:42:11: 		CUDA version: 9.0.0
12/09/2017 11:42:11: 		CUDNN version: 7.0.4
12/09/2017 11:42:11: 		Build Branch: HEAD
12/09/2017 11:42:11: 		Build SHA1: b130d7735044ce6697bfb963af91445bee740c73
12/09/2017 11:42:11: 		MPI distribution: Open MPI
12/09/2017 11:42:11: 		MPI version: 1.10.7
12/09/2017 11:42:11: -------------------------------------------------------------------
12/09/2017 11:42:11: -------------------------------------------------------------------
12/09/2017 11:42:11: GPU info:

12/09/2017 11:42:11: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
12/09/2017 11:42:11: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_dpt.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:addLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain
configparameters: cntk_dpt.cntk:ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining
configparameters: cntk_dpt.cntk:currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data
configparameters: cntk_dpt.cntk:DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data
configparameters: cntk_dpt.cntk:deviceId=0
configparameters: cntk_dpt.cntk:dptPre1=[
    action = "train"
    modelPath = "/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:dptPre2=[
    action = "train"
    modelPath = "/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_dpt.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_dpt.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_dpt.cntk:ndlMacros=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/macros.txt
configparameters: cntk_dpt.cntk:OutputDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:precision=float
configparameters: cntk_dpt.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    useMersenneTwisterRand=true
    features = [
        dim = 363
        type = "real"
        scpFile = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
        labelMappingFile = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_dpt.cntk:RunDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_dpt.cntk:speechTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech"
    deviceId = 0
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_dpt.cntk:timestamping=true
configparameters: cntk_dpt.cntk:traceLevel=1
12/09/2017 11:42:11: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain
12/09/2017 11:42:11: precision = "float"

12/09/2017 11:42:11: ##############################################################################
12/09/2017 11:42:11: #                                                                            #
12/09/2017 11:42:11: # dptPre1 command (train action)                                             #
12/09/2017 11:42:11: #                                                                            #
12/09/2017 11:42:11: ##############################################################################

12/09/2017 11:42:11: 
Creating virgin network.
NDLBuilder Using GPU 0
SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/glob_0000.scp ... 948 entries
total 132 state names in state list /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/09/2017 11:42:11: 
Model has 19 nodes. Using GPU 0.

12/09/2017 11:42:11: Training criterion:   ce = CrossEntropyWithSoftmax
12/09/2017 11:42:11: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 2 are aliased.
	OL.t (gradient) reuses OL.z (gradient)

Memory Sharing: Out of 29 matrices, 12 are shared as 3, and 17 are not shared.

Here are the ones that share memory:
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ HL1.t : [512 x *]
	  HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *]
	  HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *]
	  OL.t : [132 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }

Here are the ones that don't share memory:
	{scaledLogLikelihood : [132 x 1 x *]}
	{features : [363 x *]}
	{featNorm : [363 x *]}
	{labels : [132 x *]}
	{globalMean : [363 x 1]}
	{globalInvStd : [363 x 1]}
	{globalPrior : [132 x 1]}
	{HL1.W : [512 x 363]}
	{HL1.b : [512 x 1]}
	{OL.W : [132 x 512]}
	{OL.b : [132 x 1]}
	{OL.b : [132 x 1] (gradient)}
	{ce : [1]}
	{OL.W : [132 x 512] (gradient)}
	{logPrior : [132 x 1]}
	{ce : [1] (gradient)}
	{err : [1]}


12/09/2017 11:42:11: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

12/09/2017 11:42:11: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/09/2017 11:42:11: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/09/2017 11:42:11: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/09/2017 11:42:11: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/09/2017 11:42:11: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/09/2017 11:42:11: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/09/2017 11:42:12: Starting minibatch loop.
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 3.77545433 * 2560; err = 0.83984375 * 2560; time = 0.1617s; samplesPerSecond = 15828.6
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.92129173 * 2560; err = 0.69921875 * 2560; time = 0.0078s; samplesPerSecond = 328677.1
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.54243622 * 2560; err = 0.64882812 * 2560; time = 0.0073s; samplesPerSecond = 351696.7
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.20117416 * 2560; err = 0.60156250 * 2560; time = 0.0073s; samplesPerSecond = 353064.5
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.98474121 * 2560; err = 0.55273438 * 2560; time = 0.0069s; samplesPerSecond = 368796.4
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.87129364 * 2560; err = 0.51562500 * 2560; time = 0.0069s; samplesPerSecond = 369568.4
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.83400879 * 2560; err = 0.52812500 * 2560; time = 0.0069s; samplesPerSecond = 370268.6
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.71646271 * 2560; err = 0.49335937 * 2560; time = 0.0068s; samplesPerSecond = 376708.8
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.66541901 * 2560; err = 0.46328125 * 2560; time = 0.0071s; samplesPerSecond = 362914.7
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.57725677 * 2560; err = 0.46054688 * 2560; time = 0.0068s; samplesPerSecond = 377175.0
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.61621246 * 2560; err = 0.45390625 * 2560; time = 0.0074s; samplesPerSecond = 346184.5
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.56063843 * 2560; err = 0.44140625 * 2560; time = 0.0068s; samplesPerSecond = 376575.8
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.52853241 * 2560; err = 0.44492188 * 2560; time = 0.0075s; samplesPerSecond = 343407.5
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.53461304 * 2560; err = 0.46210937 * 2560; time = 0.0072s; samplesPerSecond = 354590.3
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.46378479 * 2560; err = 0.44140625 * 2560; time = 0.0072s; samplesPerSecond = 356923.8
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.43345032 * 2560; err = 0.42617187 * 2560; time = 0.0069s; samplesPerSecond = 371450.5
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.43222961 * 2560; err = 0.42226562 * 2560; time = 0.0070s; samplesPerSecond = 367314.7
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.38003845 * 2560; err = 0.41250000 * 2560; time = 0.0068s; samplesPerSecond = 376061.3
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.35853271 * 2560; err = 0.40039062 * 2560; time = 0.0075s; samplesPerSecond = 339374.0
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.44864807 * 2560; err = 0.42656250 * 2560; time = 0.0072s; samplesPerSecond = 355446.9
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.43953552 * 2560; err = 0.42578125 * 2560; time = 0.0068s; samplesPerSecond = 375989.5
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.41762695 * 2560; err = 0.42617187 * 2560; time = 0.0070s; samplesPerSecond = 366473.4
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.33197937 * 2560; err = 0.40390625 * 2560; time = 0.0068s; samplesPerSecond = 375344.6
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.36100464 * 2560; err = 0.40429688 * 2560; time = 0.0070s; samplesPerSecond = 364464.7
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.30899048 * 2560; err = 0.39648438 * 2560; time = 0.0068s; samplesPerSecond = 377213.9
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.25351562 * 2560; err = 0.36953125 * 2560; time = 0.0071s; samplesPerSecond = 359591.0
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.30351257 * 2560; err = 0.39648438 * 2560; time = 0.0068s; samplesPerSecond = 375592.4
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.36050720 * 2560; err = 0.40898438 * 2560; time = 0.0068s; samplesPerSecond = 379040.3
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.29572754 * 2560; err = 0.39531250 * 2560; time = 0.0070s; samplesPerSecond = 363579.6
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.35762024 * 2560; err = 0.40898438 * 2560; time = 0.0068s; samplesPerSecond = 379017.8
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.32346802 * 2560; err = 0.39843750 * 2560; time = 0.0070s; samplesPerSecond = 364532.2
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.27053833 * 2560; err = 0.38203125 * 2560; time = 0.0066s; samplesPerSecond = 388172.9
12/09/2017 11:42:12: Finished Epoch[ 1 of 2]: [Training] ce = 1.65219517 * 81920; err = 0.46722412 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.456201s
12/09/2017 11:42:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech.1'

12/09/2017 11:42:12: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/09/2017 11:42:12: Starting minibatch loop.
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.24904280 * 2560; err = 0.39492187 * 2560; time = 0.0081s; samplesPerSecond = 314430.6
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.23917685 * 2560; err = 0.36992188 * 2560; time = 0.0074s; samplesPerSecond = 346888.2
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.26081600 * 2560; err = 0.39531250 * 2560; time = 0.0070s; samplesPerSecond = 366080.4
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.26097717 * 2560; err = 0.38281250 * 2560; time = 0.0069s; samplesPerSecond = 370049.1
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.27839279 * 2560; err = 0.36953125 * 2560; time = 0.0069s; samplesPerSecond = 368525.6
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.18358917 * 2560; err = 0.35742188 * 2560; time = 0.0069s; samplesPerSecond = 370456.1
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.19746399 * 2560; err = 0.36992188 * 2560; time = 0.0075s; samplesPerSecond = 340136.1
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.23055496 * 2560; err = 0.37070313 * 2560; time = 0.0069s; samplesPerSecond = 372922.3
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.26867142 * 2560; err = 0.38828125 * 2560; time = 0.0071s; samplesPerSecond = 360345.1
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.24915771 * 2560; err = 0.37500000 * 2560; time = 0.0068s; samplesPerSecond = 374088.5
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.20246201 * 2560; err = 0.36718750 * 2560; time = 0.0071s; samplesPerSecond = 362436.8
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.18079071 * 2560; err = 0.36289063 * 2560; time = 0.0068s; samplesPerSecond = 374696.3
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.16271973 * 2560; err = 0.36523438 * 2560; time = 0.0072s; samplesPerSecond = 356511.2
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.16420593 * 2560; err = 0.36484375 * 2560; time = 0.0071s; samplesPerSecond = 360975.2
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.14631195 * 2560; err = 0.34375000 * 2560; time = 0.0068s; samplesPerSecond = 375956.4
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.11735229 * 2560; err = 0.34609375 * 2560; time = 0.0070s; samplesPerSecond = 363507.3
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.17672577 * 2560; err = 0.35976562 * 2560; time = 0.0068s; samplesPerSecond = 376354.4
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.13726349 * 2560; err = 0.35312500 * 2560; time = 0.0071s; samplesPerSecond = 361403.3
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.14749298 * 2560; err = 0.35390625 * 2560; time = 0.0068s; samplesPerSecond = 374734.7
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.11475067 * 2560; err = 0.33515625 * 2560; time = 0.0074s; samplesPerSecond = 346428.1
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.16500397 * 2560; err = 0.35000000 * 2560; time = 0.0068s; samplesPerSecond = 376481.7
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.14435730 * 2560; err = 0.35234375 * 2560; time = 0.0071s; samplesPerSecond = 362575.4
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.09438171 * 2560; err = 0.34648438 * 2560; time = 0.0068s; samplesPerSecond = 375031.1
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.12633362 * 2560; err = 0.34531250 * 2560; time = 0.0070s; samplesPerSecond = 365844.9
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.09389648 * 2560; err = 0.33867188 * 2560; time = 0.0068s; samplesPerSecond = 375339.1
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.08799744 * 2560; err = 0.32968750 * 2560; time = 0.0068s; samplesPerSecond = 377709.3
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.12633667 * 2560; err = 0.33906250 * 2560; time = 0.0072s; samplesPerSecond = 353327.6
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.12987671 * 2560; err = 0.34375000 * 2560; time = 0.0068s; samplesPerSecond = 376365.4
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.11752319 * 2560; err = 0.34531250 * 2560; time = 0.0070s; samplesPerSecond = 364979.1
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08401489 * 2560; err = 0.32695313 * 2560; time = 0.0068s; samplesPerSecond = 377041.7
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08304138 * 2560; err = 0.34492187 * 2560; time = 0.0071s; samplesPerSecond = 362236.8
12/09/2017 11:42:12:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07171021 * 2560; err = 0.32734375 * 2560; time = 0.0067s; samplesPerSecond = 384540.3
12/09/2017 11:42:12: Finished Epoch[ 2 of 2]: [Training] ce = 1.16538725 * 81920; err = 0.35673828 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.228749s
12/09/2017 11:42:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech'

12/09/2017 11:42:12: Action "train" complete.


12/09/2017 11:42:12: ##############################################################################
12/09/2017 11:42:12: #                                                                            #
12/09/2017 11:42:12: # addLayer2 command (edit action)                                            #
12/09/2017 11:42:12: #                                                                            #
12/09/2017 11:42:12: ##############################################################################


12/09/2017 11:42:12: Action "edit" complete.


12/09/2017 11:42:12: ##############################################################################
12/09/2017 11:42:12: #                                                                            #
12/09/2017 11:42:12: # dptPre2 command (train action)                                             #
12/09/2017 11:42:12: #                                                                            #
12/09/2017 11:42:12: ##############################################################################

12/09/2017 11:42:12: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/glob_0000.scp ... 948 entries
total 132 state names in state list /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/09/2017 11:42:12: 
Model has 24 nodes. Using GPU 0.

12/09/2017 11:42:12: Training criterion:   ce = CrossEntropyWithSoftmax
12/09/2017 11:42:12: Evaluation criterion: err = ClassificationError

12/09/2017 11:42:12: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

12/09/2017 11:42:12: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/09/2017 11:42:12: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/09/2017 11:42:12: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/09/2017 11:42:12: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/09/2017 11:42:12: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/09/2017 11:42:12: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/09/2017 11:42:12: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/09/2017 11:42:12: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/09/2017 11:42:12: Starting minibatch loop.
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 3.95232048 * 2560; err = 0.81835938 * 2560; time = 0.0114s; samplesPerSecond = 224630.4
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.59509544 * 2560; err = 0.63632813 * 2560; time = 0.0088s; samplesPerSecond = 292457.8
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.15305252 * 2560; err = 0.58046875 * 2560; time = 0.0086s; samplesPerSecond = 298615.4
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.80730286 * 2560; err = 0.50039062 * 2560; time = 0.0087s; samplesPerSecond = 293271.9
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.62435303 * 2560; err = 0.47460938 * 2560; time = 0.0085s; samplesPerSecond = 299506.3
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.57792664 * 2560; err = 0.45468750 * 2560; time = 0.0087s; samplesPerSecond = 293164.5
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.57253876 * 2560; err = 0.46523437 * 2560; time = 0.0086s; samplesPerSecond = 297927.3
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.49025574 * 2560; err = 0.45156250 * 2560; time = 0.0088s; samplesPerSecond = 291024.8
12/09/2017 11:42:12:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.43519135 * 2560; err = 0.41289063 * 2560; time = 0.0088s; samplesPerSecond = 289809.1
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.39548492 * 2560; err = 0.41093750 * 2560; time = 0.0085s; samplesPerSecond = 300992.3
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.40931549 * 2560; err = 0.40351562 * 2560; time = 0.0087s; samplesPerSecond = 295237.0
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.35583801 * 2560; err = 0.39492187 * 2560; time = 0.0085s; samplesPerSecond = 300667.1
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.31971741 * 2560; err = 0.38828125 * 2560; time = 0.0088s; samplesPerSecond = 290635.0
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.33088074 * 2560; err = 0.40664062 * 2560; time = 0.0085s; samplesPerSecond = 301392.8
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.27847748 * 2560; err = 0.38242188 * 2560; time = 0.0085s; samplesPerSecond = 300663.6
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.28628845 * 2560; err = 0.39296875 * 2560; time = 0.0085s; samplesPerSecond = 301922.4
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.29282837 * 2560; err = 0.37734375 * 2560; time = 0.0085s; samplesPerSecond = 300751.9
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.26449585 * 2560; err = 0.38867188 * 2560; time = 0.0088s; samplesPerSecond = 290223.1
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.28384094 * 2560; err = 0.38828125 * 2560; time = 0.0085s; samplesPerSecond = 301297.0
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.32117004 * 2560; err = 0.40000000 * 2560; time = 0.0087s; samplesPerSecond = 295919.5
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.30416870 * 2560; err = 0.38085938 * 2560; time = 0.0085s; samplesPerSecond = 301183.6
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.31772766 * 2560; err = 0.39765625 * 2560; time = 0.0087s; samplesPerSecond = 292990.0
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.24123840 * 2560; err = 0.37148437 * 2560; time = 0.0086s; samplesPerSecond = 298264.0
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.26621399 * 2560; err = 0.38476562 * 2560; time = 0.0089s; samplesPerSecond = 286590.7
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.23011169 * 2560; err = 0.37031250 * 2560; time = 0.0088s; samplesPerSecond = 291140.7
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.19255066 * 2560; err = 0.35820313 * 2560; time = 0.0086s; samplesPerSecond = 297584.5
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.20788269 * 2560; err = 0.36914062 * 2560; time = 0.0087s; samplesPerSecond = 295871.7
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.24570618 * 2560; err = 0.37656250 * 2560; time = 0.0085s; samplesPerSecond = 299678.1
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.17422485 * 2560; err = 0.34257813 * 2560; time = 0.0089s; samplesPerSecond = 288512.5
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.17809753 * 2560; err = 0.35312500 * 2560; time = 0.0085s; samplesPerSecond = 299727.2
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.19910583 * 2560; err = 0.35625000 * 2560; time = 0.0087s; samplesPerSecond = 294822.2
12/09/2017 11:42:13:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.15553284 * 2560; err = 0.34570312 * 2560; time = 0.0085s; samplesPerSecond = 300258.0
12/09/2017 11:42:13: Finished Epoch[ 1 of 2]: [Training] ce = 1.48309174 * 81920; err = 0.42297363 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.36s
12/09/2017 11:42:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.1'

12/09/2017 11:42:13: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/09/2017 11:42:13: Starting minibatch loop.
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.16412601 * 2560; err = 0.36210938 * 2560; time = 0.0098s; samplesPerSecond = 261203.2
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.18867970 * 2560; err = 0.35742188 * 2560; time = 0.0086s; samplesPerSecond = 298340.5
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.15690613 * 2560; err = 0.35625000 * 2560; time = 0.0086s; samplesPerSecond = 298883.9
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.15283051 * 2560; err = 0.35390625 * 2560; time = 0.0101s; samplesPerSecond = 252834.5
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.19624062 * 2560; err = 0.35000000 * 2560; time = 0.0086s; samplesPerSecond = 297882.2
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.13569336 * 2560; err = 0.35000000 * 2560; time = 0.0086s; samplesPerSecond = 298890.8
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.14269714 * 2560; err = 0.35390625 * 2560; time = 0.0086s; samplesPerSecond = 299268.2
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.17199554 * 2560; err = 0.36562500 * 2560; time = 0.0086s; samplesPerSecond = 299152.8
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.17918625 * 2560; err = 0.36679688 * 2560; time = 0.0085s; samplesPerSecond = 300585.9
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.19158630 * 2560; err = 0.36484375 * 2560; time = 0.0088s; samplesPerSecond = 291435.7
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.14164963 * 2560; err = 0.34414062 * 2560; time = 0.0087s; samplesPerSecond = 294242.7
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.13930664 * 2560; err = 0.34257813 * 2560; time = 0.0085s; samplesPerSecond = 299881.7
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.09886627 * 2560; err = 0.33906250 * 2560; time = 0.0090s; samplesPerSecond = 285494.4
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.12534027 * 2560; err = 0.34882812 * 2560; time = 0.0085s; samplesPerSecond = 299818.5
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.10109558 * 2560; err = 0.33359375 * 2560; time = 0.0088s; samplesPerSecond = 290213.2
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.08001862 * 2560; err = 0.34101562 * 2560; time = 0.0085s; samplesPerSecond = 300896.8
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.12076874 * 2560; err = 0.33359375 * 2560; time = 0.0085s; samplesPerSecond = 300441.3
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.07955017 * 2560; err = 0.33476563 * 2560; time = 0.0085s; samplesPerSecond = 300212.3
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.11439514 * 2560; err = 0.34531250 * 2560; time = 0.0085s; samplesPerSecond = 300177.1
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.08090973 * 2560; err = 0.32578125 * 2560; time = 0.0086s; samplesPerSecond = 297965.5
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.12362366 * 2560; err = 0.33281250 * 2560; time = 0.0085s; samplesPerSecond = 300907.4
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.09581451 * 2560; err = 0.33554688 * 2560; time = 0.0085s; samplesPerSecond = 300660.0
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.04845886 * 2560; err = 0.32968750 * 2560; time = 0.0085s; samplesPerSecond = 300723.6
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.09396973 * 2560; err = 0.33945313 * 2560; time = 0.0085s; samplesPerSecond = 300677.7
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.09650269 * 2560; err = 0.34140625 * 2560; time = 0.0085s; samplesPerSecond = 300039.8
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.07186279 * 2560; err = 0.32734375 * 2560; time = 0.0085s; samplesPerSecond = 299622.0
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.11242065 * 2560; err = 0.34296875 * 2560; time = 0.0085s; samplesPerSecond = 299881.7
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.09167480 * 2560; err = 0.33437500 * 2560; time = 0.0085s; samplesPerSecond = 300198.2
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.10017090 * 2560; err = 0.34414062 * 2560; time = 0.0086s; samplesPerSecond = 298922.2
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.09057312 * 2560; err = 0.32578125 * 2560; time = 0.0085s; samplesPerSecond = 300865.0
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08012695 * 2560; err = 0.33281250 * 2560; time = 0.0087s; samplesPerSecond = 292839.2
12/09/2017 11:42:13:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07658386 * 2560; err = 0.33593750 * 2560; time = 0.0085s; samplesPerSecond = 299583.4
12/09/2017 11:42:13: Finished Epoch[ 2 of 2]: [Training] ce = 1.12011328 * 81920; err = 0.34349365 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.28507s
12/09/2017 11:42:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech'

12/09/2017 11:42:13: Action "train" complete.


12/09/2017 11:42:13: ##############################################################################
12/09/2017 11:42:13: #                                                                            #
12/09/2017 11:42:13: # addLayer3 command (edit action)                                            #
12/09/2017 11:42:13: #                                                                            #
12/09/2017 11:42:13: ##############################################################################


12/09/2017 11:42:13: Action "edit" complete.


12/09/2017 11:42:13: ##############################################################################
12/09/2017 11:42:13: #                                                                            #
12/09/2017 11:42:13: # speechTrain command (train action)                                         #
12/09/2017 11:42:13: #                                                                            #
12/09/2017 11:42:13: ##############################################################################

12/09/2017 11:42:13: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/glob_0000.scp ... 948 entries
total 132 state names in state list /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/09/2017 11:42:13: 
Model has 29 nodes. Using GPU 0.

12/09/2017 11:42:13: Training criterion:   ce = CrossEntropyWithSoftmax
12/09/2017 11:42:13: Evaluation criterion: err = ClassificationError

12/09/2017 11:42:13: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

12/09/2017 11:42:13: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/09/2017 11:42:13: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/09/2017 11:42:13: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/09/2017 11:42:13: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/09/2017 11:42:13: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
12/09/2017 11:42:13: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
12/09/2017 11:42:13: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/09/2017 11:42:13: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/09/2017 11:42:13: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/09/2017 11:42:13: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/09/2017 11:42:13: Starting minibatch loop.
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.12%]: ce = 4.04514732 * 2560; err = 0.84101563 * 2560; time = 0.0139s; samplesPerSecond = 183937.1
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.57487679 * 2560; err = 0.61679688 * 2560; time = 0.0110s; samplesPerSecond = 232102.7
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.06998596 * 2560; err = 0.56523437 * 2560; time = 0.0110s; samplesPerSecond = 231821.1
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.69130554 * 2560; err = 0.47031250 * 2560; time = 0.0111s; samplesPerSecond = 231193.0
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.62%]: ce = 1.51569901 * 2560; err = 0.43671875 * 2560; time = 0.0110s; samplesPerSecond = 232231.1
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.45793076 * 2560; err = 0.41914062 * 2560; time = 0.0110s; samplesPerSecond = 232632.1
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.46249542 * 2560; err = 0.43203125 * 2560; time = 0.0110s; samplesPerSecond = 232241.7
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.37602081 * 2560; err = 0.40351562 * 2560; time = 0.0110s; samplesPerSecond = 232484.2
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.12%]: ce = 1.32697144 * 2560; err = 0.38632813 * 2560; time = 0.0113s; samplesPerSecond = 225809.3
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.28866119 * 2560; err = 0.37617187 * 2560; time = 0.0111s; samplesPerSecond = 229674.7
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.31844482 * 2560; err = 0.38437500 * 2560; time = 0.0112s; samplesPerSecond = 228927.1
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.27721405 * 2560; err = 0.36992188 * 2560; time = 0.0110s; samplesPerSecond = 232890.3
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.62%]: ce = 1.24465790 * 2560; err = 0.37382813 * 2560; time = 0.0111s; samplesPerSecond = 230782.4
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.25987854 * 2560; err = 0.38710937 * 2560; time = 0.0111s; samplesPerSecond = 230522.6
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.20045929 * 2560; err = 0.35976562 * 2560; time = 0.0110s; samplesPerSecond = 232488.4
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.22033539 * 2560; err = 0.36914062 * 2560; time = 0.0110s; samplesPerSecond = 233100.2
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.12%]: ce = 1.21545715 * 2560; err = 0.36093750 * 2560; time = 0.0110s; samplesPerSecond = 232368.2
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.19536133 * 2560; err = 0.36406250 * 2560; time = 0.0111s; samplesPerSecond = 230630.6
12/09/2017 11:42:13:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.21321716 * 2560; err = 0.36796875 * 2560; time = 0.0110s; samplesPerSecond = 232172.2
12/09/2017 11:42:14:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.25707092 * 2560; err = 0.38085938 * 2560; time = 0.0112s; samplesPerSecond = 228640.8
12/09/2017 11:42:14:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.62%]: ce = 1.25220337 * 2560; err = 0.36484375 * 2560; time = 0.0110s; samplesPerSecond = 232575.0
12/09/2017 11:42:14:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.25466614 * 2560; err = 0.38789062 * 2560; time = 0.0112s; samplesPerSecond = 228982.4
12/09/2017 11:42:14:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.18672180 * 2560; err = 0.35429688 * 2560; time = 0.0110s; samplesPerSecond = 232797.1
12/09/2017 11:42:14:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.21309814 * 2560; err = 0.37539062 * 2560; time = 0.0110s; samplesPerSecond = 232142.7
12/09/2017 11:42:14:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.12%]: ce = 1.18207397 * 2560; err = 0.35585937 * 2560; time = 0.0111s; samplesPerSecond = 231431.3
12/09/2017 11:42:14:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.14777222 * 2560; err = 0.34140625 * 2560; time = 0.0110s; samplesPerSecond = 232581.4
12/09/2017 11:42:14:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.13528748 * 2560; err = 0.35156250 * 2560; time = 0.0110s; samplesPerSecond = 232936.9
12/09/2017 11:42:14:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.19689026 * 2560; err = 0.36328125 * 2560; time = 0.0110s; samplesPerSecond = 232634.2
12/09/2017 11:42:14:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.62%]: ce = 1.13403015 * 2560; err = 0.33554688 * 2560; time = 0.0113s; samplesPerSecond = 227389.8
12/09/2017 11:42:14:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.14353638 * 2560; err = 0.35273437 * 2560; time = 0.0110s; samplesPerSecond = 232233.2
12/09/2017 11:42:14:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.15669556 * 2560; err = 0.34765625 * 2560; time = 0.0111s; samplesPerSecond = 230926.0
12/09/2017 11:42:14:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.10986328 * 2560; err = 0.33359375 * 2560; time = 0.0111s; samplesPerSecond = 231307.9
12/09/2017 11:42:14: Finished Epoch[ 1 of 4]: [Training] ce = 1.41637592 * 81920; err = 0.40404053 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.437721s
12/09/2017 11:42:14: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.1'

12/09/2017 11:42:14: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/09/2017 11:42:14: Starting minibatch loop.
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.26108437 * 5120; err = 0.37500000 * 5120; time = 0.0188s; samplesPerSecond = 272903.7
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.40673923 * 5120; err = 0.40703125 * 5120; time = 0.0167s; samplesPerSecond = 307494.6
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.22149639 * 5120; err = 0.35937500 * 5120; time = 0.0166s; samplesPerSecond = 307688.6
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.13947525 * 5120; err = 0.35195312 * 5120; time = 0.0166s; samplesPerSecond = 308608.5
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.15874138 * 5120; err = 0.35000000 * 5120; time = 0.0168s; samplesPerSecond = 305505.7
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.13039322 * 5120; err = 0.33984375 * 5120; time = 0.0166s; samplesPerSecond = 307842.2
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.10522003 * 5120; err = 0.34609375 * 5120; time = 0.0167s; samplesPerSecond = 307129.4
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07494049 * 5120; err = 0.33437500 * 5120; time = 0.0170s; samplesPerSecond = 301033.0
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.08323288 * 5120; err = 0.32832031 * 5120; time = 0.0166s; samplesPerSecond = 307979.2
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.10492630 * 5120; err = 0.35058594 * 5120; time = 0.0166s; samplesPerSecond = 307585.1
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.09108047 * 5120; err = 0.32636719 * 5120; time = 0.0166s; samplesPerSecond = 307968.1
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.06803894 * 5120; err = 0.33242187 * 5120; time = 0.0166s; samplesPerSecond = 308099.7
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.07306976 * 5120; err = 0.33281250 * 5120; time = 0.0166s; samplesPerSecond = 308300.0
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.20960236 * 5120; err = 0.36835937 * 5120; time = 0.0166s; samplesPerSecond = 308363.1
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.07773590 * 5120; err = 0.32851562 * 5120; time = 0.0168s; samplesPerSecond = 304448.4
12/09/2017 11:42:14:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.05148163 * 5120; err = 0.31875000 * 5120; time = 0.0177s; samplesPerSecond = 289638.6
12/09/2017 11:42:14: Finished Epoch[ 2 of 4]: [Training] ce = 1.14107866 * 81920; err = 0.34686279 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.275554s
12/09/2017 11:42:14: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.2'

12/09/2017 11:42:14: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

12/09/2017 11:42:14: Starting minibatch loop.
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.07412243 * 5120; err = 0.33593750 * 5120; time = 0.0176s; samplesPerSecond = 290157.3
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.09550304 * 5120; err = 0.33242187 * 5120; time = 0.0167s; samplesPerSecond = 306632.7
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.08694725 * 5120; err = 0.33945313 * 5120; time = 0.0167s; samplesPerSecond = 306256.7
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.04788971 * 5120; err = 0.32480469 * 5120; time = 0.0166s; samplesPerSecond = 308049.6
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.07330208 * 5120; err = 0.32773438 * 5120; time = 0.0166s; samplesPerSecond = 308144.2
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.08705254 * 5120; err = 0.33222656 * 5120; time = 0.0167s; samplesPerSecond = 307485.3
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.06946869 * 5120; err = 0.33320312 * 5120; time = 0.0166s; samplesPerSecond = 308094.1
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07995758 * 5120; err = 0.33769531 * 5120; time = 0.0166s; samplesPerSecond = 308324.1
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.10155334 * 5120; err = 0.35058594 * 5120; time = 0.0166s; samplesPerSecond = 308212.8
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.02064209 * 5120; err = 0.31406250 * 5120; time = 0.0166s; samplesPerSecond = 307642.4
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.02912445 * 5120; err = 0.32519531 * 5120; time = 0.0166s; samplesPerSecond = 307655.3
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.05624924 * 5120; err = 0.32734375 * 5120; time = 0.0167s; samplesPerSecond = 307361.7
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.06630859 * 5120; err = 0.33730469 * 5120; time = 0.0166s; samplesPerSecond = 307538.9
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.09063416 * 5120; err = 0.34375000 * 5120; time = 0.0167s; samplesPerSecond = 307478.0
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.02371521 * 5120; err = 0.31660156 * 5120; time = 0.0167s; samplesPerSecond = 307042.8
12/09/2017 11:42:14:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.03207855 * 5120; err = 0.32617188 * 5120; time = 0.0166s; samplesPerSecond = 307781.1
12/09/2017 11:42:14: Finished Epoch[ 3 of 4]: [Training] ce = 1.06465931 * 81920; err = 0.33153076 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.273384s
12/09/2017 11:42:14: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.3'

12/09/2017 11:42:14: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

12/09/2017 11:42:14: Starting minibatch loop.
12/09/2017 11:42:14:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.02240515 * 5120; err = 0.32734375 * 5120; time = 0.0173s; samplesPerSecond = 295124.7
12/09/2017 11:42:14:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.00561662 * 4926; err = 0.31790499 * 4926; time = 0.0373s; samplesPerSecond = 131999.6
12/09/2017 11:42:14:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.02030258 * 5120; err = 0.31718750 * 5120; time = 0.0167s; samplesPerSecond = 307013.3
12/09/2017 11:42:14:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.03147869 * 5120; err = 0.32089844 * 5120; time = 0.0166s; samplesPerSecond = 307962.5
12/09/2017 11:42:14:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.03559341 * 5120; err = 0.32343750 * 5120; time = 0.0167s; samplesPerSecond = 307418.9
12/09/2017 11:42:14:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 0.99760704 * 5120; err = 0.31464844 * 5120; time = 0.0166s; samplesPerSecond = 308480.2
12/09/2017 11:42:15:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.01162643 * 5120; err = 0.31718750 * 5120; time = 0.0166s; samplesPerSecond = 308623.4
12/09/2017 11:42:15:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.00835876 * 5120; err = 0.30839844 * 5120; time = 0.0166s; samplesPerSecond = 308134.9
12/09/2017 11:42:15:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.97858810 * 5120; err = 0.31562500 * 5120; time = 0.0170s; samplesPerSecond = 301716.0
12/09/2017 11:42:15:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.98578568 * 5120; err = 0.30195312 * 5120; time = 0.0167s; samplesPerSecond = 306805.4
12/09/2017 11:42:15:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.03475266 * 5120; err = 0.32089844 * 5120; time = 0.0168s; samplesPerSecond = 305128.8
12/09/2017 11:42:15:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 0.98508987 * 5120; err = 0.30683594 * 5120; time = 0.0166s; samplesPerSecond = 307821.8
12/09/2017 11:42:15:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 0.99634094 * 5120; err = 0.31250000 * 5120; time = 0.0167s; samplesPerSecond = 307383.8
12/09/2017 11:42:15:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.96515045 * 5120; err = 0.29863281 * 5120; time = 0.0166s; samplesPerSecond = 308088.5
12/09/2017 11:42:15:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.97302704 * 5120; err = 0.29843750 * 5120; time = 0.0166s; samplesPerSecond = 307616.5
12/09/2017 11:42:15:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.96172943 * 5120; err = 0.30351563 * 5120; time = 0.0166s; samplesPerSecond = 307836.6
12/09/2017 11:42:15: Finished Epoch[ 4 of 4]: [Training] ce = 1.00105877 * 81920; err = 0.31295166 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.294541s
12/09/2017 11:42:15: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech'

12/09/2017 11:42:15: Action "train" complete.

12/09/2017 11:42:15: __COMPLETED__