CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57700428 kB
-------------------------------------------------------------------
=== Running mpiexec -n 2 /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion/cntkcv.cntk currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion OutputDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu DeviceId=0 timestamping=true numCPUThreads=6 shareNodeValueMatrices=true saveBestModelPerCriterion=true stderr=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr
CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 11:43:52

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion  OutputDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=6  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr
CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 11:43:52

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion  OutputDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=6  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr
Changed current directory to /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data
Changed current directory to /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data
--------------------------------------------------------------------------
[[47200,1],0]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: 4bb8be993ee1

Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: 2 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 2 out of 2 MPI nodes on a single host (2 requested); we (1) are in (participating)
ping [mpihelper]: 2 nodes pinging each other
ping [requestnodes (after change)]: 2 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 2 out of 2 MPI nodes on a single host (2 requested); we (0) are in (participating)
ping [mpihelper]: 2 nodes pinging each other
12/09/2017 11:43:52: Redirecting stderr to file /tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr_speechTrain.logrank0
12/09/2017 11:43:53: Redirecting stderr to file /tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr_speechTrain.logrank1
[4bb8be993ee1:16242] 1 more process has sent help message help-mpi-btl-base.txt / btl:no-nics
[4bb8be993ee1:16242] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
MPI Rank 0: CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 11:43:52
MPI Rank 0: 
MPI Rank 0: /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion  OutputDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=6  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr
MPI Rank 0: 12/09/2017 11:43:52: -------------------------------------------------------------------
MPI Rank 0: 12/09/2017 11:43:52: Build info: 
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:43:52: 		Built time: Dec  8 2017 01:46:20
MPI Rank 0: 12/09/2017 11:43:52: 		Last modified date: Wed Nov 15 09:27:10 2017
MPI Rank 0: 12/09/2017 11:43:52: 		Build type: release
MPI Rank 0: 12/09/2017 11:43:52: 		Build target: GPU
MPI Rank 0: 12/09/2017 11:43:52: 		With 1bit-SGD: yes
MPI Rank 0: 12/09/2017 11:43:52: 		With ASGD: yes
MPI Rank 0: 12/09/2017 11:43:52: 		Math lib: mkl
MPI Rank 0: 12/09/2017 11:43:52: 		CUDA version: 9.0.0
MPI Rank 0: 12/09/2017 11:43:52: 		CUDNN version: 7.0.4
MPI Rank 0: 12/09/2017 11:43:52: 		Build Branch: HEAD
MPI Rank 0: 12/09/2017 11:43:52: 		Build SHA1: b130d7735044ce6697bfb963af91445bee740c73
MPI Rank 0: 12/09/2017 11:43:52: 		MPI distribution: Open MPI
MPI Rank 0: 12/09/2017 11:43:52: 		MPI version: 1.10.7
MPI Rank 0: 12/09/2017 11:43:52: -------------------------------------------------------------------
MPI Rank 0: 12/09/2017 11:43:52: -------------------------------------------------------------------
MPI Rank 0: 12/09/2017 11:43:52: GPU info:
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:43:52: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
MPI Rank 0: 12/09/2017 11:43:52: -------------------------------------------------------------------
MPI Rank 0: 12/09/2017 11:43:52: Using 6 CPU threads.
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:43:52: ##############################################################################
MPI Rank 0: 12/09/2017 11:43:52: #                                                                            #
MPI Rank 0: 12/09/2017 11:43:52: # speechTrain command (train action)                                         #
MPI Rank 0: 12/09/2017 11:43:52: #                                                                            #
MPI Rank 0: 12/09/2017 11:43:52: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:43:52: 
MPI Rank 0: Creating virgin network.
MPI Rank 0: SimpleNetworkBuilder Using GPU 0
MPI Rank 0: Reading script file glob_0000.scp ... 948 entries
MPI Rank 0: HTKDeserializer: selected '948' utterances grouped into '3' chunks, average chunk size: 316.0 utterances, 84244.7 frames (for I/O: 316.0 utterances, 84244.7 frames)
MPI Rank 0: HTKDeserializer: determined feature kind as '33'-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: Total (133) state names in state list '/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/state.list'
MPI Rank 0: MLFDeserializer: '948' utterances with '252734' frames
MPI Rank 0: Reading script file glob_0000.cv.scp ... 300 entries
MPI Rank 0: HTKDeserializer: selected '300' utterances grouped into '1' chunks, average chunk size: 300.0 utterances, 83050.0 frames (for I/O: 300.0 utterances, 83050.0 frames)
MPI Rank 0: HTKDeserializer: determined feature kind as '33'-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: Total (133) state names in state list '/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/state.list'
MPI Rank 0: MLFDeserializer: '948' utterances with '252734' frames
MPI Rank 0: 12/09/2017 11:43:52: 
MPI Rank 0: Model has 25 nodes. Using GPU 0.
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:43:52: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 12/09/2017 11:43:52: Evaluation criterion: EvalClassificationError = ClassificationError
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: Gradient Memory Aliasing: 4 are aliased.
MPI Rank 0: 	W2*H1 (gradient) reuses HLast (gradient)
MPI Rank 0: 	W1*H1 (gradient) reuses W1*H1+B1 (gradient)
MPI Rank 0: 
MPI Rank 0: Memory Sharing: Out of 40 matrices, 21 are shared as 5, and 19 are not shared.
MPI Rank 0: 
MPI Rank 0: Here are the ones that share memory:
MPI Rank 0: 	{ PosteriorProb : [132 x 1 x *]
MPI Rank 0: 	  ScaledLogLikelihood : [132 x 1 x *] }
MPI Rank 0: 	{ B0 : [512 x 1] (gradient)
MPI Rank 0: 	  H1 : [512 x 1 x *] }
MPI Rank 0: 	{ H2 : [512 x 1 x *]
MPI Rank 0: 	  W0*features+B0 : [512 x 1 x *]
MPI Rank 0: 	  W1 : [512 x 512] (gradient)
MPI Rank 0: 	  W1*H1 : [512 x 1 x *] }
MPI Rank 0: 	{ HLast : [132 x 1 x *] (gradient)
MPI Rank 0: 	  W0 : [512 x 363] (gradient)
MPI Rank 0: 	  W0*features+B0 : [512 x 1 x *] (gradient)
MPI Rank 0: 	  W1*H1 : [512 x 1 x *] (gradient)
MPI Rank 0: 	  W1*H1+B1 : [512 x 1 x *]
MPI Rank 0: 	  W1*H1+B1 : [512 x 1 x *] (gradient)
MPI Rank 0: 	  W2*H1 : [132 x 1 x *]
MPI Rank 0: 	  W2*H1 : [132 x 1 x *] (gradient) }
MPI Rank 0: 	{ H1 : [512 x 1 x *] (gradient)
MPI Rank 0: 	  H2 : [512 x 1 x *] (gradient)
MPI Rank 0: 	  HLast : [132 x 1 x *]
MPI Rank 0: 	  W0*features : [512 x *]
MPI Rank 0: 	  W0*features : [512 x *] (gradient) }
MPI Rank 0: 
MPI Rank 0: Here are the ones that don't share memory:
MPI Rank 0: 	{features : [363 x *]}
MPI Rank 0: 	{MeanOfFeatures : [363]}
MPI Rank 0: 	{InvStdOfFeatures : [363]}
MPI Rank 0: 	{W0 : [512 x 363]}
MPI Rank 0: 	{W2 : [132 x 512]}
MPI Rank 0: 	{B2 : [132 x 1]}
MPI Rank 0: 	{labels : [132 x *]}
MPI Rank 0: 	{Prior : [132]}
MPI Rank 0: 	{B0 : [512 x 1]}
MPI Rank 0: 	{W1 : [512 x 512]}
MPI Rank 0: 	{B1 : [512 x 1]}
MPI Rank 0: 	{CrossEntropyWithSoftmax : [1]}
MPI Rank 0: 	{CrossEntropyWithSoftmax : [1] (gradient)}
MPI Rank 0: 	{EvalClassificationError : [1]}
MPI Rank 0: 	{W2 : [132 x 512] (gradient)}
MPI Rank 0: 	{LogOfPrior : [132]}
MPI Rank 0: 	{B2 : [132 x 1] (gradient)}
MPI Rank 0: 	{B1 : [512 x 1] (gradient)}
MPI Rank 0: 	{MVNormalizedFeatures : [363 x *]}
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:43:52: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:43:52: 	Node 'B0' (LearnableParameter operation) : [512 x 1]
MPI Rank 0: 12/09/2017 11:43:52: 	Node 'B1' (LearnableParameter operation) : [512 x 1]
MPI Rank 0: 12/09/2017 11:43:52: 	Node 'B2' (LearnableParameter operation) : [132 x 1]
MPI Rank 0: 12/09/2017 11:43:52: 	Node 'W0' (LearnableParameter operation) : [512 x 363]
MPI Rank 0: 12/09/2017 11:43:52: 	Node 'W1' (LearnableParameter operation) : [512 x 512]
MPI Rank 0: 12/09/2017 11:43:52: 	Node 'W2' (LearnableParameter operation) : [132 x 512]
MPI Rank 0: 
MPI Rank 0: Initializing dataParallelSGD with FP64 aggregation.
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:43:53: Precomputing --> 3 PreCompute nodes found.
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:43:53: 	MeanOfFeatures = Mean()
MPI Rank 0: 12/09/2017 11:43:53: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 12/09/2017 11:43:53: 	Prior = Mean()
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:43:57: Precomputing --> Completed.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:43:57: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:43:57: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[   1-  10, 3.12%]: CrossEntropyWithSoftmax = 4.62512789 * 640; EvalClassificationError = 0.94062500 * 640; time = 0.0699s; samplesPerSecond = 9153.0
MPI Rank 0: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  11-  20, 6.25%]: CrossEntropyWithSoftmax = 4.35619366 * 640; EvalClassificationError = 0.92343750 * 640; time = 0.0633s; samplesPerSecond = 10110.1
MPI Rank 0: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  21-  30, 9.38%]: CrossEntropyWithSoftmax = 3.97911998 * 640; EvalClassificationError = 0.89531250 * 640; time = 0.0638s; samplesPerSecond = 10026.2
MPI Rank 0: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  31-  40, 12.50%]: CrossEntropyWithSoftmax = 3.73643568 * 640; EvalClassificationError = 0.84531250 * 640; time = 0.0652s; samplesPerSecond = 9811.6
MPI Rank 0: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  41-  50, 15.62%]: CrossEntropyWithSoftmax = 3.83079081 * 640; EvalClassificationError = 0.88281250 * 640; time = 0.0633s; samplesPerSecond = 10117.4
MPI Rank 0: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  51-  60, 18.75%]: CrossEntropyWithSoftmax = 3.71437690 * 640; EvalClassificationError = 0.86875000 * 640; time = 0.0641s; samplesPerSecond = 9987.0
MPI Rank 0: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  61-  70, 21.88%]: CrossEntropyWithSoftmax = 3.42186231 * 640; EvalClassificationError = 0.79062500 * 640; time = 0.0643s; samplesPerSecond = 9946.2
MPI Rank 0: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  71-  80, 25.00%]: CrossEntropyWithSoftmax = 3.53658053 * 640; EvalClassificationError = 0.82031250 * 640; time = 0.0663s; samplesPerSecond = 9658.0
MPI Rank 0: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  81-  90, 28.12%]: CrossEntropyWithSoftmax = 3.49758018 * 640; EvalClassificationError = 0.81718750 * 640; time = 0.0642s; samplesPerSecond = 9975.7
MPI Rank 0: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  91- 100, 31.25%]: CrossEntropyWithSoftmax = 3.39996308 * 640; EvalClassificationError = 0.80468750 * 640; time = 0.0720s; samplesPerSecond = 8885.0
MPI Rank 0: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[ 101- 110, 34.38%]: CrossEntropyWithSoftmax = 3.49445773 * 640; EvalClassificationError = 0.82500000 * 640; time = 0.0640s; samplesPerSecond = 9992.8
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 111- 120, 37.50%]: CrossEntropyWithSoftmax = 3.26676999 * 640; EvalClassificationError = 0.79218750 * 640; time = 0.0657s; samplesPerSecond = 9745.4
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 121- 130, 40.62%]: CrossEntropyWithSoftmax = 3.18870174 * 640; EvalClassificationError = 0.78906250 * 640; time = 0.0648s; samplesPerSecond = 9878.1
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 131- 140, 43.75%]: CrossEntropyWithSoftmax = 3.05687264 * 640; EvalClassificationError = 0.74687500 * 640; time = 0.0646s; samplesPerSecond = 9900.1
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 141- 150, 46.88%]: CrossEntropyWithSoftmax = 2.95594570 * 640; EvalClassificationError = 0.71875000 * 640; time = 0.0651s; samplesPerSecond = 9828.7
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 151- 160, 50.00%]: CrossEntropyWithSoftmax = 3.10219605 * 640; EvalClassificationError = 0.74062500 * 640; time = 0.0653s; samplesPerSecond = 9806.1
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 161- 170, 53.12%]: CrossEntropyWithSoftmax = 2.80745016 * 640; EvalClassificationError = 0.70625000 * 640; time = 0.0654s; samplesPerSecond = 9782.5
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 171- 180, 56.25%]: CrossEntropyWithSoftmax = 2.72061843 * 640; EvalClassificationError = 0.65468750 * 640; time = 0.0649s; samplesPerSecond = 9868.2
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 181- 190, 59.38%]: CrossEntropyWithSoftmax = 2.80425748 * 640; EvalClassificationError = 0.71718750 * 640; time = 0.0652s; samplesPerSecond = 9821.8
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 191- 200, 62.50%]: CrossEntropyWithSoftmax = 2.71253069 * 640; EvalClassificationError = 0.67812500 * 640; time = 0.0662s; samplesPerSecond = 9660.9
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 201- 210, 65.62%]: CrossEntropyWithSoftmax = 2.59360400 * 640; EvalClassificationError = 0.66093750 * 640; time = 0.0655s; samplesPerSecond = 9768.6
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 211- 220, 68.75%]: CrossEntropyWithSoftmax = 2.60386650 * 640; EvalClassificationError = 0.65625000 * 640; time = 0.0647s; samplesPerSecond = 9891.1
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 221- 230, 71.88%]: CrossEntropyWithSoftmax = 2.53706679 * 640; EvalClassificationError = 0.65625000 * 640; time = 0.0650s; samplesPerSecond = 9852.8
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 231- 240, 75.00%]: CrossEntropyWithSoftmax = 2.56177344 * 640; EvalClassificationError = 0.65625000 * 640; time = 0.0656s; samplesPerSecond = 9749.4
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 241- 250, 78.12%]: CrossEntropyWithSoftmax = 2.50118792 * 640; EvalClassificationError = 0.64218750 * 640; time = 0.0652s; samplesPerSecond = 9814.0
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 251- 260, 81.25%]: CrossEntropyWithSoftmax = 2.40119789 * 640; EvalClassificationError = 0.62500000 * 640; time = 0.0648s; samplesPerSecond = 9874.6
MPI Rank 0: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 261- 270, 84.38%]: CrossEntropyWithSoftmax = 2.27491504 * 640; EvalClassificationError = 0.58906250 * 640; time = 0.0644s; samplesPerSecond = 9941.8
MPI Rank 0: 12/09/2017 11:43:59:  Epoch[ 1 of 15]-Minibatch[ 271- 280, 87.50%]: CrossEntropyWithSoftmax = 2.51724208 * 640; EvalClassificationError = 0.65781250 * 640; time = 0.0650s; samplesPerSecond = 9839.3
MPI Rank 0: 12/09/2017 11:43:59:  Epoch[ 1 of 15]-Minibatch[ 281- 290, 90.62%]: CrossEntropyWithSoftmax = 2.27797543 * 640; EvalClassificationError = 0.59687500 * 640; time = 0.0653s; samplesPerSecond = 9797.6
MPI Rank 0: 12/09/2017 11:43:59:  Epoch[ 1 of 15]-Minibatch[ 291- 300, 93.75%]: CrossEntropyWithSoftmax = 2.26017741 * 640; EvalClassificationError = 0.60937500 * 640; time = 0.0650s; samplesPerSecond = 9847.5
MPI Rank 0: 12/09/2017 11:43:59:  Epoch[ 1 of 15]-Minibatch[ 301- 310, 96.88%]: CrossEntropyWithSoftmax = 2.24735343 * 640; EvalClassificationError = 0.58437500 * 640; time = 0.0647s; samplesPerSecond = 9897.3
MPI Rank 0: 12/09/2017 11:43:59:  Epoch[ 1 of 15]-Minibatch[ 311- 320, 100.00%]: CrossEntropyWithSoftmax = 2.23665382 * 640; EvalClassificationError = 0.60625000 * 640; time = 0.0660s; samplesPerSecond = 9691.3
MPI Rank 0: 12/09/2017 11:43:59: Finished Epoch[ 1 of 15]: [Training] CrossEntropyWithSoftmax = 3.03815142 * 20480; EvalClassificationError = 0.73432617 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=2.09514s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:01: Final Results: Minibatch[1-1299]: CrossEntropyWithSoftmax = 2.24821048 * 83050; perplexity = 9.47077252; EvalClassificationError = 0.61623119 * 83050
MPI Rank 0: 12/09/2017 11:44:01: Finished Epoch[ 1 of 15]: [Validate] CrossEntropyWithSoftmax = 2.24821048 * 83050; EvalClassificationError = 0.61623119 * 83050
MPI Rank 0: 12/09/2017 11:44:01: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 2.248210 (Epoch 1); EvalClassificationError = 0.616231 (Epoch 1)
MPI Rank 0: 12/09/2017 11:44:01: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.1'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:01: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:01: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:01:  Epoch[ 2 of 15]-Minibatch[   1-  10, 12.50%]: CrossEntropyWithSoftmax = 2.13894071 * 2560; EvalClassificationError = 0.56992188 * 2560; time = 0.1238s; samplesPerSecond = 20671.6
MPI Rank 0: 12/09/2017 11:44:01:  Epoch[ 2 of 15]-Minibatch[  11-  20, 25.00%]: CrossEntropyWithSoftmax = 2.06106261 * 2560; EvalClassificationError = 0.55664062 * 2560; time = 0.1191s; samplesPerSecond = 21501.2
MPI Rank 0: 12/09/2017 11:44:01:  Epoch[ 2 of 15]-Minibatch[  21-  30, 37.50%]: CrossEntropyWithSoftmax = 2.04459475 * 2560; EvalClassificationError = 0.55039063 * 2560; time = 0.1169s; samplesPerSecond = 21908.1
MPI Rank 0: 12/09/2017 11:44:01:  Epoch[ 2 of 15]-Minibatch[  31-  40, 50.00%]: CrossEntropyWithSoftmax = 2.03347291 * 2560; EvalClassificationError = 0.55742187 * 2560; time = 0.1212s; samplesPerSecond = 21126.6
MPI Rank 0: 12/09/2017 11:44:02:  Epoch[ 2 of 15]-Minibatch[  41-  50, 62.50%]: CrossEntropyWithSoftmax = 2.02079287 * 2560; EvalClassificationError = 0.54414063 * 2560; time = 0.1159s; samplesPerSecond = 22085.1
MPI Rank 0: 12/09/2017 11:44:02:  Epoch[ 2 of 15]-Minibatch[  51-  60, 75.00%]: CrossEntropyWithSoftmax = 1.96950012 * 2560; EvalClassificationError = 0.53085938 * 2560; time = 0.1189s; samplesPerSecond = 21530.7
MPI Rank 0: 12/09/2017 11:44:02:  Epoch[ 2 of 15]-Minibatch[  61-  70, 87.50%]: CrossEntropyWithSoftmax = 1.95934863 * 2560; EvalClassificationError = 0.52812500 * 2560; time = 0.1153s; samplesPerSecond = 22197.1
MPI Rank 0: 12/09/2017 11:44:02:  Epoch[ 2 of 15]-Minibatch[  71-  80, 100.00%]: CrossEntropyWithSoftmax = 1.94070839 * 2560; EvalClassificationError = 0.53125000 * 2560; time = 0.1157s; samplesPerSecond = 22132.9
MPI Rank 0: 12/09/2017 11:44:02: Finished Epoch[ 2 of 15]: [Training] CrossEntropyWithSoftmax = 2.02105263 * 20480; EvalClassificationError = 0.54609375 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=0.95125s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:03: Final Results: Minibatch[1-326]: CrossEntropyWithSoftmax = 1.92733488 * 83050; perplexity = 6.87117334; EvalClassificationError = 0.53122216 * 83050
MPI Rank 0: 12/09/2017 11:44:03: Finished Epoch[ 2 of 15]: [Validate] CrossEntropyWithSoftmax = 1.92733488 * 83050; EvalClassificationError = 0.53122216 * 83050
MPI Rank 0: 12/09/2017 11:44:03: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.927335 (Epoch 2); EvalClassificationError = 0.531222 (Epoch 2)
MPI Rank 0: 12/09/2017 11:44:03: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.2'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:03: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:03: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:03:  Epoch[ 3 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.94336420 * 10240; EvalClassificationError = 0.53056641 * 10240; time = 0.3756s; samplesPerSecond = 27261.3
MPI Rank 0: 12/09/2017 11:44:04:  Epoch[ 3 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.96525554 * 10240; EvalClassificationError = 0.54873047 * 10240; time = 0.3563s; samplesPerSecond = 28741.7
MPI Rank 0: 12/09/2017 11:44:04: Finished Epoch[ 3 of 15]: [Training] CrossEntropyWithSoftmax = 1.95430987 * 20480; EvalClassificationError = 0.53964844 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=0.73597s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:05: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.90639119 * 83050; perplexity = 6.72876211; EvalClassificationError = 0.52304636 * 83050
MPI Rank 0: 12/09/2017 11:44:05: Finished Epoch[ 3 of 15]: [Validate] CrossEntropyWithSoftmax = 1.90639119 * 83050; EvalClassificationError = 0.52304636 * 83050
MPI Rank 0: 12/09/2017 11:44:05: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.906391 (Epoch 3); EvalClassificationError = 0.523046 (Epoch 3)
MPI Rank 0: 12/09/2017 11:44:05: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.3'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:05: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:05: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:05:  Epoch[ 4 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.92960398 * 10240; EvalClassificationError = 0.52734375 * 10240; time = 0.3662s; samplesPerSecond = 27963.2
MPI Rank 0: 12/09/2017 11:44:06:  Epoch[ 4 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.91791093 * 10240; EvalClassificationError = 0.52138672 * 10240; time = 0.3584s; samplesPerSecond = 28569.2
MPI Rank 0: 12/09/2017 11:44:06: Finished Epoch[ 4 of 15]: [Training] CrossEntropyWithSoftmax = 1.92375746 * 20480; EvalClassificationError = 0.52436523 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=0.729153s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:06: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.89723688 * 83050; perplexity = 6.66744604; EvalClassificationError = 0.52192655 * 83050
MPI Rank 0: 12/09/2017 11:44:06: Finished Epoch[ 4 of 15]: [Validate] CrossEntropyWithSoftmax = 1.89723688 * 83050; EvalClassificationError = 0.52192655 * 83050
MPI Rank 0: 12/09/2017 11:44:06: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.897237 (Epoch 4); EvalClassificationError = 0.521927 (Epoch 4)
MPI Rank 0: 12/09/2017 11:44:07: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.4'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:07: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:07: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:07:  Epoch[ 5 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.93213905 * 10240; EvalClassificationError = 0.52744141 * 10240; time = 0.3641s; samplesPerSecond = 28123.7
MPI Rank 0: 12/09/2017 11:44:07:  Epoch[ 5 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.91008045 * 10240; EvalClassificationError = 0.52197266 * 10240; time = 0.3595s; samplesPerSecond = 28485.3
MPI Rank 0: 12/09/2017 11:44:07: Finished Epoch[ 5 of 15]: [Training] CrossEntropyWithSoftmax = 1.92110975 * 20480; EvalClassificationError = 0.52470703 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=0.728212s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:08: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.88941575 * 83050; perplexity = 6.61550243; EvalClassificationError = 0.52039735 * 83050
MPI Rank 0: 12/09/2017 11:44:08: Finished Epoch[ 5 of 15]: [Validate] CrossEntropyWithSoftmax = 1.88941575 * 83050; EvalClassificationError = 0.52039735 * 83050
MPI Rank 0: 12/09/2017 11:44:08: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.889416 (Epoch 5); EvalClassificationError = 0.520397 (Epoch 5)
MPI Rank 0: 12/09/2017 11:44:08: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.5'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:08: Starting Epoch 6: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:08: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:09:  Epoch[ 6 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.92107601 * 10240; EvalClassificationError = 0.52783203 * 10240; time = 0.3628s; samplesPerSecond = 28224.9
MPI Rank 0: 12/09/2017 11:44:09:  Epoch[ 6 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.90118051 * 10240; EvalClassificationError = 0.52031250 * 10240; time = 0.3551s; samplesPerSecond = 28836.1
MPI Rank 0: 12/09/2017 11:44:09: Finished Epoch[ 6 of 15]: [Training] CrossEntropyWithSoftmax = 1.91112826 * 20480; EvalClassificationError = 0.52407227 * 20480; totalSamplesSeen = 122880; learningRatePerSample = 9.7656251e-05; epochTime=0.72211s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:10: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.88230716 * 83050; perplexity = 6.56864231; EvalClassificationError = 0.51898856 * 83050
MPI Rank 0: 12/09/2017 11:44:10: Finished Epoch[ 6 of 15]: [Validate] CrossEntropyWithSoftmax = 1.88230716 * 83050; EvalClassificationError = 0.51898856 * 83050
MPI Rank 0: 12/09/2017 11:44:10: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.882307 (Epoch 6); EvalClassificationError = 0.518989 (Epoch 6)
MPI Rank 0: 12/09/2017 11:44:10: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.6'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:10: Starting Epoch 7: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:10: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:10:  Epoch[ 7 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.87751809 * 10240; EvalClassificationError = 0.51201172 * 10240; time = 0.3610s; samplesPerSecond = 28365.0
MPI Rank 0: 12/09/2017 11:44:11:  Epoch[ 7 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.90589643 * 10240; EvalClassificationError = 0.53007812 * 10240; time = 0.3577s; samplesPerSecond = 28627.4
MPI Rank 0: 12/09/2017 11:44:11: Finished Epoch[ 7 of 15]: [Training] CrossEntropyWithSoftmax = 1.89170726 * 20480; EvalClassificationError = 0.52104492 * 20480; totalSamplesSeen = 143360; learningRatePerSample = 9.7656251e-05; epochTime=0.723116s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:12: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.87533201 * 83050; perplexity = 6.52298444; EvalClassificationError = 0.51865141 * 83050
MPI Rank 0: 12/09/2017 11:44:12: Finished Epoch[ 7 of 15]: [Validate] CrossEntropyWithSoftmax = 1.87533201 * 83050; EvalClassificationError = 0.51865141 * 83050
MPI Rank 0: 12/09/2017 11:44:12: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.875332 (Epoch 7); EvalClassificationError = 0.518651 (Epoch 7)
MPI Rank 0: 12/09/2017 11:44:12: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.7'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:12: Starting Epoch 8: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:12: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:12:  Epoch[ 8 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.88190523 * 10240; EvalClassificationError = 0.51777344 * 10240; time = 0.3583s; samplesPerSecond = 28581.4
MPI Rank 0: 12/09/2017 11:44:12:  Epoch[ 8 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.86655063 * 10240; EvalClassificationError = 0.51562500 * 10240; time = 0.3583s; samplesPerSecond = 28580.2
MPI Rank 0: 12/09/2017 11:44:12: Finished Epoch[ 8 of 15]: [Training] CrossEntropyWithSoftmax = 1.87422793 * 20480; EvalClassificationError = 0.51669922 * 20480; totalSamplesSeen = 163840; learningRatePerSample = 9.7656251e-05; epochTime=0.721064s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:13: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.86996773 * 83050; perplexity = 6.48808705; EvalClassificationError = 0.51725467 * 83050
MPI Rank 0: 12/09/2017 11:44:13: Finished Epoch[ 8 of 15]: [Validate] CrossEntropyWithSoftmax = 1.86996773 * 83050; EvalClassificationError = 0.51725467 * 83050
MPI Rank 0: 12/09/2017 11:44:13: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.869968 (Epoch 8); EvalClassificationError = 0.517255 (Epoch 8)
MPI Rank 0: 12/09/2017 11:44:13: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.8'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:13: Starting Epoch 9: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:13: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:14:  Epoch[ 9 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.85947921 * 10240; EvalClassificationError = 0.50673828 * 10240; time = 0.3620s; samplesPerSecond = 28287.1
MPI Rank 0: 12/09/2017 11:44:14:  Epoch[ 9 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.85700426 * 10240; EvalClassificationError = 0.51582031 * 10240; time = 0.3510s; samplesPerSecond = 29177.1
MPI Rank 0: 12/09/2017 11:44:14: Finished Epoch[ 9 of 15]: [Training] CrossEntropyWithSoftmax = 1.85824174 * 20480; EvalClassificationError = 0.51127930 * 20480; totalSamplesSeen = 184320; learningRatePerSample = 9.7656251e-05; epochTime=0.718032s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:15: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.86323873 * 83050; perplexity = 6.44457525; EvalClassificationError = 0.51674895 * 83050
MPI Rank 0: 12/09/2017 11:44:15: Finished Epoch[ 9 of 15]: [Validate] CrossEntropyWithSoftmax = 1.86323873 * 83050; EvalClassificationError = 0.51674895 * 83050
MPI Rank 0: 12/09/2017 11:44:15: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.863239 (Epoch 9); EvalClassificationError = 0.516749 (Epoch 9)
MPI Rank 0: 12/09/2017 11:44:15: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.9'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:15: Starting Epoch 10: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:15: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:16:  Epoch[10 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.89317989 * 10240; EvalClassificationError = 0.52548828 * 10240; time = 0.3542s; samplesPerSecond = 28912.9
MPI Rank 0: 12/09/2017 11:44:16:  Epoch[10 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.84631301 * 10240; EvalClassificationError = 0.50986328 * 10240; time = 0.3494s; samplesPerSecond = 29310.0
MPI Rank 0: 12/09/2017 11:44:16: Finished Epoch[10 of 15]: [Training] CrossEntropyWithSoftmax = 1.86974645 * 20480; EvalClassificationError = 0.51767578 * 20480; totalSamplesSeen = 204800; learningRatePerSample = 9.7656251e-05; epochTime=0.70767s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:17: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.85695611 * 83050; perplexity = 6.40421333; EvalClassificationError = 0.51576159 * 83050
MPI Rank 0: 12/09/2017 11:44:17: Finished Epoch[10 of 15]: [Validate] CrossEntropyWithSoftmax = 1.85695611 * 83050; EvalClassificationError = 0.51576159 * 83050
MPI Rank 0: 12/09/2017 11:44:17: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.856956 (Epoch 10); EvalClassificationError = 0.515762 (Epoch 10)
MPI Rank 0: 12/09/2017 11:44:17: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.10'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:17: Starting Epoch 11: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:17: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:17:  Epoch[11 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.86460008 * 10240; EvalClassificationError = 0.50751953 * 10240; time = 0.3573s; samplesPerSecond = 28660.4
MPI Rank 0: 12/09/2017 11:44:18:  Epoch[11 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.86031159 * 10240; EvalClassificationError = 0.51816406 * 10240; time = 0.3530s; samplesPerSecond = 29009.4
MPI Rank 0: 12/09/2017 11:44:18: Finished Epoch[11 of 15]: [Training] CrossEntropyWithSoftmax = 1.86245583 * 20480; EvalClassificationError = 0.51284180 * 20480; totalSamplesSeen = 225280; learningRatePerSample = 9.7656251e-05; epochTime=0.715101s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:19: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.85008405 * 83050; perplexity = 6.36035408; EvalClassificationError = 0.51326911 * 83050
MPI Rank 0: 12/09/2017 11:44:19: Finished Epoch[11 of 15]: [Validate] CrossEntropyWithSoftmax = 1.85008405 * 83050; EvalClassificationError = 0.51326911 * 83050
MPI Rank 0: 12/09/2017 11:44:19: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.850084 (Epoch 11); EvalClassificationError = 0.513269 (Epoch 11)
MPI Rank 0: 12/09/2017 11:44:19: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.11'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:19: Starting Epoch 12: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:19: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:19:  Epoch[12 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.86700752 * 10240; EvalClassificationError = 0.51181641 * 10240; time = 0.3575s; samplesPerSecond = 28641.7
MPI Rank 0: 12/09/2017 11:44:19:  Epoch[12 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.83390766 * 10240; EvalClassificationError = 0.50585938 * 10240; time = 0.3515s; samplesPerSecond = 29132.0
MPI Rank 0: 12/09/2017 11:44:19: Finished Epoch[12 of 15]: [Training] CrossEntropyWithSoftmax = 1.85045759 * 20480; EvalClassificationError = 0.50883789 * 20480; totalSamplesSeen = 245760; learningRatePerSample = 9.7656251e-05; epochTime=0.714021s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:20: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.84352145 * 83050; perplexity = 6.31875031; EvalClassificationError = 0.51169175 * 83050
MPI Rank 0: 12/09/2017 11:44:20: Finished Epoch[12 of 15]: [Validate] CrossEntropyWithSoftmax = 1.84352145 * 83050; EvalClassificationError = 0.51169175 * 83050
MPI Rank 0: 12/09/2017 11:44:20: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.843521 (Epoch 12); EvalClassificationError = 0.511692 (Epoch 12)
MPI Rank 0: 12/09/2017 11:44:20: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.12'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:20: Starting Epoch 13: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:20: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:21:  Epoch[13 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.84005490 * 10046; EvalClassificationError = 0.51542903 * 10046; time = 0.4086s; samplesPerSecond = 24585.0
MPI Rank 0: 12/09/2017 11:44:21:  Epoch[13 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.87225994 * 10240; EvalClassificationError = 0.51484375 * 10240; time = 0.3439s; samplesPerSecond = 29773.2
MPI Rank 0: 12/09/2017 11:44:21: Finished Epoch[13 of 15]: [Training] CrossEntropyWithSoftmax = 1.85713955 * 20480; EvalClassificationError = 0.51479492 * 20480; totalSamplesSeen = 266240; learningRatePerSample = 9.7656251e-05; epochTime=0.767058s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:22: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.83713385 * 83050; perplexity = 6.27851730; EvalClassificationError = 0.50862131 * 83050
MPI Rank 0: 12/09/2017 11:44:22: Finished Epoch[13 of 15]: [Validate] CrossEntropyWithSoftmax = 1.83713385 * 83050; EvalClassificationError = 0.50862131 * 83050
MPI Rank 0: 12/09/2017 11:44:22: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.837134 (Epoch 13); EvalClassificationError = 0.508621 (Epoch 13)
MPI Rank 0: 12/09/2017 11:44:22: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.13'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:22: Starting Epoch 14: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:22: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:23:  Epoch[14 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.85347546 * 10240; EvalClassificationError = 0.50312500 * 10240; time = 0.4343s; samplesPerSecond = 23580.9
MPI Rank 0: 12/09/2017 11:44:23:  Epoch[14 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.84170081 * 10240; EvalClassificationError = 0.50791016 * 10240; time = 0.3655s; samplesPerSecond = 28013.4
MPI Rank 0: 12/09/2017 11:44:23: Finished Epoch[14 of 15]: [Training] CrossEntropyWithSoftmax = 1.84758814 * 20480; EvalClassificationError = 0.50551758 * 20480; totalSamplesSeen = 286720; learningRatePerSample = 9.7656251e-05; epochTime=0.804193s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:24: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.83143597 * 83050; perplexity = 6.24284478; EvalClassificationError = 0.50930765 * 83050
MPI Rank 0: 12/09/2017 11:44:24: Finished Epoch[14 of 15]: [Validate] CrossEntropyWithSoftmax = 1.83143597 * 83050; EvalClassificationError = 0.50930765 * 83050
MPI Rank 0: 12/09/2017 11:44:24: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.831436 (Epoch 14); EvalClassificationError = 0.508621 (Epoch 13)
MPI Rank 0: 12/09/2017 11:44:24: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.14'
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:24: Starting Epoch 15: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:24: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:25:  Epoch[15 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.81729821 * 10240; EvalClassificationError = 0.50380859 * 10240; time = 0.3660s; samplesPerSecond = 27977.5
MPI Rank 0: 12/09/2017 11:44:25:  Epoch[15 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.84154546 * 10240; EvalClassificationError = 0.51152344 * 10240; time = 0.3487s; samplesPerSecond = 29367.0
MPI Rank 0: 12/09/2017 11:44:25: Finished Epoch[15 of 15]: [Training] CrossEntropyWithSoftmax = 1.82942183 * 20480; EvalClassificationError = 0.50766602 * 20480; totalSamplesSeen = 307200; learningRatePerSample = 9.7656251e-05; epochTime=0.719177s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:26: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.82545027 * 83050; perplexity = 6.20558856; EvalClassificationError = 0.50745334 * 83050
MPI Rank 0: 12/09/2017 11:44:26: Finished Epoch[15 of 15]: [Validate] CrossEntropyWithSoftmax = 1.82545027 * 83050; EvalClassificationError = 0.50745334 * 83050
MPI Rank 0: 12/09/2017 11:44:26: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.825450 (Epoch 15); EvalClassificationError = 0.507453 (Epoch 15)
MPI Rank 0: 12/09/2017 11:44:26: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn'
MPI Rank 0: 12/09/2017 11:44:26: Best epoch for criterion 'CrossEntropyWithSoftmax' is 15 and model /tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn copied to /tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn_CrossEntropyWithSoftmax
MPI Rank 0: 12/09/2017 11:44:26: Best epoch for criterion 'EvalClassificationError' is 15 and model /tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn copied to /tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn_EvalClassificationError
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:26: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:26: __COMPLETED__
MPI Rank 1: CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 11:43:52
MPI Rank 1: 
MPI Rank 1: /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion  OutputDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=6  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr
MPI Rank 1: 12/09/2017 11:43:53: -------------------------------------------------------------------
MPI Rank 1: 12/09/2017 11:43:53: Build info: 
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:43:53: 		Built time: Dec  8 2017 01:46:20
MPI Rank 1: 12/09/2017 11:43:53: 		Last modified date: Wed Nov 15 09:27:10 2017
MPI Rank 1: 12/09/2017 11:43:53: 		Build type: release
MPI Rank 1: 12/09/2017 11:43:53: 		Build target: GPU
MPI Rank 1: 12/09/2017 11:43:53: 		With 1bit-SGD: yes
MPI Rank 1: 12/09/2017 11:43:53: 		With ASGD: yes
MPI Rank 1: 12/09/2017 11:43:53: 		Math lib: mkl
MPI Rank 1: 12/09/2017 11:43:53: 		CUDA version: 9.0.0
MPI Rank 1: 12/09/2017 11:43:53: 		CUDNN version: 7.0.4
MPI Rank 1: 12/09/2017 11:43:53: 		Build Branch: HEAD
MPI Rank 1: 12/09/2017 11:43:53: 		Build SHA1: b130d7735044ce6697bfb963af91445bee740c73
MPI Rank 1: 12/09/2017 11:43:53: 		MPI distribution: Open MPI
MPI Rank 1: 12/09/2017 11:43:53: 		MPI version: 1.10.7
MPI Rank 1: 12/09/2017 11:43:53: -------------------------------------------------------------------
MPI Rank 1: 12/09/2017 11:43:53: -------------------------------------------------------------------
MPI Rank 1: 12/09/2017 11:43:53: GPU info:
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:43:53: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8017 MB
MPI Rank 1: 12/09/2017 11:43:53: -------------------------------------------------------------------
MPI Rank 1: 12/09/2017 11:43:53: Using 6 CPU threads.
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:43:53: ##############################################################################
MPI Rank 1: 12/09/2017 11:43:53: #                                                                            #
MPI Rank 1: 12/09/2017 11:43:53: # speechTrain command (train action)                                         #
MPI Rank 1: 12/09/2017 11:43:53: #                                                                            #
MPI Rank 1: 12/09/2017 11:43:53: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:43:53: 
MPI Rank 1: Creating virgin network.
MPI Rank 1: SimpleNetworkBuilder Using GPU 0
MPI Rank 1: Reading script file glob_0000.scp ... 948 entries
MPI Rank 1: HTKDeserializer: selected '948' utterances grouped into '3' chunks, average chunk size: 316.0 utterances, 84244.7 frames (for I/O: 316.0 utterances, 84244.7 frames)
MPI Rank 1: HTKDeserializer: determined feature kind as '33'-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: Total (133) state names in state list '/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/state.list'
MPI Rank 1: MLFDeserializer: '948' utterances with '252734' frames
MPI Rank 1: Reading script file glob_0000.cv.scp ... 300 entries
MPI Rank 1: HTKDeserializer: selected '300' utterances grouped into '1' chunks, average chunk size: 300.0 utterances, 83050.0 frames (for I/O: 300.0 utterances, 83050.0 frames)
MPI Rank 1: HTKDeserializer: determined feature kind as '33'-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: Total (133) state names in state list '/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/state.list'
MPI Rank 1: MLFDeserializer: '948' utterances with '252734' frames
MPI Rank 1: 12/09/2017 11:43:53: 
MPI Rank 1: Model has 25 nodes. Using GPU 0.
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:43:53: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 12/09/2017 11:43:53: Evaluation criterion: EvalClassificationError = ClassificationError
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: Gradient Memory Aliasing: 4 are aliased.
MPI Rank 1: 	W2*H1 (gradient) reuses HLast (gradient)
MPI Rank 1: 	W1*H1 (gradient) reuses W1*H1+B1 (gradient)
MPI Rank 1: 
MPI Rank 1: Memory Sharing: Out of 40 matrices, 21 are shared as 5, and 19 are not shared.
MPI Rank 1: 
MPI Rank 1: Here are the ones that share memory:
MPI Rank 1: 	{ PosteriorProb : [132 x 1 x *]
MPI Rank 1: 	  ScaledLogLikelihood : [132 x 1 x *] }
MPI Rank 1: 	{ HLast : [132 x 1 x *] (gradient)
MPI Rank 1: 	  W0 : [512 x 363] (gradient)
MPI Rank 1: 	  W0*features+B0 : [512 x 1 x *] (gradient)
MPI Rank 1: 	  W1*H1 : [512 x 1 x *] (gradient)
MPI Rank 1: 	  W1*H1+B1 : [512 x 1 x *]
MPI Rank 1: 	  W1*H1+B1 : [512 x 1 x *] (gradient)
MPI Rank 1: 	  W2*H1 : [132 x 1 x *]
MPI Rank 1: 	  W2*H1 : [132 x 1 x *] (gradient) }
MPI Rank 1: 	{ B0 : [512 x 1] (gradient)
MPI Rank 1: 	  H1 : [512 x 1 x *] }
MPI Rank 1: 	{ H1 : [512 x 1 x *] (gradient)
MPI Rank 1: 	  H2 : [512 x 1 x *] (gradient)
MPI Rank 1: 	  HLast : [132 x 1 x *]
MPI Rank 1: 	  W0*features : [512 x *]
MPI Rank 1: 	  W0*features : [512 x *] (gradient) }
MPI Rank 1: 	{ H2 : [512 x 1 x *]
MPI Rank 1: 	  W0*features+B0 : [512 x 1 x *]
MPI Rank 1: 	  W1 : [512 x 512] (gradient)
MPI Rank 1: 	  W1*H1 : [512 x 1 x *] }
MPI Rank 1: 
MPI Rank 1: Here are the ones that don't share memory:
MPI Rank 1: 	{features : [363 x *]}
MPI Rank 1: 	{MeanOfFeatures : [363]}
MPI Rank 1: 	{InvStdOfFeatures : [363]}
MPI Rank 1: 	{W0 : [512 x 363]}
MPI Rank 1: 	{B0 : [512 x 1]}
MPI Rank 1: 	{W1 : [512 x 512]}
MPI Rank 1: 	{B1 : [512 x 1]}
MPI Rank 1: 	{W2 : [132 x 512]}
MPI Rank 1: 	{B2 : [132 x 1]}
MPI Rank 1: 	{labels : [132 x *]}
MPI Rank 1: 	{Prior : [132]}
MPI Rank 1: 	{CrossEntropyWithSoftmax : [1]}
MPI Rank 1: 	{EvalClassificationError : [1]}
MPI Rank 1: 	{B1 : [512 x 1] (gradient)}
MPI Rank 1: 	{LogOfPrior : [132]}
MPI Rank 1: 	{MVNormalizedFeatures : [363 x *]}
MPI Rank 1: 	{CrossEntropyWithSoftmax : [1] (gradient)}
MPI Rank 1: 	{W2 : [132 x 512] (gradient)}
MPI Rank 1: 	{B2 : [132 x 1] (gradient)}
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:43:53: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:43:53: 	Node 'B0' (LearnableParameter operation) : [512 x 1]
MPI Rank 1: 12/09/2017 11:43:53: 	Node 'B1' (LearnableParameter operation) : [512 x 1]
MPI Rank 1: 12/09/2017 11:43:53: 	Node 'B2' (LearnableParameter operation) : [132 x 1]
MPI Rank 1: 12/09/2017 11:43:53: 	Node 'W0' (LearnableParameter operation) : [512 x 363]
MPI Rank 1: 12/09/2017 11:43:53: 	Node 'W1' (LearnableParameter operation) : [512 x 512]
MPI Rank 1: 12/09/2017 11:43:53: 	Node 'W2' (LearnableParameter operation) : [132 x 512]
MPI Rank 1: 
MPI Rank 1: Initializing dataParallelSGD with FP64 aggregation.
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:43:53: Precomputing --> 3 PreCompute nodes found.
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:43:53: 	MeanOfFeatures = Mean()
MPI Rank 1: 12/09/2017 11:43:53: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 12/09/2017 11:43:53: 	Prior = Mean()
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:43:57: Precomputing --> Completed.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:43:57: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:43:57: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[   1-  10, 3.12%]: CrossEntropyWithSoftmax = 4.62512789 * 640; EvalClassificationError = 0.94062500 * 640; time = 0.0695s; samplesPerSecond = 9212.7
MPI Rank 1: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  11-  20, 6.25%]: CrossEntropyWithSoftmax = 4.35619366 * 640; EvalClassificationError = 0.92343750 * 640; time = 0.0633s; samplesPerSecond = 10112.5
MPI Rank 1: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  21-  30, 9.38%]: CrossEntropyWithSoftmax = 3.97911998 * 640; EvalClassificationError = 0.89531250 * 640; time = 0.0638s; samplesPerSecond = 10027.8
MPI Rank 1: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  31-  40, 12.50%]: CrossEntropyWithSoftmax = 3.73643568 * 640; EvalClassificationError = 0.84531250 * 640; time = 0.0652s; samplesPerSecond = 9811.8
MPI Rank 1: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  41-  50, 15.62%]: CrossEntropyWithSoftmax = 3.83079081 * 640; EvalClassificationError = 0.88281250 * 640; time = 0.0632s; samplesPerSecond = 10122.0
MPI Rank 1: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  51-  60, 18.75%]: CrossEntropyWithSoftmax = 3.71437690 * 640; EvalClassificationError = 0.86875000 * 640; time = 0.0641s; samplesPerSecond = 9988.6
MPI Rank 1: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  61-  70, 21.88%]: CrossEntropyWithSoftmax = 3.42186231 * 640; EvalClassificationError = 0.79062500 * 640; time = 0.0643s; samplesPerSecond = 9947.1
MPI Rank 1: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  71-  80, 25.00%]: CrossEntropyWithSoftmax = 3.53658053 * 640; EvalClassificationError = 0.82031250 * 640; time = 0.0662s; samplesPerSecond = 9660.5
MPI Rank 1: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  81-  90, 28.12%]: CrossEntropyWithSoftmax = 3.49758018 * 640; EvalClassificationError = 0.81718750 * 640; time = 0.0641s; samplesPerSecond = 9978.0
MPI Rank 1: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[  91- 100, 31.25%]: CrossEntropyWithSoftmax = 3.39996308 * 640; EvalClassificationError = 0.80468750 * 640; time = 0.0720s; samplesPerSecond = 8888.1
MPI Rank 1: 12/09/2017 11:43:57:  Epoch[ 1 of 15]-Minibatch[ 101- 110, 34.38%]: CrossEntropyWithSoftmax = 3.49445773 * 640; EvalClassificationError = 0.82500000 * 640; time = 0.0649s; samplesPerSecond = 9864.2
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 111- 120, 37.50%]: CrossEntropyWithSoftmax = 3.26676999 * 640; EvalClassificationError = 0.79218750 * 640; time = 0.0648s; samplesPerSecond = 9876.1
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 121- 130, 40.62%]: CrossEntropyWithSoftmax = 3.18870174 * 640; EvalClassificationError = 0.78906250 * 640; time = 0.0648s; samplesPerSecond = 9880.6
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 131- 140, 43.75%]: CrossEntropyWithSoftmax = 3.05687264 * 640; EvalClassificationError = 0.74687500 * 640; time = 0.0649s; samplesPerSecond = 9867.6
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 141- 150, 46.88%]: CrossEntropyWithSoftmax = 2.95594570 * 640; EvalClassificationError = 0.71875000 * 640; time = 0.0649s; samplesPerSecond = 9862.9
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 151- 160, 50.00%]: CrossEntropyWithSoftmax = 3.10219605 * 640; EvalClassificationError = 0.74062500 * 640; time = 0.0653s; samplesPerSecond = 9808.3
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 161- 170, 53.12%]: CrossEntropyWithSoftmax = 2.80745016 * 640; EvalClassificationError = 0.70625000 * 640; time = 0.0654s; samplesPerSecond = 9782.9
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 171- 180, 56.25%]: CrossEntropyWithSoftmax = 2.72061843 * 640; EvalClassificationError = 0.65468750 * 640; time = 0.0648s; samplesPerSecond = 9871.6
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 181- 190, 59.38%]: CrossEntropyWithSoftmax = 2.80425748 * 640; EvalClassificationError = 0.71718750 * 640; time = 0.0652s; samplesPerSecond = 9821.0
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 191- 200, 62.50%]: CrossEntropyWithSoftmax = 2.71253069 * 640; EvalClassificationError = 0.67812500 * 640; time = 0.0672s; samplesPerSecond = 9529.5
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 201- 210, 65.62%]: CrossEntropyWithSoftmax = 2.59360400 * 640; EvalClassificationError = 0.66093750 * 640; time = 0.0646s; samplesPerSecond = 9909.2
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 211- 220, 68.75%]: CrossEntropyWithSoftmax = 2.60386650 * 640; EvalClassificationError = 0.65625000 * 640; time = 0.0647s; samplesPerSecond = 9893.7
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 221- 230, 71.88%]: CrossEntropyWithSoftmax = 2.53706679 * 640; EvalClassificationError = 0.65625000 * 640; time = 0.0650s; samplesPerSecond = 9852.5
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 231- 240, 75.00%]: CrossEntropyWithSoftmax = 2.56177344 * 640; EvalClassificationError = 0.65625000 * 640; time = 0.0656s; samplesPerSecond = 9754.1
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 241- 250, 78.12%]: CrossEntropyWithSoftmax = 2.50118792 * 640; EvalClassificationError = 0.64218750 * 640; time = 0.0653s; samplesPerSecond = 9805.3
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 251- 260, 81.25%]: CrossEntropyWithSoftmax = 2.40119789 * 640; EvalClassificationError = 0.62500000 * 640; time = 0.0647s; samplesPerSecond = 9891.5
MPI Rank 1: 12/09/2017 11:43:58:  Epoch[ 1 of 15]-Minibatch[ 261- 270, 84.38%]: CrossEntropyWithSoftmax = 2.27491504 * 640; EvalClassificationError = 0.58906250 * 640; time = 0.0644s; samplesPerSecond = 9941.9
MPI Rank 1: 12/09/2017 11:43:59:  Epoch[ 1 of 15]-Minibatch[ 271- 280, 87.50%]: CrossEntropyWithSoftmax = 2.51724208 * 640; EvalClassificationError = 0.65781250 * 640; time = 0.0650s; samplesPerSecond = 9840.8
MPI Rank 1: 12/09/2017 11:43:59:  Epoch[ 1 of 15]-Minibatch[ 281- 290, 90.62%]: CrossEntropyWithSoftmax = 2.27797543 * 640; EvalClassificationError = 0.59687500 * 640; time = 0.0653s; samplesPerSecond = 9799.7
MPI Rank 1: 12/09/2017 11:43:59:  Epoch[ 1 of 15]-Minibatch[ 291- 300, 93.75%]: CrossEntropyWithSoftmax = 2.26017741 * 640; EvalClassificationError = 0.60937500 * 640; time = 0.0650s; samplesPerSecond = 9848.2
MPI Rank 1: 12/09/2017 11:43:59:  Epoch[ 1 of 15]-Minibatch[ 301- 310, 96.88%]: CrossEntropyWithSoftmax = 2.24735343 * 640; EvalClassificationError = 0.58437500 * 640; time = 0.0647s; samplesPerSecond = 9899.0
MPI Rank 1: 12/09/2017 11:43:59:  Epoch[ 1 of 15]-Minibatch[ 311- 320, 100.00%]: CrossEntropyWithSoftmax = 2.23665382 * 640; EvalClassificationError = 0.60625000 * 640; time = 0.0660s; samplesPerSecond = 9696.8
MPI Rank 1: 12/09/2017 11:43:59: Finished Epoch[ 1 of 15]: [Training] CrossEntropyWithSoftmax = 3.03815142 * 20480; EvalClassificationError = 0.73432617 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=2.09473s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:01: Final Results: Minibatch[1-1299]: CrossEntropyWithSoftmax = 2.24821048 * 83050; perplexity = 9.47077252; EvalClassificationError = 0.61623119 * 83050
MPI Rank 1: 12/09/2017 11:44:01: Finished Epoch[ 1 of 15]: [Validate] CrossEntropyWithSoftmax = 2.24821048 * 83050; EvalClassificationError = 0.61623119 * 83050
MPI Rank 1: 12/09/2017 11:44:01: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 2.248210 (Epoch 1); EvalClassificationError = 0.616231 (Epoch 1)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:01: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:01: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:01:  Epoch[ 2 of 15]-Minibatch[   1-  10, 12.50%]: CrossEntropyWithSoftmax = 2.13894071 * 2560; EvalClassificationError = 0.56992188 * 2560; time = 0.1242s; samplesPerSecond = 20607.3
MPI Rank 1: 12/09/2017 11:44:01:  Epoch[ 2 of 15]-Minibatch[  11-  20, 25.00%]: CrossEntropyWithSoftmax = 2.06106261 * 2560; EvalClassificationError = 0.55664062 * 2560; time = 0.1191s; samplesPerSecond = 21495.7
MPI Rank 1: 12/09/2017 11:44:01:  Epoch[ 2 of 15]-Minibatch[  21-  30, 37.50%]: CrossEntropyWithSoftmax = 2.04459475 * 2560; EvalClassificationError = 0.55039063 * 2560; time = 0.1160s; samplesPerSecond = 22071.2
MPI Rank 1: 12/09/2017 11:44:01:  Epoch[ 2 of 15]-Minibatch[  31-  40, 50.00%]: CrossEntropyWithSoftmax = 2.03347291 * 2560; EvalClassificationError = 0.55742187 * 2560; time = 0.1215s; samplesPerSecond = 21069.9
MPI Rank 1: 12/09/2017 11:44:02:  Epoch[ 2 of 15]-Minibatch[  41-  50, 62.50%]: CrossEntropyWithSoftmax = 2.02079287 * 2560; EvalClassificationError = 0.54414063 * 2560; time = 0.1155s; samplesPerSecond = 22160.0
MPI Rank 1: 12/09/2017 11:44:02:  Epoch[ 2 of 15]-Minibatch[  51-  60, 75.00%]: CrossEntropyWithSoftmax = 1.96950012 * 2560; EvalClassificationError = 0.53085938 * 2560; time = 0.1189s; samplesPerSecond = 21533.5
MPI Rank 1: 12/09/2017 11:44:02:  Epoch[ 2 of 15]-Minibatch[  61-  70, 87.50%]: CrossEntropyWithSoftmax = 1.95934863 * 2560; EvalClassificationError = 0.52812500 * 2560; time = 0.1153s; samplesPerSecond = 22203.1
MPI Rank 1: 12/09/2017 11:44:02:  Epoch[ 2 of 15]-Minibatch[  71-  80, 100.00%]: CrossEntropyWithSoftmax = 1.94070839 * 2560; EvalClassificationError = 0.53125000 * 2560; time = 0.1156s; samplesPerSecond = 22137.2
MPI Rank 1: 12/09/2017 11:44:02: Finished Epoch[ 2 of 15]: [Training] CrossEntropyWithSoftmax = 2.02105263 * 20480; EvalClassificationError = 0.54609375 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=0.951664s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:03: Final Results: Minibatch[1-326]: CrossEntropyWithSoftmax = 1.92733488 * 83050; perplexity = 6.87117334; EvalClassificationError = 0.53122216 * 83050
MPI Rank 1: 12/09/2017 11:44:03: Finished Epoch[ 2 of 15]: [Validate] CrossEntropyWithSoftmax = 1.92733488 * 83050; EvalClassificationError = 0.53122216 * 83050
MPI Rank 1: 12/09/2017 11:44:03: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.927335 (Epoch 2); EvalClassificationError = 0.531222 (Epoch 2)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:03: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:03: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:03:  Epoch[ 3 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.94336420 * 10240; EvalClassificationError = 0.53056641 * 10240; time = 0.3754s; samplesPerSecond = 27275.5
MPI Rank 1: 12/09/2017 11:44:04:  Epoch[ 3 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.96525554 * 10240; EvalClassificationError = 0.54873047 * 10240; time = 0.3562s; samplesPerSecond = 28747.5
MPI Rank 1: 12/09/2017 11:44:04: Finished Epoch[ 3 of 15]: [Training] CrossEntropyWithSoftmax = 1.95430987 * 20480; EvalClassificationError = 0.53964844 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=0.736363s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:05: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.90639119 * 83050; perplexity = 6.72876211; EvalClassificationError = 0.52304636 * 83050
MPI Rank 1: 12/09/2017 11:44:05: Finished Epoch[ 3 of 15]: [Validate] CrossEntropyWithSoftmax = 1.90639119 * 83050; EvalClassificationError = 0.52304636 * 83050
MPI Rank 1: 12/09/2017 11:44:05: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.906391 (Epoch 3); EvalClassificationError = 0.523046 (Epoch 3)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:05: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:05: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:05:  Epoch[ 4 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.92960398 * 10240; EvalClassificationError = 0.52734375 * 10240; time = 0.3667s; samplesPerSecond = 27921.8
MPI Rank 1: 12/09/2017 11:44:06:  Epoch[ 4 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.91791093 * 10240; EvalClassificationError = 0.52138672 * 10240; time = 0.3576s; samplesPerSecond = 28635.1
MPI Rank 1: 12/09/2017 11:44:06: Finished Epoch[ 4 of 15]: [Training] CrossEntropyWithSoftmax = 1.92375746 * 20480; EvalClassificationError = 0.52436523 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=0.728713s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:06: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.89723688 * 83050; perplexity = 6.66744604; EvalClassificationError = 0.52192655 * 83050
MPI Rank 1: 12/09/2017 11:44:06: Finished Epoch[ 4 of 15]: [Validate] CrossEntropyWithSoftmax = 1.89723688 * 83050; EvalClassificationError = 0.52192655 * 83050
MPI Rank 1: 12/09/2017 11:44:06: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.897237 (Epoch 4); EvalClassificationError = 0.521927 (Epoch 4)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:07: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:07: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:07:  Epoch[ 5 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.93213905 * 10240; EvalClassificationError = 0.52744141 * 10240; time = 0.3638s; samplesPerSecond = 28148.8
MPI Rank 1: 12/09/2017 11:44:07:  Epoch[ 5 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.91008045 * 10240; EvalClassificationError = 0.52197266 * 10240; time = 0.3594s; samplesPerSecond = 28489.1
MPI Rank 1: 12/09/2017 11:44:07: Finished Epoch[ 5 of 15]: [Training] CrossEntropyWithSoftmax = 1.92110975 * 20480; EvalClassificationError = 0.52470703 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=0.727781s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:08: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.88941575 * 83050; perplexity = 6.61550243; EvalClassificationError = 0.52039735 * 83050
MPI Rank 1: 12/09/2017 11:44:08: Finished Epoch[ 5 of 15]: [Validate] CrossEntropyWithSoftmax = 1.88941575 * 83050; EvalClassificationError = 0.52039735 * 83050
MPI Rank 1: 12/09/2017 11:44:08: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.889416 (Epoch 5); EvalClassificationError = 0.520397 (Epoch 5)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:08: Starting Epoch 6: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:08: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:09:  Epoch[ 6 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.92107601 * 10240; EvalClassificationError = 0.52783203 * 10240; time = 0.3625s; samplesPerSecond = 28250.0
MPI Rank 1: 12/09/2017 11:44:09:  Epoch[ 6 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.90118051 * 10240; EvalClassificationError = 0.52031250 * 10240; time = 0.3551s; samplesPerSecond = 28840.2
MPI Rank 1: 12/09/2017 11:44:09: Finished Epoch[ 6 of 15]: [Training] CrossEntropyWithSoftmax = 1.91112826 * 20480; EvalClassificationError = 0.52407227 * 20480; totalSamplesSeen = 122880; learningRatePerSample = 9.7656251e-05; epochTime=0.721684s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:10: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.88230716 * 83050; perplexity = 6.56864231; EvalClassificationError = 0.51898856 * 83050
MPI Rank 1: 12/09/2017 11:44:10: Finished Epoch[ 6 of 15]: [Validate] CrossEntropyWithSoftmax = 1.88230716 * 83050; EvalClassificationError = 0.51898856 * 83050
MPI Rank 1: 12/09/2017 11:44:10: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.882307 (Epoch 6); EvalClassificationError = 0.518989 (Epoch 6)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:10: Starting Epoch 7: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:10: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:10:  Epoch[ 7 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.87751809 * 10240; EvalClassificationError = 0.51201172 * 10240; time = 0.3605s; samplesPerSecond = 28401.7
MPI Rank 1: 12/09/2017 11:44:11:  Epoch[ 7 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.90589643 * 10240; EvalClassificationError = 0.53007812 * 10240; time = 0.3577s; samplesPerSecond = 28631.2
MPI Rank 1: 12/09/2017 11:44:11: Finished Epoch[ 7 of 15]: [Training] CrossEntropyWithSoftmax = 1.89170726 * 20480; EvalClassificationError = 0.52104492 * 20480; totalSamplesSeen = 143360; learningRatePerSample = 9.7656251e-05; epochTime=0.72269s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:12: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.87533201 * 83050; perplexity = 6.52298444; EvalClassificationError = 0.51865141 * 83050
MPI Rank 1: 12/09/2017 11:44:12: Finished Epoch[ 7 of 15]: [Validate] CrossEntropyWithSoftmax = 1.87533201 * 83050; EvalClassificationError = 0.51865141 * 83050
MPI Rank 1: 12/09/2017 11:44:12: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.875332 (Epoch 7); EvalClassificationError = 0.518651 (Epoch 7)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:12: Starting Epoch 8: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:12: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:12:  Epoch[ 8 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.88190523 * 10240; EvalClassificationError = 0.51777344 * 10240; time = 0.3578s; samplesPerSecond = 28619.2
MPI Rank 1: 12/09/2017 11:44:12:  Epoch[ 8 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.86655063 * 10240; EvalClassificationError = 0.51562500 * 10240; time = 0.3582s; samplesPerSecond = 28585.7
MPI Rank 1: 12/09/2017 11:44:12: Finished Epoch[ 8 of 15]: [Training] CrossEntropyWithSoftmax = 1.87422793 * 20480; EvalClassificationError = 0.51669922 * 20480; totalSamplesSeen = 163840; learningRatePerSample = 9.7656251e-05; epochTime=0.72065s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:13: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.86996773 * 83050; perplexity = 6.48808705; EvalClassificationError = 0.51725467 * 83050
MPI Rank 1: 12/09/2017 11:44:13: Finished Epoch[ 8 of 15]: [Validate] CrossEntropyWithSoftmax = 1.86996773 * 83050; EvalClassificationError = 0.51725467 * 83050
MPI Rank 1: 12/09/2017 11:44:13: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.869968 (Epoch 8); EvalClassificationError = 0.517255 (Epoch 8)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:13: Starting Epoch 9: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:13: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:14:  Epoch[ 9 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.85947921 * 10240; EvalClassificationError = 0.50673828 * 10240; time = 0.3615s; samplesPerSecond = 28323.4
MPI Rank 1: 12/09/2017 11:44:14:  Epoch[ 9 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.85700426 * 10240; EvalClassificationError = 0.51582031 * 10240; time = 0.3509s; samplesPerSecond = 29182.5
MPI Rank 1: 12/09/2017 11:44:14: Finished Epoch[ 9 of 15]: [Training] CrossEntropyWithSoftmax = 1.85824174 * 20480; EvalClassificationError = 0.51127930 * 20480; totalSamplesSeen = 184320; learningRatePerSample = 9.7656251e-05; epochTime=0.717108s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:15: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.86323873 * 83050; perplexity = 6.44457525; EvalClassificationError = 0.51674895 * 83050
MPI Rank 1: 12/09/2017 11:44:15: Finished Epoch[ 9 of 15]: [Validate] CrossEntropyWithSoftmax = 1.86323873 * 83050; EvalClassificationError = 0.51674895 * 83050
MPI Rank 1: 12/09/2017 11:44:15: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.863239 (Epoch 9); EvalClassificationError = 0.516749 (Epoch 9)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:15: Starting Epoch 10: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:15: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:16:  Epoch[10 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.89317989 * 10240; EvalClassificationError = 0.52548828 * 10240; time = 0.3537s; samplesPerSecond = 28950.8
MPI Rank 1: 12/09/2017 11:44:16:  Epoch[10 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.84631301 * 10240; EvalClassificationError = 0.50986328 * 10240; time = 0.3493s; samplesPerSecond = 29312.2
MPI Rank 1: 12/09/2017 11:44:16: Finished Epoch[10 of 15]: [Training] CrossEntropyWithSoftmax = 1.86974645 * 20480; EvalClassificationError = 0.51767578 * 20480; totalSamplesSeen = 204800; learningRatePerSample = 9.7656251e-05; epochTime=0.707242s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:17: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.85695611 * 83050; perplexity = 6.40421333; EvalClassificationError = 0.51576159 * 83050
MPI Rank 1: 12/09/2017 11:44:17: Finished Epoch[10 of 15]: [Validate] CrossEntropyWithSoftmax = 1.85695611 * 83050; EvalClassificationError = 0.51576159 * 83050
MPI Rank 1: 12/09/2017 11:44:17: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.856956 (Epoch 10); EvalClassificationError = 0.515762 (Epoch 10)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:17: Starting Epoch 11: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:17: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:17:  Epoch[11 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.86460008 * 10240; EvalClassificationError = 0.50751953 * 10240; time = 0.3577s; samplesPerSecond = 28624.3
MPI Rank 1: 12/09/2017 11:44:18:  Epoch[11 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.86031159 * 10240; EvalClassificationError = 0.51816406 * 10240; time = 0.3522s; samplesPerSecond = 29075.7
MPI Rank 1: 12/09/2017 11:44:18: Finished Epoch[11 of 15]: [Training] CrossEntropyWithSoftmax = 1.86245583 * 20480; EvalClassificationError = 0.51284180 * 20480; totalSamplesSeen = 225280; learningRatePerSample = 9.7656251e-05; epochTime=0.71467s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:19: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.85008405 * 83050; perplexity = 6.36035408; EvalClassificationError = 0.51326911 * 83050
MPI Rank 1: 12/09/2017 11:44:19: Finished Epoch[11 of 15]: [Validate] CrossEntropyWithSoftmax = 1.85008405 * 83050; EvalClassificationError = 0.51326911 * 83050
MPI Rank 1: 12/09/2017 11:44:19: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.850084 (Epoch 11); EvalClassificationError = 0.513269 (Epoch 11)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:19: Starting Epoch 12: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:19: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:19:  Epoch[12 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.86700752 * 10240; EvalClassificationError = 0.51181641 * 10240; time = 0.3571s; samplesPerSecond = 28678.9
MPI Rank 1: 12/09/2017 11:44:19:  Epoch[12 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.83390766 * 10240; EvalClassificationError = 0.50585938 * 10240; time = 0.3523s; samplesPerSecond = 29064.6
MPI Rank 1: 12/09/2017 11:44:19: Finished Epoch[12 of 15]: [Training] CrossEntropyWithSoftmax = 1.85045759 * 20480; EvalClassificationError = 0.50883789 * 20480; totalSamplesSeen = 245760; learningRatePerSample = 9.7656251e-05; epochTime=0.713625s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:20: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.84352145 * 83050; perplexity = 6.31875031; EvalClassificationError = 0.51169175 * 83050
MPI Rank 1: 12/09/2017 11:44:20: Finished Epoch[12 of 15]: [Validate] CrossEntropyWithSoftmax = 1.84352145 * 83050; EvalClassificationError = 0.51169175 * 83050
MPI Rank 1: 12/09/2017 11:44:20: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.843521 (Epoch 12); EvalClassificationError = 0.511692 (Epoch 12)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:20: Starting Epoch 13: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:20: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:21:  Epoch[13 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.84005490 * 10046; EvalClassificationError = 0.51542903 * 10046; time = 0.4082s; samplesPerSecond = 24610.5
MPI Rank 1: 12/09/2017 11:44:21:  Epoch[13 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.87225994 * 10240; EvalClassificationError = 0.51484375 * 10240; time = 0.3439s; samplesPerSecond = 29778.3
MPI Rank 1: 12/09/2017 11:44:21: Finished Epoch[13 of 15]: [Training] CrossEntropyWithSoftmax = 1.85713955 * 20480; EvalClassificationError = 0.51479492 * 20480; totalSamplesSeen = 266240; learningRatePerSample = 9.7656251e-05; epochTime=0.766645s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:22: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.83713385 * 83050; perplexity = 6.27851730; EvalClassificationError = 0.50862131 * 83050
MPI Rank 1: 12/09/2017 11:44:22: Finished Epoch[13 of 15]: [Validate] CrossEntropyWithSoftmax = 1.83713385 * 83050; EvalClassificationError = 0.50862131 * 83050
MPI Rank 1: 12/09/2017 11:44:22: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.837134 (Epoch 13); EvalClassificationError = 0.508621 (Epoch 13)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:22: Starting Epoch 14: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:22: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:23:  Epoch[14 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.85347546 * 10240; EvalClassificationError = 0.50312500 * 10240; time = 0.4339s; samplesPerSecond = 23597.4
MPI Rank 1: 12/09/2017 11:44:23:  Epoch[14 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.84170081 * 10240; EvalClassificationError = 0.50791016 * 10240; time = 0.3663s; samplesPerSecond = 27951.9
MPI Rank 1: 12/09/2017 11:44:23: Finished Epoch[14 of 15]: [Training] CrossEntropyWithSoftmax = 1.84758814 * 20480; EvalClassificationError = 0.50551758 * 20480; totalSamplesSeen = 286720; learningRatePerSample = 9.7656251e-05; epochTime=0.80606s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:24: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.83143597 * 83050; perplexity = 6.24284478; EvalClassificationError = 0.50930765 * 83050
MPI Rank 1: 12/09/2017 11:44:24: Finished Epoch[14 of 15]: [Validate] CrossEntropyWithSoftmax = 1.83143597 * 83050; EvalClassificationError = 0.50930765 * 83050
MPI Rank 1: 12/09/2017 11:44:24: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.831436 (Epoch 14); EvalClassificationError = 0.508621 (Epoch 13)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:24: Starting Epoch 15: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:24: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:25:  Epoch[15 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.81729821 * 10240; EvalClassificationError = 0.50380859 * 10240; time = 0.3656s; samplesPerSecond = 28006.8
MPI Rank 1: 12/09/2017 11:44:25:  Epoch[15 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.84154546 * 10240; EvalClassificationError = 0.51152344 * 10240; time = 0.3486s; samplesPerSecond = 29371.7
MPI Rank 1: 12/09/2017 11:44:25: Finished Epoch[15 of 15]: [Training] CrossEntropyWithSoftmax = 1.82942183 * 20480; EvalClassificationError = 0.50766602 * 20480; totalSamplesSeen = 307200; learningRatePerSample = 9.7656251e-05; epochTime=0.718752s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:26: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.82545027 * 83050; perplexity = 6.20558856; EvalClassificationError = 0.50745334 * 83050
MPI Rank 1: 12/09/2017 11:44:26: Finished Epoch[15 of 15]: [Validate] CrossEntropyWithSoftmax = 1.82545027 * 83050; EvalClassificationError = 0.50745334 * 83050
MPI Rank 1: 12/09/2017 11:44:26: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.825450 (Epoch 15); EvalClassificationError = 0.507453 (Epoch 15)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:26: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:26: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running mpiexec -n 2 /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion/cntkcv.cntk currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion OutputDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu DeviceId=0 timestamping=true makeMode=true numCPUThreads=6 shareNodeValueMatrices=true saveBestModelPerCriterion=true stderr=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr
CNTK 2.3.1+ (CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 11:44:26

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion  OutputDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DeviceId=0  timestamping=true  makeMode=true  numCPUThreads=6  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr
HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 11:44:26

/home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DataChanged current directory to /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data
  RunDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion  OutputDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DeviceId=0  timestamping=true  makeMode=true  numCPUThreads=6  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr
Changed current directory to /home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data
--------------------------------------------------------------------------
[[59710,1],1]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: 4bb8be993ee1

Another transport will be used instead, although this may result in
lower performance.
--------------------------------------------------------------------------
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: 2 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 2 out of 2 MPI nodes on a single host (2 requested); we (1) are in (participating)
ping [mpihelper]: 2 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 2 out of 2 MPI nodes on a single host (2 requested); we (0) are in (participating)
ping [mpihelper]: 2 nodes pinging each other
12/09/2017 11:44:26: Redirecting stderr to file /tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr_speechTrain.logrank0
12/09/2017 11:44:27: Redirecting stderr to file /tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr_speechTrain.logrank1
[4bb8be993ee1:28204] 1 more process has sent help message help-mpi-btl-base.txt / btl:no-nics
[4bb8be993ee1:28204] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
MPI Rank 0: CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 11:44:26
MPI Rank 0: 
MPI Rank 0: /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion  OutputDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DeviceId=0  timestamping=true  makeMode=true  numCPUThreads=6  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr
MPI Rank 0: 12/09/2017 11:44:26: -------------------------------------------------------------------
MPI Rank 0: 12/09/2017 11:44:26: Build info: 
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:26: 		Built time: Dec  8 2017 01:46:20
MPI Rank 0: 12/09/2017 11:44:26: 		Last modified date: Wed Nov 15 09:27:10 2017
MPI Rank 0: 12/09/2017 11:44:26: 		Build type: release
MPI Rank 0: 12/09/2017 11:44:26: 		Build target: GPU
MPI Rank 0: 12/09/2017 11:44:26: 		With 1bit-SGD: yes
MPI Rank 0: 12/09/2017 11:44:26: 		With ASGD: yes
MPI Rank 0: 12/09/2017 11:44:26: 		Math lib: mkl
MPI Rank 0: 12/09/2017 11:44:26: 		CUDA version: 9.0.0
MPI Rank 0: 12/09/2017 11:44:26: 		CUDNN version: 7.0.4
MPI Rank 0: 12/09/2017 11:44:26: 		Build Branch: HEAD
MPI Rank 0: 12/09/2017 11:44:26: 		Build SHA1: b130d7735044ce6697bfb963af91445bee740c73
MPI Rank 0: 12/09/2017 11:44:26: 		MPI distribution: Open MPI
MPI Rank 0: 12/09/2017 11:44:26: 		MPI version: 1.10.7
MPI Rank 0: 12/09/2017 11:44:26: -------------------------------------------------------------------
MPI Rank 0: 12/09/2017 11:44:26: -------------------------------------------------------------------
MPI Rank 0: 12/09/2017 11:44:26: GPU info:
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:26: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8112 MB
MPI Rank 0: 12/09/2017 11:44:26: -------------------------------------------------------------------
MPI Rank 0: 12/09/2017 11:44:26: Using 6 CPU threads.
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:26: ##############################################################################
MPI Rank 0: 12/09/2017 11:44:26: #                                                                            #
MPI Rank 0: 12/09/2017 11:44:26: # speechTrain command (train action)                                         #
MPI Rank 0: 12/09/2017 11:44:26: #                                                                            #
MPI Rank 0: 12/09/2017 11:44:26: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:26: 
MPI Rank 0: Starting from checkpoint. Loading network from '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.14'.
MPI Rank 0: SimpleNetworkBuilder Using GPU 0
MPI Rank 0: Reading script file glob_0000.scp ... 948 entries
MPI Rank 0: HTKDeserializer: selected '948' utterances grouped into '3' chunks, average chunk size: 316.0 utterances, 84244.7 frames (for I/O: 316.0 utterances, 84244.7 frames)
MPI Rank 0: HTKDeserializer: determined feature kind as '33'-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: Total (133) state names in state list '/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/state.list'
MPI Rank 0: MLFDeserializer: '948' utterances with '252734' frames
MPI Rank 0: Reading script file glob_0000.cv.scp ... 300 entries
MPI Rank 0: HTKDeserializer: selected '300' utterances grouped into '1' chunks, average chunk size: 300.0 utterances, 83050.0 frames (for I/O: 300.0 utterances, 83050.0 frames)
MPI Rank 0: HTKDeserializer: determined feature kind as '33'-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: Total (133) state names in state list '/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/state.list'
MPI Rank 0: MLFDeserializer: '948' utterances with '252734' frames
MPI Rank 0: 12/09/2017 11:44:26: 
MPI Rank 0: Model has 25 nodes. Using GPU 0.
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:26: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 12/09/2017 11:44:26: Evaluation criterion: EvalClassificationError = ClassificationError
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:26: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:26: 	Node 'B0' (LearnableParameter operation) : [512 x 1]
MPI Rank 0: 12/09/2017 11:44:26: 	Node 'B1' (LearnableParameter operation) : [512 x 1]
MPI Rank 0: 12/09/2017 11:44:26: 	Node 'B2' (LearnableParameter operation) : [132 x 1]
MPI Rank 0: 12/09/2017 11:44:26: 	Node 'W0' (LearnableParameter operation) : [512 x 363]
MPI Rank 0: 12/09/2017 11:44:26: 	Node 'W1' (LearnableParameter operation) : [512 x 512]
MPI Rank 0: 12/09/2017 11:44:26: 	Node 'W2' (LearnableParameter operation) : [132 x 512]
MPI Rank 0: 
MPI Rank 0: Initializing dataParallelSGD with FP64 aggregation.
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:27: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:27: Starting Epoch 15: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:27: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 12/09/2017 11:44:28:  Epoch[15 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.81729821 * 10240; EvalClassificationError = 0.50380859 * 10240; time = 1.0496s; samplesPerSecond = 9756.4
MPI Rank 0: 12/09/2017 11:44:28:  Epoch[15 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.84154546 * 10240; EvalClassificationError = 0.51152344 * 10240; time = 0.3453s; samplesPerSecond = 29655.7
MPI Rank 0: 12/09/2017 11:44:28: Finished Epoch[15 of 15]: [Training] CrossEntropyWithSoftmax = 1.82942183 * 20480; EvalClassificationError = 0.50766602 * 20480; totalSamplesSeen = 307200; learningRatePerSample = 9.7656251e-05; epochTime=1.43559s
MPI Rank 0: NcclComm: disabled, same device used by more than one rank
MPI Rank 0: 12/09/2017 11:44:30: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.82545027 * 83050; perplexity = 6.20558856; EvalClassificationError = 0.50745334 * 83050
MPI Rank 0: 12/09/2017 11:44:30: Finished Epoch[15 of 15]: [Validate] CrossEntropyWithSoftmax = 1.82545027 * 83050; EvalClassificationError = 0.50745334 * 83050
MPI Rank 0: 12/09/2017 11:44:30: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.825450 (Epoch 15); EvalClassificationError = 0.507453 (Epoch 15)
MPI Rank 0: 12/09/2017 11:44:30: SGD: Saving checkpoint model '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn'
MPI Rank 0: 12/09/2017 11:44:30: Best epoch for criterion 'CrossEntropyWithSoftmax' is 15 and model /tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn copied to /tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn_CrossEntropyWithSoftmax
MPI Rank 0: 12/09/2017 11:44:30: Best epoch for criterion 'EvalClassificationError' is 15 and model /tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn copied to /tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn_EvalClassificationError
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:30: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 12/09/2017 11:44:30: __COMPLETED__
MPI Rank 1: CNTK 2.3.1+ (HEAD b130d7, Dec  8 2017 01:52:00) at 2017/12/09 11:44:26
MPI Rank 1: 
MPI Rank 1: /home/ubuntu/workspace/build/1bitsgd/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DataDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SaveBestModelPerCriterion  OutputDir=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu  DeviceId=0  timestamping=true  makeMode=true  numCPUThreads=6  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/stderr
MPI Rank 1: 12/09/2017 11:44:27: -------------------------------------------------------------------
MPI Rank 1: 12/09/2017 11:44:27: Build info: 
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:27: 		Built time: Dec  8 2017 01:46:20
MPI Rank 1: 12/09/2017 11:44:27: 		Last modified date: Wed Nov 15 09:27:10 2017
MPI Rank 1: 12/09/2017 11:44:27: 		Build type: release
MPI Rank 1: 12/09/2017 11:44:27: 		Build target: GPU
MPI Rank 1: 12/09/2017 11:44:27: 		With 1bit-SGD: yes
MPI Rank 1: 12/09/2017 11:44:27: 		With ASGD: yes
MPI Rank 1: 12/09/2017 11:44:27: 		Math lib: mkl
MPI Rank 1: 12/09/2017 11:44:27: 		CUDA version: 9.0.0
MPI Rank 1: 12/09/2017 11:44:27: 		CUDNN version: 7.0.4
MPI Rank 1: 12/09/2017 11:44:27: 		Build Branch: HEAD
MPI Rank 1: 12/09/2017 11:44:27: 		Build SHA1: b130d7735044ce6697bfb963af91445bee740c73
MPI Rank 1: 12/09/2017 11:44:27: 		MPI distribution: Open MPI
MPI Rank 1: 12/09/2017 11:44:27: 		MPI version: 1.10.7
MPI Rank 1: 12/09/2017 11:44:27: -------------------------------------------------------------------
MPI Rank 1: 12/09/2017 11:44:27: -------------------------------------------------------------------
MPI Rank 1: 12/09/2017 11:44:27: GPU info:
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:27: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8019 MB
MPI Rank 1: 12/09/2017 11:44:27: -------------------------------------------------------------------
MPI Rank 1: 12/09/2017 11:44:27: Using 6 CPU threads.
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:27: ##############################################################################
MPI Rank 1: 12/09/2017 11:44:27: #                                                                            #
MPI Rank 1: 12/09/2017 11:44:27: # speechTrain command (train action)                                         #
MPI Rank 1: 12/09/2017 11:44:27: #                                                                            #
MPI Rank 1: 12/09/2017 11:44:27: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:27: 
MPI Rank 1: Starting from checkpoint. Loading network from '/tmp/cntk-test-20171209080859.615414/Speech/DNN_SaveBestModelPerCriterion@release_gpu/models/cntkSpeech.dnn.14'.
MPI Rank 1: SimpleNetworkBuilder Using GPU 0
MPI Rank 1: Reading script file glob_0000.scp ... 948 entries
MPI Rank 1: HTKDeserializer: selected '948' utterances grouped into '3' chunks, average chunk size: 316.0 utterances, 84244.7 frames (for I/O: 316.0 utterances, 84244.7 frames)
MPI Rank 1: HTKDeserializer: determined feature kind as '33'-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: Total (133) state names in state list '/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/state.list'
MPI Rank 1: MLFDeserializer: '948' utterances with '252734' frames
MPI Rank 1: Reading script file glob_0000.cv.scp ... 300 entries
MPI Rank 1: HTKDeserializer: selected '300' utterances grouped into '1' chunks, average chunk size: 300.0 utterances, 83050.0 frames (for I/O: 300.0 utterances, 83050.0 frames)
MPI Rank 1: HTKDeserializer: determined feature kind as '33'-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: Total (133) state names in state list '/home/ubuntu/workspace/Tests/EndToEndTests/Speech/Data/state.list'
MPI Rank 1: MLFDeserializer: '948' utterances with '252734' frames
MPI Rank 1: 12/09/2017 11:44:27: 
MPI Rank 1: Model has 25 nodes. Using GPU 0.
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:27: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 12/09/2017 11:44:27: Evaluation criterion: EvalClassificationError = ClassificationError
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:27: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:27: 	Node 'B0' (LearnableParameter operation) : [512 x 1]
MPI Rank 1: 12/09/2017 11:44:27: 	Node 'B1' (LearnableParameter operation) : [512 x 1]
MPI Rank 1: 12/09/2017 11:44:27: 	Node 'B2' (LearnableParameter operation) : [132 x 1]
MPI Rank 1: 12/09/2017 11:44:27: 	Node 'W0' (LearnableParameter operation) : [512 x 363]
MPI Rank 1: 12/09/2017 11:44:27: 	Node 'W1' (LearnableParameter operation) : [512 x 512]
MPI Rank 1: 12/09/2017 11:44:27: 	Node 'W2' (LearnableParameter operation) : [132 x 512]
MPI Rank 1: 
MPI Rank 1: Initializing dataParallelSGD with FP64 aggregation.
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:27: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:27: Starting Epoch 15: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:27: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 12/09/2017 11:44:28:  Epoch[15 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.81729821 * 10240; EvalClassificationError = 0.50380859 * 10240; time = 1.0568s; samplesPerSecond = 9689.4
MPI Rank 1: 12/09/2017 11:44:28:  Epoch[15 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.84154546 * 10240; EvalClassificationError = 0.51152344 * 10240; time = 0.3452s; samplesPerSecond = 29663.9
MPI Rank 1: 12/09/2017 11:44:28: Finished Epoch[15 of 15]: [Training] CrossEntropyWithSoftmax = 1.82942183 * 20480; EvalClassificationError = 0.50766602 * 20480; totalSamplesSeen = 307200; learningRatePerSample = 9.7656251e-05; epochTime=1.43515s
MPI Rank 1: NcclComm: disabled, same device used by more than one rank
MPI Rank 1: 12/09/2017 11:44:30: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.82545027 * 83050; perplexity = 6.20558856; EvalClassificationError = 0.50745334 * 83050
MPI Rank 1: 12/09/2017 11:44:30: Finished Epoch[15 of 15]: [Validate] CrossEntropyWithSoftmax = 1.82545027 * 83050; EvalClassificationError = 0.50745334 * 83050
MPI Rank 1: 12/09/2017 11:44:30: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.825450 (Epoch 15); EvalClassificationError = 0.507453 (Epoch 15)
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:30: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 12/09/2017 11:44:30: __COMPLETED__